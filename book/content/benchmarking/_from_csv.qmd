## From a csv file

::: {.panel-tabset}

## polars (eager)

```{r}
#| label: csv-polars-benchmarking

csv_polars <- function() {
  
  # Reading the csv file (eager mode)
  result_pl <- pl$read_csv(path = "Datasets/DataMultiTypes.csv")
  
  # Conversion of 2 columns to Date format
  result_pl <- result_pl$with_columns(
    pl$col("colDate1")$str$strptime(pl$Date, "%F %T", strict = FALSE),
    pl$col("colDate2")$str$strptime(pl$Date, "%F %T", strict = FALSE)
  )
  
  # Creation of a diff column between 2 dates (in days)
  result_pl <- result_pl$with_columns(
    (pl$col("colDate2") - pl$col("colDate1"))$dt$days()$alias("diff")
  )
  
  # Filter rows
  result_pl <- result_pl$filter(
    pl$col("colInt")>2000 & pl$col("colInt")<8000
  )
  
  # Grouping and aggregation
  result_agg <- result_pl$groupby(
    "colString"
  )$agg(
    pl$col("colInt")$min()$alias("min_colInt"),
    pl$col("colInt")$mean()$alias("mean_colInt"),
    pl$col("colInt")$max()$alias("max_colInt"),
    pl$col("colNum")$min()$alias("min_colNum"),
    pl$col("colNum")$mean()$alias("mean_colNum"),
    pl$col("colNum")$max()$alias("max_colNum")
  )
  
  return(result_agg)
}

tic()
res_polars <- csv_polars()
toc()
print(res_polars)
```

## R base

```{r}
#| label: csv-rbase-benchmarking

csv_rbase <- function() {
  
  # Reading the csv file
  result <- read.csv("Datasets/DataMultiTypes.csv")
  
  # Conversion of 2 columns to Date format
  result$colDate1 <- as.Date(result$colDate1)
  result$colDate2 <- as.Date(result$colDate2)
  
  # Creation of a diff column between 2 dates (in days)
  result$diff <- round(
    as.integer(
      difftime(
        result$colDate2,
        result$colDate1,
        units = "days")
      ),
    0)
  
  # Filter rows
  result <- result[result$colInt>2000 & result$colInt<8000,]
  
  # Grouping and aggregation
  result_agg <- aggregate(cbind(colInt, colNum) ~ colString, 
                          data = result, 
                          FUN = function(x) c(mean = mean(x), 
                                              min = min(x), 
                                              max = max(x)))
  
  return(result_agg)
}

tic()
res_rbase <- csv_rbase()
toc()
print(res_rbase)
```

## dplyr

```{r}
#| label: csv-dplyr-benchmarking

csv_dplyr <- function() {
  
  # Reading the csv file
  result <- read.csv("Datasets/DataMultiTypes.csv")
  
  # Conversion of 2 columns to Date format
  result <- result |>
    mutate(
      colDate1 = as.Date(colDate1),
      colDate2 = as.Date(colDate2)
    )
  
  # Creation of a diff column between 2 dates (in days)
  result <- result |> 
    mutate(diff = round(as.integer(difftime(colDate2, colDate1, units = "days")),0))
  
  # Filter rows
  result <- result |>
    filter(
      colInt>2000 & colInt<8000
      )
  
  # Grouping and aggregation
  result_agg <- result |>
    group_by(colString) |> 
    summarise(
      min_colInt = min(colInt),
      mean_colInt = mean(colInt),
      mas_colInt = max(colInt),
      min_colNum = min(colNum),
      mean_colNum = mean(colNum),
      max_colNum = max(colNum)
  )
  
  return(result_agg)
}

tic()
res_dplyr <- csv_dplyr()
toc()
print(res_dplyr)
```

## data.table

```{r}
#| label: csv-datatable-benchmarking

csv_dt <- function() {
  
  # Reading the csv file
  result <- read.csv("Datasets/DataMultiTypes.csv")
  
  # Conversion data.frame to data.table
  result_dt <- as.data.table(result)
  
  # Conversion of 2 columns to Date format
  result_dt <- result_dt[, `:=`(colDate1 = as.Date(colDate1),colDate2 = as.Date(colDate2))]
  
  # Creation of a diff column between 2 dates (in days)
  result_dt <- result_dt[, diff := as.integer(difftime(colDate2, colDate1, units = "days"))]
  
  # Filter rows
  result_dt <- result_dt[result_dt$colInt>2000 & result$colInt<8000]
  
  # Grouping and aggregation
  result_agg <- result_dt[, .(
      min_colInt = min(colInt),
      mean_colInt = mean(colInt),
      mas_colInt = max(colInt),
      min_colNum = min(colNum),
      mean_colNum = mean(colNum),
      max_colNum = max(colNum)
    ), by = colString]
  
  return(result_agg)
}

tic()
res_dt <- csv_dt()
toc()
print(res_dt)
```
:::

### Results polars vs others

```{r}
#| label: csv-results-benchmarking
#| message: false
#| warning: false

microbenchmark(
  "R base" = csv_rbase(),
  "dplyr" = csv_dplyr(),
  "data.table" = as.data.frame(csv_dt()),
  "polars" = csv_polars()$to_data_frame(),
  times = 5
 )
```
 
 
::: {.callout-note}
**The data processing performed is not entirely equivalent, since it includes in addition:**  
- for `polars`, conversion to data.frame R at the end of processing  
- for `data.table`, conversion to dt format at the start, then conversion to data.frame R at the end of processing  
:::

ðŸ‘‰ The data processing is 56X faster with `polars`! ðŸ†

::: {.callout-tip}
**The data processing described above is not optimised.** For example, the intermediate result is stored at each stage, which is not good practice...
:::

Here's what the code would be like if we use either **eager mode** or **lazy mode**:

::: {.panel-tabset}

## Eager mode

```{r}
#| label: csv-eager-polars-benchmarking

csv_eager_polars <- function() {
# Reading the csv file (eager mode)
result_agg <- pl$read_csv(path = "Datasets/DataMultiTypes.csv")$
  # Conversion of 2 columns to Date format
  with_columns(
    pl$col("colDate1")$str$strptime(pl$Date, "%F %T", strict = FALSE),
    pl$col("colDate2")$str$strptime(pl$Date, "%F %T", strict = FALSE)
  )$
  # Creation of a diff column between 2 dates (in days)
  with_columns(
    (pl$col("colDate2") - pl$col("colDate1"))$dt$days()$alias("diff")
  )$
  # Filter rows
  filter(
    pl$col("colInt")>2000 & pl$col("colInt")<8000
  )$
  # Grouping and aggregation
  groupby(
    "colString")$
  agg(
    pl$col("colInt")$min()$alias("min_colInt"),
    pl$col("colInt")$mean()$alias("mean_colInt"),
    pl$col("colInt")$max()$alias("max_colInt"),
    pl$col("colNum")$min()$alias("min_colNum"),
    pl$col("colNum")$mean()$alias("mean_colNum"),
    pl$col("colNum")$max()$alias("max_colNum")
  )
  
  return(result_agg)
}
```

## Lazy mode

```{r}
#| label: csv-lazy-polars-benchmarking

csv_lazy_polars <- function() {
# Reading the csv file (eager mode)
result_agg <- pl$lazy_csv_reader(path = "Datasets/DataMultiTypes.csv")$
  # Conversion of 2 columns to Date format
  with_columns(
    pl$col("colDate1")$str$strptime(pl$Date, "%F %T", strict = FALSE),
    pl$col("colDate2")$str$strptime(pl$Date, "%F %T", strict = FALSE)
  )$
  # Creation of a diff column between 2 dates (in days)
  with_columns(
    (pl$col("colDate2") - pl$col("colDate1"))$dt$days()$alias("diff")
  )$
  # Filter rows
  filter(
    pl$col("colInt")>2000 & pl$col("colInt")<8000
  )$
  # Grouping and aggregation
  groupby(
    "colString")$
  agg(
    pl$col("colInt")$min()$alias("min_colInt"),
    pl$col("colInt")$mean()$alias("mean_colInt"),
    pl$col("colInt")$max()$alias("max_colInt"),
    pl$col("colNum")$min()$alias("min_colNum"),
    pl$col("colNum")$mean()$alias("mean_colNum"),
    pl$col("colNum")$max()$alias("max_colNum")
  )
  
  return(result_agg)
}
```
:::

### Results eager vs lazy mode

```{r}
#| label: csv-results-eager-lazy-benchmarking
#| message: false
#| warning: false

microbenchmark(
  "eager mode" = csv_eager_polars(),
  "lazy mode" = csv_lazy_polars(),
  times = 5
 )
```

ðŸ‘‰ The data processing is 124X faster with **lazy mode** `polars`! ðŸ†ðŸ†