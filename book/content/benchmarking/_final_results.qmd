## Final results

### Performance

So what can we conclude?  
With which file format and which method is it fastest to execute the same request?  

Let's have a look! First, let's aggregate all the benchmark results:

```{r}
#| label: final-results-rbind

# Aggregation
bmk_results <- rbind(
  csv_bmk,
  unique_parquet_bmk,
  partitioned_parquet_bmk,
  duckdb_bmk
)
```

Let's do a few basic data manipulation before plotting the results :

```{r}
#| label: data-manipulation-before-plotting
#| code-fold: true
#| message: false
#| warning: false
#| results: 'hide'

# Sort the results
bmk_results$expr <- reorder(bmk_results$expr, bmk_results$time, decreasing = TRUE)

# Define a function to get different colors
get_label_color <- function(label) {
  if (endsWith(label, "partitioned parquet file")) {
    "red"
  } else if (endsWith(label, "unique parquet file")) {
    "orange"
  } else if (endsWith(label, "csv file")) {
    "blue"
  } else if (endsWith(label, "duckdb file")) {
    "green"
  } else {
    "black" 
  }
}
# Define colors for the plot in bmk_results
bmk_results$mycolor <- sapply(as.character(bmk_results$expr),get_label_color)
```


```{r}
#| label: final-results-plot

autoplot(bmk_results) +
    aes(color = bmk_results$mycolor) +
  labs(title = "polars âš”ï¸ others : Benchmark results!",
       subtitle = "ðŸ”Ž Right-click on the plot to open it wide in a new tab") +
  theme(plot.title = element_text(hjust = 0.5))
```

::: {.callout-important title="Final conclusion"}

The first thing to note is that execution time is faster when working with **parquet files** than with csv files. ðŸ†  
**With the exception of polars in lazy mode, execution time is systematically lower with parquet files.**

The big winner of our benchmark is nevertheless **polars (lazy mode)**, which takes the top 2 places in our ranking. ðŸ†ðŸ†ðŸ†  
 
This is followed by processing with arrow and then with SQL.   
 
Not surprisingly, R base and dplyr are at the bottom of the ranking.
:::

### Memory usage

We've just analysed the performance of the various alternatives to Polars, but what about R's memory usage?  

To do this, we're going to use `mem_change()` from {pryr} package. This method tells you how memory changes during code execution. Positive numbers represent an increase in the memory used by R, and negative numbers represent a decrease. 


```{r}
#| label: memory-usage-results
gc()
mem_change(csv_rbase())
mem_change(csv_dplyr())
mem_change(csv_dt())
mem_change(duckdb_sql())
mem_change(parquet_polars_lazy()$collect())
mem_change(parquet_polars_lazy()$collect()$to_data_frame())
```
