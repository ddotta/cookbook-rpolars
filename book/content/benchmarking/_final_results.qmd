## Final results

So what can we conclude?  
With which file format and which method is it fastest to execute the same request?  

Let's have a look! First, let's aggregate all the benchmark results:

```{r}
#| label: final-results-rbind

# Aggregation
bmk_results <- rbind(
  csv_bmk,
  unique_parquet_bmk,
  partitioned_parquet_bmk,
  duckdb_bmk
)
# Sort the results
bmk_results$expr <- reorder(bmk_results$expr, bmk_results$time, decreasing = TRUE)
```


```{r}
#| label: final-results-plot
autoplot(bmk_results) +
  labs(title = "polars âš”ï¸ others : Benchmark results!") +
  theme(plot.title = element_text(hjust = 0.5))
```


The first thing to note is that execution time is faster when working with **parquet files** than with csv files. ðŸ†  
**With the exception of polars in lazy mode, execution time is systematically lower with parquet files.**

The big winner of our benchmark is nevertheless **polars (lazy mode)**, which takes the top 3 places in our ranking. ðŸ†ðŸ†ðŸ†  
 
This is followed by processing with arrow and then with SQL.   
 
Not surprisingly, R base and dplyr are at the bottom of the ranking.

