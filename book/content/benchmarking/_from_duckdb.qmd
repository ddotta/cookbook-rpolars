## From a DuckDb file

### Use DuckDB engine on R object

Let's start by looking at how to use the DuckDb engine on R objects.  
There are two main possibilities:  


1. To use the DuckDB engine to query a R object with **dplyr**, you can use the `arrow::to_duckdb()` method (**arrow/dplyr/DuckDB engine**) 

2. To use the DuckDB engine to query a R object with **the standard DBI methods**, you can use the `arrow::to_duckdb()` and `DBI::dbGetQuery()` methods (**arrow/SQL/DuckDB engine**).
In the following example, we save the R data.frame as a DuckDb virtual table, giving it a name that will be used in the SQL query, finally we execute the query.


::: {.panel-tabset}

## arrow/dplyr/DuckDB

```{r}
#| label: duckdb-arrow-dplyr-benchmarking

duckdb_arrow_dplyr <- function(variables) {
  
  result <- DataMultiTypes |>
    
    to_duckdb() |>
    
    mutate(
      # Conversion of 2 columns to Date format
      colDate1 = as.Date(colDate1),
      colDate2 = as.Date(colDate2)
    ) |>
    # Filter rows
    filter(
      colInt>2000 & colInt<8000
    ) |>
    # Grouping and aggregation
    group_by(colString) |> 
    summarise(
      min_colInt = min(colInt, na.rm = TRUE),
      mean_colInt = mean(colInt, na.rm = TRUE),
      mas_colInt = max(colInt, na.rm = TRUE),
      min_colNum = min(colNum, na.rm = TRUE),
      mean_colNum = mean(colNum, na.rm = TRUE),
      max_colNum = max(colNum, na.rm = TRUE)
    )
  
  
  return(result)
  
}
tic()
duckdb_arrow_dplyr()
toc()
```

## arrow/SQL/DuckDB

```{r}
#| label: duckdb-arrow-sql-benchmarking

duckdb_arrow_sql <- function(variables) {
  
  con <- dbConnect(duckdb::duckdb())
  
  arrow::to_duckdb(DataMultiTypes, table_name = "DataMultiTypes_duckdb", con = con)
  
  result <- dbGetQuery(
    con, 
    "SELECT colString,
           MIN(colInt) AS min_colInt,
           AVG(colInt) AS mean_colInt,
           MAX(colInt) AS max_colInt,
           MIN(colNum) AS min_colNum,
           AVG(colNum) AS mean_colNum,
           MAX(colNum) AS max_colNum
    FROM (
        SELECT colString,
               colInt,
               colNum
        FROM DataMultiTypes_duckdb
        WHERE colInt > 2000 AND colInt < 8000
) AS filtered_data
GROUP BY colString;")
  
  dbDisconnect(con, shutdown=TRUE)
  
  return(result)
  
}
tic()
duckdb_arrow_sql()
toc()
```
:::

::: {.callout-tip}
With the arrow::to_duckdb()` method, we see that the result is returned by mentioning â€œ# Database: DuckDBâ€, it is indeed the DuckDB engine that was used.

One of the advantages of using the DuckDB engine and dplyr may be **to use a feature implemented by DuckDB but not yet by Arrow**. We can do the opposite, and return to the Arrow engine with `arrow::to_arrow()`.

**The interoperability between Arrow, DuckDB and dplyr is very easy to use and brings a lot of flexibility for data processing.**
:::


### Results with DuckDB engine

```{r}
#| label: duckdb-engine-results-benchmarking
#| message: false
#| warning: false

microbenchmark(
  "arrow/dplyr/DuckDB" = duckdb_arrow_dplyr(),
  "arrow/SQL/DuckDB" = duckdb_arrow_sql(),
  times = 5
 )
```

### Queries on Duckdb files

Let's now look at how to perform queries on duckdb files.

For this comparison, we will use :

- For **SQL**, the `DBI::dbGetQuery()` method. In this way, we use the standard DBI methods to work from a DuckDb file.  

::: {.panel-tabset}

## arrow/SQL

```{r}
#| label: duckdb-sql-benchmarking

duckdb_sql <- function(variables) {
  
  con <- dbConnect(duckdb::duckdb(),
                 "Datasets/DataMultiTypes.duckdb")
  
  result <- dbGetQuery(
    con, 
    "SELECT colString,
           MIN(colInt) AS min_colInt,
           AVG(colInt) AS mean_colInt,
           MAX(colInt) AS max_colInt,
           MIN(colNum) AS min_colNum,
           AVG(colNum) AS mean_colNum,
           MAX(colNum) AS max_colNum
    FROM (
        SELECT colString,
               colInt,
               colNum
        FROM DataMultiTypes
        WHERE colInt > 2000 AND colInt < 8000
) AS filtered_data
GROUP BY colString;")
  
  dbDisconnect(con, shutdown=TRUE)
  
  return(result)
  
}
tic()
duckdb_sql()
toc()
```
:::

### Results for partitioned parquet files

```{r}
#| label: duckdb-results-benchmarking
#| message: false
#| warning: false

duckdb_bmk <- microbenchmark(
  "SQL" = duckdb_sql(),
  times = 5
 )
```
 
Note that the query withthe standard DBI methods is faster than those with dplyr verbs ðŸ†