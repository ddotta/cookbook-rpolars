[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cookbook Polars for R",
    "section": "",
    "text": "Preface\nWelcome to the Polars cookbook for R users. The goal of the cookbook is to provide solutions to common tasks and problems in using Polars with R. It allows R users using their usual packages to quickly get the syntax required to use Polars with R.\nIt is structured around side-by-side comparisons between polars, R base, dplyr, tidyr and data.table.\nThis book is not a substitute for the official documentation of the rpolars project which is the definitive reference on the subject. It is simply intended to illustrate my use of Polars with R and can be a complementary to the official Polars documentation."
  },
  {
    "objectID": "index.html#run-the-code-from-this-book",
    "href": "index.html#run-the-code-from-this-book",
    "title": "Cookbook Polars for R",
    "section": "Run the code from this book",
    "text": "Run the code from this book\nThis cookbook’s website is built by GitHub Actions, which runs the code every time we make a change, ensuring code correctness and reproducibility. The current build status as follows:\n\n\n\n\n\nTo run this cookbook’s code, you can copied and pasted the code into the R command window if you want to see them in action."
  },
  {
    "objectID": "index.html#what-is-polars",
    "href": "index.html#what-is-polars",
    "title": "Cookbook Polars for R",
    "section": "What is Polars ?",
    "text": "What is Polars ?\nPolars is a very fast and elegant dataframe library that does the same sort of thing as the main data manipulation packages in R including dplyr and data.table.\nMost of this book is structured examples of Polars, dplyr and data.table idiomatic code, with comments on the API and performance of the three."
  },
  {
    "objectID": "index.html#who-is-this-for",
    "href": "index.html#who-is-this-for",
    "title": "Cookbook Polars for R",
    "section": "Who is this for?",
    "text": "Who is this for?\nThis is not a beginner’s introduction to data programming, though you certainly don’t need to be an expert to read it. If you have some familiarity with any dataframe library, most of the examples should make sense, but if you’re familiar with dplyr or data.table they’ll make even more sense because all the Polars code is accompanied by the equivalent code.\nFor users of Python and in particular Pandas, you can consult this excellent book which was the inspiration for the one you are reading now."
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Cookbook Polars for R",
    "section": "Contributing",
    "text": "Contributing\nThis book is free and open source, so please do open an issue if you notice a problem!"
  },
  {
    "objectID": "first_steps.html#installation",
    "href": "first_steps.html#installation",
    "title": "1  First steps with Polars",
    "section": "1.1 Installation",
    "text": "1.1 Installation\nUntil the R polars package is uploaded to CRAN, the polars package development team offers several solutions for installation.\nThe most practical one in my opinion at the moment is to use R-universe and install like this:\n\ninstall.packages(\"polars\", repos = \"https://rpolars.r-universe.dev\")\nlibrary(polars)\n\nTo know the version of the polars package you have just installed and to have information on which features are enabled, you can use the polars_info() method.\n\npl$polars_info()\n\nR Polars package version: 0.7.0.9000\n\nFeatures:          \nsimd FALSE"
  },
  {
    "objectID": "first_steps.html#first-glimpse",
    "href": "first_steps.html#first-glimpse",
    "title": "1  First steps with Polars",
    "section": "1.2 First glimpse",
    "text": "1.2 First glimpse\nPolars’ main functions are stored in the “pl” namespace and can be accessed using the “pl$” prefix to prevent conflicts with other packages and base R function names. For more, see here.\n\n1.2.1 Convert a R data.frame to a polars DataFrame\nFirst example to convert the most famous R data frame (iris) to a Polars DataFrame:\n\niris_polars &lt;- pl$DataFrame(iris)\niris_polars\n\nshape: (150, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬───────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species   │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---       │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat       │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═══════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa    │\n│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ setosa    │\n│ …            ┆ …           ┆ …            ┆ …           ┆ …         │\n│ 6.3          ┆ 2.5         ┆ 5.0          ┆ 1.9         ┆ virginica │\n│ 6.5          ┆ 3.0         ┆ 5.2          ┆ 2.0         ┆ virginica │\n│ 6.2          ┆ 3.4         ┆ 5.4          ┆ 2.3         ┆ virginica │\n│ 5.9          ┆ 3.0         ┆ 5.1          ┆ 1.8         ┆ virginica │\n└──────────────┴─────────────┴──────────────┴─────────────┴───────────┘\n\n\n\n\n1.2.2 Count the number of lines\nFor example, to count the number of lines of the iris data frame :\n\npolarsR base\n\n\n\n# With pl$ prefix\npl$DataFrame(iris)$height\n\n[1] 150\n\n# Using iris_polars\niris_polars$height\n\n[1] 150\n\n\n\n\n\nnrow(iris)\n\n[1] 150\n\n\n\n\n\n\n\n1.2.3 Extract data from a DataFrame\nTo select the first 5 iris rows and the Petal.Length and Species columns, syntax is identical between Polars and R base:\n\npolarsR basedplyrdata.table\n\n\n\niris_polars[1:5, c(\"Petal.Length\", \"Species\")]\n\nshape: (5, 2)\n┌──────────────┬─────────┐\n│ Petal.Length ┆ Species │\n│ ---          ┆ ---     │\n│ f64          ┆ cat     │\n╞══════════════╪═════════╡\n│ 1.4          ┆ setosa  │\n│ 1.4          ┆ setosa  │\n│ 1.3          ┆ setosa  │\n│ 1.5          ┆ setosa  │\n│ 1.4          ┆ setosa  │\n└──────────────┴─────────┘\n\n\n\n\n\niris[1:5, c(\"Petal.Length\", \"Species\")]\n\n  Petal.Length Species\n1          1.4  setosa\n2          1.4  setosa\n3          1.3  setosa\n4          1.5  setosa\n5          1.4  setosa\n\n\n\n\n\niris |&gt; \n  slice(1:5) |&gt; \n  select(Petal.Length,Species)\n\n  Petal.Length Species\n1          1.4  setosa\n2          1.4  setosa\n3          1.3  setosa\n4          1.5  setosa\n5          1.4  setosa\n\n\n\n\n\niris_dt[1:5, .(Petal.Length, Species)]\n\n   Petal.Length Species\n1:          1.4  setosa\n2:          1.4  setosa\n3:          1.3  setosa\n4:          1.5  setosa\n5:          1.4  setosa"
  },
  {
    "objectID": "first_steps.html#data-structures",
    "href": "first_steps.html#data-structures",
    "title": "1  First steps with Polars",
    "section": "1.3 Data Structures",
    "text": "1.3 Data Structures\n\nThe core base data structures provided by Polars are Series and DataFrames.\n\n\n1.3.1 Series and vectors\n\n\n\n\n\n\nImportant\n\n\n\nSeries are a 1-dimensional data structure. Within a series all elements have the same Data Type.\n\n\nIn Polars objects, Series object are like R vectors.\nTo create a Polars Series from scratch:\n\npolarsR base\n\n\n\nmynumbers_serie &lt;- pl$Series(1:3)\nmynumbers_serie\n\npolars Series: shape: (3,)\nSeries: '' [i32]\n[\n    1\n    2\n    3\n]\n\nmyletters_serie &lt;- pl$Series(c(\"a\",\"b\",\"c\"))\nmyletters_serie\n\npolars Series: shape: (3,)\nSeries: '' [str]\n[\n    \"a\"\n    \"b\"\n    \"c\"\n]\n\n# To name a Series\npl$Series(name = \"myletters\", c(\"a\",\"b\",\"c\"))\n\npolars Series: shape: (3,)\nSeries: 'myletters' [str]\n[\n    \"a\"\n    \"b\"\n    \"c\"\n]\n\n\n\n\n\nmynumbers_vector &lt;- 1:3\nmynumbers_vector\n\n[1] 1 2 3\n\nmyletters_vector &lt;- c(\"a\",\"b\",\"c\")\nmyletters_vector\n\n[1] \"a\" \"b\" \"c\"\n\n\n\n\n\n\n\n1.3.2 DataFrame and data.frame\n\n\n\n\n\n\nNote\n\n\n\nA DataFrame is a 2-dimensional data structure that is backed by a Series, and it can be seen as an abstraction of a collection (e.g. list) of Series.\n\n\nIn polars objects, DataFrame object are like R data.frame and close to a tibble and a data.table object. DataFrame has some attributes and you can see here to know how you can use it.\nTo create a Polars DataFrame from scratch:\n\npolarsR basedplyrdata.table\n\n\n\n# Creation of a DataFrame object with Series\nmydf &lt;- pl$DataFrame(\n  col1 = mynumbers_serie,\n  col2 = myletters_serie\n)\n# Creation of a DataFrame object with Series and vectors\npl$DataFrame(\n  col1 = mynumbers_serie,\n  col2 = myletters_vector\n)\n\nshape: (3, 2)\n┌──────┬──────┐\n│ col1 ┆ col2 │\n│ ---  ┆ ---  │\n│ i32  ┆ str  │\n╞══════╪══════╡\n│ 1    ┆ a    │\n│ 2    ┆ b    │\n│ 3    ┆ c    │\n└──────┴──────┘\n\n\n\n\n\ndata.frame(\n  col1 = mynumbers_vector,\n  col2 = myletters_vector\n)\n\n  col1 col2\n1    1    a\n2    2    b\n3    3    c\n\n\n\n\n\ntibble(\n  col1 = mynumbers_vector,\n  col2 = myletters_vector\n)\n\n# A tibble: 3 × 2\n   col1 col2 \n  &lt;int&gt; &lt;chr&gt;\n1     1 a    \n2     2 b    \n3     3 c    \n\n\n\n\n\ndata.table(\n  col1 = mynumbers_vector,\n  col2 = myletters_vector\n)\n\n   col1 col2\n1:    1    a\n2:    2    b\n3:    3    c\n\n\n\n\n\n\n1.3.2.1 Missing values\nAs in arrow, missing data is represented in Polars with a null value. This null missing value applies for all data types including numerical values.\nYou can manually define a missing value using NA value in R:\n\npl$DataFrame(\n  col1 = pl$Series(c(NA,\"b\",\"c\"))\n)\n\nshape: (3, 1)\n┌──────┐\n│ col1 │\n│ ---  │\n│ str  │\n╞══════╡\n│ null │\n│ b    │\n│ c    │\n└──────┘"
  },
  {
    "objectID": "first_steps.html#manipulation-of-series-and-dataframes-with-r-standard-functions",
    "href": "first_steps.html#manipulation-of-series-and-dataframes-with-r-standard-functions",
    "title": "1  First steps with Polars",
    "section": "1.4 Manipulation of Series and DataFrames with R standard functions",
    "text": "1.4 Manipulation of Series and DataFrames with R standard functions\nSeries and DataFrames can be manipulated with a lot of standard R functions.\nSome examples with Series:\n\nsum(mynumbers_serie)\n\n[1] 6\n\npaste(myletters_serie,collapse = \"\")\n\n[1] \"abc\"\n\n\nSome examples with DataFrames:\n\nnames(mydf)\n\n[1] \"col1\" \"col2\"\n\nncol(mydf)\n\n[1] 2"
  },
  {
    "objectID": "first_steps.html#expressions",
    "href": "first_steps.html#expressions",
    "title": "1  First steps with Polars",
    "section": "1.5 Expressions",
    "text": "1.5 Expressions\nHere I’m quoting what Damian Skrzypiec said in his blog about Polars expressions:\n\nOne of fundamental building blocks in Polars are Polars expressions. In general Polars expression is any function that transforms Polars series into another Polars series. There are few advantageous aspects of Polars expressions. Firstly expressions are optimized. Particularly if expression need to be executed on multiple columns, then it will be parallelized. It’s one of reasons behind Polars high performance. Another aspect is the fact the Polars implements an extensive set of builtin expressions that user can compose (chain) into more complex expressions.\n\nThis is what an Polars expression looks like:\n\npl$col(\"Petal.Length\")$round(decimals = 0)$alias(\"Petal.Length.rounded\")\n\nWhich means that: - Select column “Petal.Length” - Then round the column with 0 decimals - Then rename the column “Petal.Length.rounded”\n\n\n\n\n\n\nTip\n\n\n\nEvery expression produces a new expression, and that they can be piped together.\n\n\nFor example:\n\npl$col(\"bar\")$filter(pl$col(\"foo\") == 1)$sum()\n\nTo learn more about Polars expressions, see the official documentation.\n\nIf you have read this far and managed to reproduce the examples, congratulations! You are ready to dive into the deep end of Polars with R in the next parts of this cookbook! 🚀"
  },
  {
    "objectID": "first_steps.html#dataframes-display-on-windows",
    "href": "first_steps.html#dataframes-display-on-windows",
    "title": "1  First steps with Polars",
    "section": "1.6 DataFrames display on Windows",
    "text": "1.6 DataFrames display on Windows\n\n\n\n\n\n\nNote\n\n\n\nThis section is for Windows and RStudio users only!\n\n\nAs a Windows and RStudio user, you may encounter a problem with the display of Polars DataFrames.\nHere’s what can happen with the default font in RStudio Lucida Console:\n\n\n\n\n\nTo resolve this display problem, I recommend using the Cascadia font:"
  },
  {
    "objectID": "data_manipulation.html#introduction-to-methods",
    "href": "data_manipulation.html#introduction-to-methods",
    "title": "2  Data manipulation",
    "section": "2.1 Introduction to methods",
    "text": "2.1 Introduction to methods\nThe added value of Polars consists in the methods. Those powerful methods are accessed using the $ operator.\n\nFor Series, see this section for the methods available in {polars}.\nFor DataFrames, see this section for the methods available in {polars}.\n\nSome examples with Series:\n\n# To get a sum\nmynumbers_serie$sum()\n\n[1] 6\n\n# To sort\nmynumbers_serie$sort()\n\npolars Series: shape: (3,)\nSeries: 'col1' [i32]\n[\n    1\n    2\n    3\n]\n\n\nSome examples with DataFrame:\n\n# To get a character vector of column names\nmydf$columns\n\n[1] \"col1\" \"col2\"\n\n# To get dimensions of DataFrame\nmydf$shape\n\n[1] 3 2\n\n# We can mix standard R functions and methods\nlength(mydf$columns)\n\n[1] 2\n\n\nPolars includes a very useful chaining method in data manipulation operations. From this point of view, Polars is more like dplyr and data.table. This is how the chaining method is defined in the official documentation:\n\nIn polars our method chaining syntax takes the form object$m1()$m2(), where object is our data object, and m1() and m2() are appropriate methods, like subsetting or aggregation expressions.\n\nLet’s see an example with the iris dataset:\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$\n  groupby(\n  \"Species\")$\n  median()  \n\nshape: (3, 5)\n┌────────────┬──────────────┬─────────────┬──────────────┬─────────────┐\n│ Species    ┆ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width │\n│ ---        ┆ ---          ┆ ---         ┆ ---          ┆ ---         │\n│ cat        ┆ f64          ┆ f64         ┆ f64          ┆ f64         │\n╞════════════╪══════════════╪═════════════╪══════════════╪═════════════╡\n│ setosa     ┆ 5.0          ┆ 3.4         ┆ 1.5          ┆ 0.2         │\n│ versicolor ┆ 5.9          ┆ 2.8         ┆ 4.35         ┆ 1.3         │\n│ virginica  ┆ 6.5          ┆ 3.0         ┆ 5.55         ┆ 2.0         │\n└────────────┴──────────────┴─────────────┴──────────────┴─────────────┘\n\n\n\n\n\naggregate(. ~ Species, iris, median)\n\n     Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n1     setosa          5.0         3.4         1.50         0.2\n2 versicolor          5.9         2.8         4.35         1.3\n3  virginica          6.5         3.0         5.55         2.0\n\n\n\n\n\niris |&gt;\n  group_by(Species) |&gt;\n  summarise(across(everything(),median))\n\n# A tibble: 3 × 5\n  Species    Sepal.Length Sepal.Width Petal.Length Petal.Width\n  &lt;fct&gt;             &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1 setosa              5           3.4         1.5          0.2\n2 versicolor          5.9         2.8         4.35         1.3\n3 virginica           6.5         3           5.55         2  \n\n\n\n\n\niris_dt[, lapply(.SD, median), by = Species]\n\n      Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n1:     setosa          5.0         3.4         1.50         0.2\n2: versicolor          5.9         2.8         4.35         1.3\n3:  virginica          6.5         3.0         5.55         2.0\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the Polars code used above, you will notice that we have introduced line breaks. We could have written the whole code on the same line but for the sake of readability I prefer to separate the methods used by line breaks."
  },
  {
    "objectID": "data_manipulation.html#conversion-between-seriesdataframes-and-vectordata.frames",
    "href": "data_manipulation.html#conversion-between-seriesdataframes-and-vectordata.frames",
    "title": "2  Data manipulation",
    "section": "2.2 Conversion between Series/DataFrames and vector/data.frames",
    "text": "2.2 Conversion between Series/DataFrames and vector/data.frames\n\n2.2.1 From vector/data.frames to Series/DataFrames\nThese conversions have already been seen earlier in this book.\n\n# To convert vector to Polars Series\nmyvector &lt;- pl$Series(c(\"a\",\"b\",\"c\"))\n# To convert data.frames to DataFrames\niris_polars &lt;- pl$DataFrame(iris)\n\n\n\n2.2.2 From Series/DataFrames to vector/data.frames\nHere, we can use to_r() and to_data_frame() methods.\n\n# To convert Polars Series to vector or list\nmyletters_serie$to_r()\n\n[1] \"a\" \"b\" \"c\"\n\n# To convert DataFrames to data.frames\nmydf$to_data_frame()\n\n  col1 col2\n1    1    a\n2    2    b\n3    3    c"
  },
  {
    "objectID": "data_manipulation.html#initial-informations-on-a-dataframe",
    "href": "data_manipulation.html#initial-informations-on-a-dataframe",
    "title": "2  Data manipulation",
    "section": "2.3 Initial informations on a DataFrame",
    "text": "2.3 Initial informations on a DataFrame\nHere is a list of instructions that I frequently use to quickly get information about a DataFrame.\n\n2.3.1 Get the schema\nA DataFrame has a schema attribute which is a named list of DataTypes.\n\nmydf$schema\n\n$col1\nDataType: Int32\n\n$col2\nDataType: Utf8\n\n# This works also on LazyFrame\nmydf$lazy()$schema\n\n$col1\nDataType: Int32\n\n$col2\nDataType: Utf8\n\n\n\n\n2.3.2 Get the dimensions\nA DataFrame has a shape attribute which is a two length numeric vector of c(nrows,ncols).\n\nmydf$shape\n\n[1] 3 2\n\n\n\n\n2.3.3 Get columns types\nA DataFrame has a dtypes attribute which is a list of dtypes (for data type) for every column of the DataFrame.\nAlternatively, the dtype_strings() method can be used to get columns types in a character/string vector.\n\n# With dtypes attribute (with a \"s\" and without parentheses)\nmydf$dtypes\n\n[[1]]\nDataType: Int32\n\n[[2]]\nDataType: Utf8\n\n# This works also on LazyFrame\nmydf$lazy()$dtypes\n\n[[1]]\nDataType: Int32\n\n[[2]]\nDataType: Utf8\n\n# With dtype_strings() method (wihout a \"s\" and with parentheses)\nmydf$dtype_strings()\n\n[1] \"i32\" \"str\"\n\n\n\n\n2.3.4 Get a glimpse\nYou can access a dense preview of a DataFrame by using the glimpse() method. f The formatting is done one line per column, so wide DataFrame show nicely. Each line will show the column name, the dtypes attributes and the first few values.\n\npl$DataFrame(iris)$glimpse()\n\n& Sepal.Length&lt;f64&gt; 5.1, 4.9, 4.7, 4.6, 5, 5.4, 4.6, 5, 4.4, 4.9\n& Sepal.Width &lt;f64&gt; 3.5, 3, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1\n& Petal.Length&lt;f64&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5\n& Petal.Width &lt;f64&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1\n& Species     &lt;cat&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa\n\n\n\n\n2.3.5 Get summary statistics\nYou can access some summary statistics from a DataFrame by using the describe() method.\n\npl$DataFrame(iris)$describe()\n\nshape: (9, 6)\n┌────────────┬──────────────┬─────────────┬──────────────┬─────────────┬─────────┐\n│ describe   ┆ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species │\n│ ---        ┆ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     │\n│ str        ┆ f64          ┆ f64         ┆ f64          ┆ f64         ┆ f64     │\n╞════════════╪══════════════╪═════════════╪══════════════╪═════════════╪═════════╡\n│ count      ┆ 150.0        ┆ 150.0       ┆ 150.0        ┆ 150.0       ┆ 150.0   │\n│ null_count ┆ 0.0          ┆ 0.0         ┆ 0.0          ┆ 0.0         ┆ 0.0     │\n│ mean       ┆ 5.843333     ┆ 3.057333    ┆ 3.758        ┆ 1.199333    ┆ null    │\n│ std        ┆ 0.828066     ┆ 0.435866    ┆ 1.765298     ┆ 0.762238    ┆ null    │\n│ min        ┆ 4.3          ┆ 2.0         ┆ 1.0          ┆ 0.1         ┆ null    │\n│ max        ┆ 7.9          ┆ 4.4         ┆ 6.9          ┆ 2.5         ┆ null    │\n│ median     ┆ 5.8          ┆ 3.0         ┆ 4.35         ┆ 1.3         ┆ null    │\n│ 25pct      ┆ 5.1          ┆ 2.8         ┆ 1.6          ┆ 0.3         ┆ null    │\n│ 75pct      ┆ 6.4          ┆ 3.3         ┆ 5.1          ┆ 1.8         ┆ null    │\n└────────────┴──────────────┴─────────────┴──────────────┴─────────────┴─────────┘\n\n\n\n\n2.3.6 Get the rows number\nA DataFrame has a width attribute which returns the width of the DataFrame.\n\n# With width attribute\nmydf$width\n\n[1] 2\n\n\n\n\n2.3.7 Get the columns number\nA DataFrame has a height attribute which returns the width of the DataFrame.\n\n# With height attribute\nmydf$height\n\n[1] 3\n\n\n\n\n2.3.8 Get the columns names\nA DataFrame has a columns attribute which returns the columns names of the DataFrame in a character vector.\n\nmydf$columns\n\n[1] \"col1\" \"col2\"\n\n# This works also on LazyFrame\nmydf$lazy()$columns\n\n[1] \"col1\" \"col2\"\n\n\n\n\n2.3.9 Rename columns\nA character vector can be passed to the columns attribute to rename the columns names of the DataFrame.\n\nmydf$columns &lt;- c(\"colA\",\"colB\")\nmydf$columns\n\n[1] \"colA\" \"colB\"\n\n\n\n\n2.3.10 Get the size\nThe estimated_size() method can be used to get an estimation of the total allocated size (in Bytes) of a DataFrame.\n\nmydf$estimated_size()\n\n[1] 47\n\n\n\n\n2.3.11 Get the first n rows\nThe head() method can be used to get the first n rows of a DataFrame.\n\n# To get the 2 first rows\nmydf$head(2)\n\nshape: (2, 2)\n┌──────┬──────┐\n│ colA ┆ colB │\n│ ---  ┆ ---  │\n│ i32  ┆ str  │\n╞══════╪══════╡\n│ 1    ┆ a    │\n│ 2    ┆ b    │\n└──────┴──────┘\n\n\n\n\n2.3.12 Count values in a DataFrame\nThe value_counts() method can be used to count values in a Series of a DataFrame. value_counts() works with a Series. It must therefore be supplied either with square brackets or with the select() method. See here to learn about it.\n\npolarsR basedplyrdata.table\n\n\n\n# 1st option with square brackets\npl$DataFrame(iris)[,c(\"Species\")]$value_counts()\n\nshape: (3, 2)\n┌────────────┬────────┐\n│ Species    ┆ counts │\n│ ---        ┆ ---    │\n│ cat        ┆ u32    │\n╞════════════╪════════╡\n│ setosa     ┆ 50     │\n│ versicolor ┆ 50     │\n│ virginica  ┆ 50     │\n└────────────┴────────┘\n\n# 2nd option with select() method\npl$DataFrame(iris)$select(pl$col(\"Species\"))$to_series()$value_counts()\n\nshape: (3, 2)\n┌────────────┬────────┐\n│ Species    ┆ counts │\n│ ---        ┆ ---    │\n│ cat        ┆ u32    │\n╞════════════╪════════╡\n│ setosa     ┆ 50     │\n│ versicolor ┆ 50     │\n│ virginica  ┆ 50     │\n└────────────┴────────┘\n\n\n\n\n\ntable(iris$Species)\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\n\n\n\niris |&gt;\n  count(Species)\n\n     Species  n\n1     setosa 50\n2 versicolor 50\n3  virginica 50\n\n\n\n\n\niris_dt[, .N, by = Species]\n\n      Species  N\n1:     setosa 50\n2: versicolor 50\n3:  virginica 50\n\n\n\n\n\n\n\n2.3.13 Count NA over columns in a DataFrame\nThe null_count() method can be used to count NA values of a DataFrame.\n\npolarsR basedplyrdata.table\n\n\n\nmydfNA &lt;- pl$DataFrame(\n  colA = pl$Series(c(\"a\",NA,\"c\")),\n  colB = pl$Series(c(\"d\",NA,NA)))\nmydfNA$null_count()\n\nshape: (1, 2)\n┌──────┬──────┐\n│ colA ┆ colB │\n│ ---  ┆ ---  │\n│ u32  ┆ u32  │\n╞══════╪══════╡\n│ 1    ┆ 2    │\n└──────┴──────┘\n\n\n\n\n\nmydfNA &lt;- data.frame(\n  colA = c(\"a\",NA,\"c\"),\n  colB = c(\"d\",NA,NA))\nsapply(mydfNA, function(x) sum(is.na(x)))\n\ncolA colB \n   1    2 \n\n\n\n\n\nmydfNA |&gt;\n  summarise(across(everything(), ~sum(is.na(.))))\n\n  colA colB\n1    1    2\n\n\n\n\n\nmydfNA_dt &lt;- as.data.table(mydfNA)\nmydfNA_dt[, lapply(.SD, function(x) sum(is.na(x))), .SDcols = names(mydfNA_dt)]\n\n   colA colB\n1:    1    2"
  },
  {
    "objectID": "data_manipulation.html#filter-rows",
    "href": "data_manipulation.html#filter-rows",
    "title": "2  Data manipulation",
    "section": "2.4 Filter rows",
    "text": "2.4 Filter rows\nThe first option to filter rows of a DataFrame is to use square brackets [] indexing (with integer row number).\n\ndata(iris)\n# The first four lines\npl$DataFrame(iris)[1:4]\n\nshape: (4, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa  │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa  │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa  │\n│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ setosa  │\n└──────────────┴─────────────┴──────────────┴─────────────┴─────────┘\n\n# The lines 1, 3 and 5\npl$DataFrame(iris)[c(1,3,5)]\n\nshape: (3, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa  │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa  │\n│ 5.0          ┆ 3.6         ┆ 1.4          ┆ 0.2         ┆ setosa  │\n└──────────────┴─────────────┴──────────────┴─────────────┴─────────┘\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt’s convenient when you have to quickly inspect your data. But you’ll quickly be limited by the square brackets, as they don’t accept conditions with the expressions. For example pl$DataFrame(iris)[Petal.Length &gt; 6] doesn’t work.\n\n\nThe second and best option is to use the filter() method. It must be used with the Polars expression, here the col() method which allows to designate the columns on which the filter condition will be applied.\nLet’s see in details what’s inside a filter() method with an example:\n\npl$col(\"Petal.Length\"): this expression selects the Petal.Length column from iris;\n\n&gt;6: applies a Boolean condition to this expression (for all Petals that have a length &gt; 6).\n\nIn the example below, we will use & operator to apply multiple conditions in filter() method:\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$filter(\n  pl$col(\"Petal.Length\") &gt; 6 & pl$col(\"Petal.Width\") &lt; 2)\n\nshape: (2, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬───────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species   │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---       │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat       │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═══════════╡\n│ 7.3          ┆ 2.9         ┆ 6.3          ┆ 1.8         ┆ virginica │\n│ 7.4          ┆ 2.8         ┆ 6.1          ┆ 1.9         ┆ virginica │\n└──────────────┴─────────────┴──────────────┴─────────────┴───────────┘\n\n\n\n\n\niris[iris$Petal.Length &gt; 6 & iris$Petal.Width &lt; 2,] # here don't forget the comma\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n108          7.3         2.9          6.3         1.8 virginica\n131          7.4         2.8          6.1         1.9 virginica\n\n\n\n\n\niris |&gt;\n  filter(Petal.Length &gt; 6 & Petal.Width &lt; 2) \n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1          7.3         2.9          6.3         1.8 virginica\n2          7.4         2.8          6.1         1.9 virginica\n\n\n\n\n\niris_dt[Petal.Length &gt; 6 & Petal.Width &lt; 2]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1:          7.3         2.9          6.3         1.8 virginica\n2:          7.4         2.8          6.1         1.9 virginica\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe equivalent of %in% R operator is the is_in() method. It should be used in association with the lit() method.\n\npl$DataFrame(\n  colA = pl$Series(c(\"a\",\"b\",\"c\"))\n  )$filter(\n  pl$col(\"colA\")$is_in(pl$lit(c(\"a\",\"b\")))\n  )\n\nshape: (2, 1)\n┌──────┐\n│ colA │\n│ ---  │\n│ str  │\n╞══════╡\n│ a    │\n│ b    │\n└──────┘\n\n\n\n\nAnother reason for using the filter() method is that filter expressions can be optimised in lazy mode by the query optimiser. Square brackets [] can only be used in eager mode.\n\n\n\n\n\n\nTip\n\n\n\nThere is another way to speed up filter processing on rows: tell polars that the column(s) used to filter rows are already sorted! To do this, you can use the set_sorted() method.\nHere’s an example:\n\nmydf &lt;- pl$DataFrame(\n  col1 = pl$Series(sort(runif(10000000)))\n)\n\nmicrobenchmark(\n  \"Without telling col1 is sorted\" = mydf$filter(pl$col(\"col1\") &lt; 100),\n  \"Telling col1 is sorted\" = mydf$with_columns(pl$col(\"col1\")$set_sorted())$filter(pl$col(\"col1\") &lt; 100)\n  )\n\nUnit: milliseconds\n                           expr     min       lq      mean   median       uq\n Without telling col1 is sorted 11.9505 12.15405 12.320508 12.29400 12.42920\n         Telling col1 is sorted  1.7911  1.89465  2.071015  1.99185  2.21435\n     max neval\n 13.0227   100\n  2.9795   100"
  },
  {
    "objectID": "data_manipulation.html#select-columns",
    "href": "data_manipulation.html#select-columns",
    "title": "2  Data manipulation",
    "section": "2.5 Select columns",
    "text": "2.5 Select columns\n\n2.5.1 Selecting by name\nThe first option for selecting columns of a DataFrame is to use square brackets [].\nThe second option is to use the select() method. In this case, it must be used with the col() method which allows to designate the columns to be selected.\n\npolarsR basedplyrdata.table\n\n\n\n# 1st option : with square brackets syntax\npl$DataFrame(iris)[1:3,c(\"Petal.Length\",\"Petal.Width\")] \n\nshape: (3, 2)\n┌──────────────┬─────────────┐\n│ Petal.Length ┆ Petal.Width │\n│ ---          ┆ ---         │\n│ f64          ┆ f64         │\n╞══════════════╪═════════════╡\n│ 1.4          ┆ 0.2         │\n│ 1.4          ┆ 0.2         │\n│ 1.3          ┆ 0.2         │\n└──────────────┴─────────────┘\n\n# 2nd option : with select() method\npl$DataFrame(iris)$select(\n  pl$col(c(\"Petal.Length\",\"Petal.Width\"))\n)$head(3) # display the first 3 lines\n\nshape: (3, 2)\n┌──────────────┬─────────────┐\n│ Petal.Length ┆ Petal.Width │\n│ ---          ┆ ---         │\n│ f64          ┆ f64         │\n╞══════════════╪═════════════╡\n│ 1.4          ┆ 0.2         │\n│ 1.4          ┆ 0.2         │\n│ 1.3          ┆ 0.2         │\n└──────────────┴─────────────┘\n\n\n\n\n\niris[1:3,c(\"Petal.Length\",\"Petal.Width\")] \n\n  Petal.Length Petal.Width\n1          1.4         0.2\n2          1.4         0.2\n3          1.3         0.2\n\n\n\n\n\niris |&gt;\n  select(Petal.Length,Petal.Width) |&gt;\n  head(3)\n\n  Petal.Length Petal.Width\n1          1.4         0.2\n2          1.4         0.2\n3          1.3         0.2\n\n\n\n\n\niris_dt[1:3,.(Petal.Length,Petal.Width)]\n\n   Petal.Length Petal.Width\n1:          1.4         0.2\n2:          1.4         0.2\n3:          1.3         0.2\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWith Polars if you want to obtain a result in an R data.frame, you can simply add the method to_data_frame() at the end of the method chaining.\n\n\n\n\n2.5.2 Selecting by data type\nTo select columns by data type from a DataFrame, you can pass a data type to pl$col expression. For example:\n\npolarsR basedplyrdata.table\n\n\n\n# Select only categorical columns\npl$DataFrame(iris)$select(pl$col(pl$Categorical))$head(3) \n\nshape: (3, 1)\n┌─────────┐\n│ Species │\n│ ---     │\n│ cat     │\n╞═════════╡\n│ setosa  │\n│ setosa  │\n│ setosa  │\n└─────────┘\n\n# Select only Float64 columns\npl$DataFrame(iris)$select(pl$col(pl$Float64))$head(3)\n\nshape: (3, 4)\n┌──────────────┬─────────────┬──────────────┬─────────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width │\n│ ---          ┆ ---         ┆ ---          ┆ ---         │\n│ f64          ┆ f64         ┆ f64          ┆ f64         │\n╞══════════════╪═════════════╪══════════════╪═════════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         │\n└──────────────┴─────────────┴──────────────┴─────────────┘\n\n\n\n\n\n# Select only factor columns\nas.data.frame(iris[1:3, sapply(iris, is.factor)])\n\n  iris[1:3, sapply(iris, is.factor)]\n1                             setosa\n2                             setosa\n3                             setosa\n\n# Select only numeric columns\niris[1:3, sapply(iris, is.numeric)]\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width\n1          5.1         3.5          1.4         0.2\n2          4.9         3.0          1.4         0.2\n3          4.7         3.2          1.3         0.2\n\n\n\n\n\n# Select only factor columns\niris %&gt;% \n  select_if(is.factor)\n\n       Species\n1       setosa\n2       setosa\n3       setosa\n4       setosa\n5       setosa\n6       setosa\n7       setosa\n8       setosa\n9       setosa\n10      setosa\n11      setosa\n12      setosa\n13      setosa\n14      setosa\n15      setosa\n16      setosa\n17      setosa\n18      setosa\n19      setosa\n20      setosa\n21      setosa\n22      setosa\n23      setosa\n24      setosa\n25      setosa\n26      setosa\n27      setosa\n28      setosa\n29      setosa\n30      setosa\n31      setosa\n32      setosa\n33      setosa\n34      setosa\n35      setosa\n36      setosa\n37      setosa\n38      setosa\n39      setosa\n40      setosa\n41      setosa\n42      setosa\n43      setosa\n44      setosa\n45      setosa\n46      setosa\n47      setosa\n48      setosa\n49      setosa\n50      setosa\n51  versicolor\n52  versicolor\n53  versicolor\n54  versicolor\n55  versicolor\n56  versicolor\n57  versicolor\n58  versicolor\n59  versicolor\n60  versicolor\n61  versicolor\n62  versicolor\n63  versicolor\n64  versicolor\n65  versicolor\n66  versicolor\n67  versicolor\n68  versicolor\n69  versicolor\n70  versicolor\n71  versicolor\n72  versicolor\n73  versicolor\n74  versicolor\n75  versicolor\n76  versicolor\n77  versicolor\n78  versicolor\n79  versicolor\n80  versicolor\n81  versicolor\n82  versicolor\n83  versicolor\n84  versicolor\n85  versicolor\n86  versicolor\n87  versicolor\n88  versicolor\n89  versicolor\n90  versicolor\n91  versicolor\n92  versicolor\n93  versicolor\n94  versicolor\n95  versicolor\n96  versicolor\n97  versicolor\n98  versicolor\n99  versicolor\n100 versicolor\n101  virginica\n102  virginica\n103  virginica\n104  virginica\n105  virginica\n106  virginica\n107  virginica\n108  virginica\n109  virginica\n110  virginica\n111  virginica\n112  virginica\n113  virginica\n114  virginica\n115  virginica\n116  virginica\n117  virginica\n118  virginica\n119  virginica\n120  virginica\n121  virginica\n122  virginica\n123  virginica\n124  virginica\n125  virginica\n126  virginica\n127  virginica\n128  virginica\n129  virginica\n130  virginica\n131  virginica\n132  virginica\n133  virginica\n134  virginica\n135  virginica\n136  virginica\n137  virginica\n138  virginica\n139  virginica\n140  virginica\n141  virginica\n142  virginica\n143  virginica\n144  virginica\n145  virginica\n146  virginica\n147  virginica\n148  virginica\n149  virginica\n150  virginica\n\n# Select only numeric columns\niris %&gt;% \n  select_if(is.numeric)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width\n1            5.1         3.5          1.4         0.2\n2            4.9         3.0          1.4         0.2\n3            4.7         3.2          1.3         0.2\n4            4.6         3.1          1.5         0.2\n5            5.0         3.6          1.4         0.2\n6            5.4         3.9          1.7         0.4\n7            4.6         3.4          1.4         0.3\n8            5.0         3.4          1.5         0.2\n9            4.4         2.9          1.4         0.2\n10           4.9         3.1          1.5         0.1\n11           5.4         3.7          1.5         0.2\n12           4.8         3.4          1.6         0.2\n13           4.8         3.0          1.4         0.1\n14           4.3         3.0          1.1         0.1\n15           5.8         4.0          1.2         0.2\n16           5.7         4.4          1.5         0.4\n17           5.4         3.9          1.3         0.4\n18           5.1         3.5          1.4         0.3\n19           5.7         3.8          1.7         0.3\n20           5.1         3.8          1.5         0.3\n21           5.4         3.4          1.7         0.2\n22           5.1         3.7          1.5         0.4\n23           4.6         3.6          1.0         0.2\n24           5.1         3.3          1.7         0.5\n25           4.8         3.4          1.9         0.2\n26           5.0         3.0          1.6         0.2\n27           5.0         3.4          1.6         0.4\n28           5.2         3.5          1.5         0.2\n29           5.2         3.4          1.4         0.2\n30           4.7         3.2          1.6         0.2\n31           4.8         3.1          1.6         0.2\n32           5.4         3.4          1.5         0.4\n33           5.2         4.1          1.5         0.1\n34           5.5         4.2          1.4         0.2\n35           4.9         3.1          1.5         0.2\n36           5.0         3.2          1.2         0.2\n37           5.5         3.5          1.3         0.2\n38           4.9         3.6          1.4         0.1\n39           4.4         3.0          1.3         0.2\n40           5.1         3.4          1.5         0.2\n41           5.0         3.5          1.3         0.3\n42           4.5         2.3          1.3         0.3\n43           4.4         3.2          1.3         0.2\n44           5.0         3.5          1.6         0.6\n45           5.1         3.8          1.9         0.4\n46           4.8         3.0          1.4         0.3\n47           5.1         3.8          1.6         0.2\n48           4.6         3.2          1.4         0.2\n49           5.3         3.7          1.5         0.2\n50           5.0         3.3          1.4         0.2\n51           7.0         3.2          4.7         1.4\n52           6.4         3.2          4.5         1.5\n53           6.9         3.1          4.9         1.5\n54           5.5         2.3          4.0         1.3\n55           6.5         2.8          4.6         1.5\n56           5.7         2.8          4.5         1.3\n57           6.3         3.3          4.7         1.6\n58           4.9         2.4          3.3         1.0\n59           6.6         2.9          4.6         1.3\n60           5.2         2.7          3.9         1.4\n61           5.0         2.0          3.5         1.0\n62           5.9         3.0          4.2         1.5\n63           6.0         2.2          4.0         1.0\n64           6.1         2.9          4.7         1.4\n65           5.6         2.9          3.6         1.3\n66           6.7         3.1          4.4         1.4\n67           5.6         3.0          4.5         1.5\n68           5.8         2.7          4.1         1.0\n69           6.2         2.2          4.5         1.5\n70           5.6         2.5          3.9         1.1\n71           5.9         3.2          4.8         1.8\n72           6.1         2.8          4.0         1.3\n73           6.3         2.5          4.9         1.5\n74           6.1         2.8          4.7         1.2\n75           6.4         2.9          4.3         1.3\n76           6.6         3.0          4.4         1.4\n77           6.8         2.8          4.8         1.4\n78           6.7         3.0          5.0         1.7\n79           6.0         2.9          4.5         1.5\n80           5.7         2.6          3.5         1.0\n81           5.5         2.4          3.8         1.1\n82           5.5         2.4          3.7         1.0\n83           5.8         2.7          3.9         1.2\n84           6.0         2.7          5.1         1.6\n85           5.4         3.0          4.5         1.5\n86           6.0         3.4          4.5         1.6\n87           6.7         3.1          4.7         1.5\n88           6.3         2.3          4.4         1.3\n89           5.6         3.0          4.1         1.3\n90           5.5         2.5          4.0         1.3\n91           5.5         2.6          4.4         1.2\n92           6.1         3.0          4.6         1.4\n93           5.8         2.6          4.0         1.2\n94           5.0         2.3          3.3         1.0\n95           5.6         2.7          4.2         1.3\n96           5.7         3.0          4.2         1.2\n97           5.7         2.9          4.2         1.3\n98           6.2         2.9          4.3         1.3\n99           5.1         2.5          3.0         1.1\n100          5.7         2.8          4.1         1.3\n101          6.3         3.3          6.0         2.5\n102          5.8         2.7          5.1         1.9\n103          7.1         3.0          5.9         2.1\n104          6.3         2.9          5.6         1.8\n105          6.5         3.0          5.8         2.2\n106          7.6         3.0          6.6         2.1\n107          4.9         2.5          4.5         1.7\n108          7.3         2.9          6.3         1.8\n109          6.7         2.5          5.8         1.8\n110          7.2         3.6          6.1         2.5\n111          6.5         3.2          5.1         2.0\n112          6.4         2.7          5.3         1.9\n113          6.8         3.0          5.5         2.1\n114          5.7         2.5          5.0         2.0\n115          5.8         2.8          5.1         2.4\n116          6.4         3.2          5.3         2.3\n117          6.5         3.0          5.5         1.8\n118          7.7         3.8          6.7         2.2\n119          7.7         2.6          6.9         2.3\n120          6.0         2.2          5.0         1.5\n121          6.9         3.2          5.7         2.3\n122          5.6         2.8          4.9         2.0\n123          7.7         2.8          6.7         2.0\n124          6.3         2.7          4.9         1.8\n125          6.7         3.3          5.7         2.1\n126          7.2         3.2          6.0         1.8\n127          6.2         2.8          4.8         1.8\n128          6.1         3.0          4.9         1.8\n129          6.4         2.8          5.6         2.1\n130          7.2         3.0          5.8         1.6\n131          7.4         2.8          6.1         1.9\n132          7.9         3.8          6.4         2.0\n133          6.4         2.8          5.6         2.2\n134          6.3         2.8          5.1         1.5\n135          6.1         2.6          5.6         1.4\n136          7.7         3.0          6.1         2.3\n137          6.3         3.4          5.6         2.4\n138          6.4         3.1          5.5         1.8\n139          6.0         3.0          4.8         1.8\n140          6.9         3.1          5.4         2.1\n141          6.7         3.1          5.6         2.4\n142          6.9         3.1          5.1         2.3\n143          5.8         2.7          5.1         1.9\n144          6.8         3.2          5.9         2.3\n145          6.7         3.3          5.7         2.5\n146          6.7         3.0          5.2         2.3\n147          6.3         2.5          5.0         1.9\n148          6.5         3.0          5.2         2.0\n149          6.2         3.4          5.4         2.3\n150          5.9         3.0          5.1         1.8\n\n\n\n\n\n# Select only factor columns\niris_dt[, .SD, .SDcols = is.factor]\n\n       Species\n  1:    setosa\n  2:    setosa\n  3:    setosa\n  4:    setosa\n  5:    setosa\n ---          \n146: virginica\n147: virginica\n148: virginica\n149: virginica\n150: virginica\n\n# Select only numeric columns\niris_dt[, .SD, .SDcols = is.numeric]\n\n     Sepal.Length Sepal.Width Petal.Length Petal.Width\n  1:          5.1         3.5          1.4         0.2\n  2:          4.9         3.0          1.4         0.2\n  3:          4.7         3.2          1.3         0.2\n  4:          4.6         3.1          1.5         0.2\n  5:          5.0         3.6          1.4         0.2\n ---                                                  \n146:          6.7         3.0          5.2         2.3\n147:          6.3         2.5          5.0         1.9\n148:          6.5         3.0          5.2         2.0\n149:          6.2         3.4          5.4         2.3\n150:          5.9         3.0          5.1         1.8\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also select columns from a DataFrame using a name pattern. See an example by removing a column\n\n\n\n\n2.5.3 Selecting using lists\nIt is also possible to select columns using R lists which can be very practical depending on the case. Here’s an example:\n\ndata(iris)\n\nl_expr = list(\n  pl$col(\"Petal.Length\"),\n  pl$col(\"Species\")\n)\n\n# Select only categorical columns\npl$DataFrame(iris)$select(l_expr)$head(3) \n\nshape: (3, 2)\n┌──────────────┬─────────┐\n│ Petal.Length ┆ Species │\n│ ---          ┆ ---     │\n│ f64          ┆ cat     │\n╞══════════════╪═════════╡\n│ 1.4          ┆ setosa  │\n│ 1.4          ┆ setosa  │\n│ 1.3          ┆ setosa  │\n└──────────────┴─────────┘\n\n\nThis way of selecting columns also works with simple R lists:\n\ndata(iris)\n\nl_expr = list(\n  \"Petal.Length\",\n  \"Species\",\n  \"Petal.Width\"\n)\n\n# Select only categorical columns\npl$DataFrame(iris)$select(l_expr)$head(3) \n\nshape: (3, 3)\n┌──────────────┬─────────┬─────────────┐\n│ Petal.Length ┆ Species ┆ Petal.Width │\n│ ---          ┆ ---     ┆ ---         │\n│ f64          ┆ cat     ┆ f64         │\n╞══════════════╪═════════╪═════════════╡\n│ 1.4          ┆ setosa  ┆ 0.2         │\n│ 1.4          ┆ setosa  ┆ 0.2         │\n│ 1.3          ┆ setosa  ┆ 0.2         │\n└──────────────┴─────────┴─────────────┘"
  },
  {
    "objectID": "data_manipulation.html#modifyadd-columns",
    "href": "data_manipulation.html#modifyadd-columns",
    "title": "2  Data manipulation",
    "section": "2.6 Modify/Add columns",
    "text": "2.6 Modify/Add columns\n\n2.6.1 Modify existing column\nSimilar to the dplyr package, the select() method can also be used to modify existing data. However, the result will exclude any columns that were not specified in the expression.\nFor example, if we want to get in the data.frame iris the Petal.Length column rounded without decimals.\n\npl$DataFrame(iris)$select(\n  pl$col(\"Petal.Length\")$round(decimals = 0)\n)$head(3) # display the first 3 lines\n\nshape: (3, 1)\n┌──────────────┐\n│ Petal.Length │\n│ ---          │\n│ f64          │\n╞══════════════╡\n│ 1.0          │\n│ 1.0          │\n│ 1.0          │\n└──────────────┘\n\n\nThe problem here is that we would like to keep all the iris columns and not just Petal.Length.\nAgain, let’s look at the official documentation:\n\nTo modify or add some columns—whilst preserving all others in the dataset—it is therefore better to use the with_columns() method.\n\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$with_columns(\n  pl$col(\"Petal.Length\")$round(decimals = 0)\n)$head(3) # display the first 3 lines\n\nshape: (3, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╡\n│ 5.1          ┆ 3.5         ┆ 1.0          ┆ 0.2         ┆ setosa  │\n│ 4.9          ┆ 3.0         ┆ 1.0          ┆ 0.2         ┆ setosa  │\n│ 4.7          ┆ 3.2         ┆ 1.0          ┆ 0.2         ┆ setosa  │\n└──────────────┴─────────────┴──────────────┴─────────────┴─────────┘\n\n\n\n\n\niris$Petal.Length &lt;- round(iris$Petal.Length, digits = 0)\niris[1:3,]\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5            1         0.2  setosa\n2          4.9         3.0            1         0.2  setosa\n3          4.7         3.2            1         0.2  setosa\n\n\n\n\n\ndata(iris)\niris |&gt;\n  mutate(Petal.Length = round(Petal.Length,0)) |&gt;\n  head(3)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5            1         0.2  setosa\n2          4.9         3.0            1         0.2  setosa\n3          4.7         3.2            1         0.2  setosa\n\n\n\n\n\niris_dt[,Petal.Length := round(Petal.Length, digits = 0)]\niris_dt[1:3,]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1:          5.1         3.5            1         0.2  setosa\n2:          4.9         3.0            1         0.2  setosa\n3:          4.7         3.2            1         0.2  setosa\n\n\n\n\n\n\n\n2.6.2 Add a new column\nIf you want to add a column to a data.frame, you use the same syntax as above with with_columns(). Simply use the alias() method to specify the name of the newly created column.\n\npl$DataFrame(iris)$with_columns(\n  pl$col(\"Petal.Length\")$round(decimals = 0)$alias(\"Petal.Length.rounded\")\n)$head(3) # display the first 3 lines\n\nshape: (3, 6)\n┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┬──────────────────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species ┆ Petal.Length.rounded │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     ┆ ---                  │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     ┆ f64                  │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╪══════════════════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa  ┆ 1.0                  │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa  ┆ 1.0                  │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa  ┆ 1.0                  │\n└──────────────┴─────────────┴──────────────┴─────────────┴─────────┴──────────────────────┘\n\n\n\n\n2.6.3 Add a new column with a constant value\nIf you need to create a new column with a constant value (i.e. the same value for all the rows in your DataFrame), you can use the literal lit() method. It works with the main types of Polars.\n\npl$DataFrame(iris)$with_columns(\n  pl$lit(\"toto\")$alias(\"mynewcolumn\")\n)$head(3) # display the first 3 lines\n\nshape: (3, 6)\n┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┬─────────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species ┆ mynewcolumn │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     ┆ ---         │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     ┆ str         │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╪═════════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa  ┆ toto        │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa  ┆ toto        │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa  ┆ toto        │\n└──────────────┴─────────────┴──────────────┴─────────────┴─────────┴─────────────┘\n\n\n\n\n2.6.4 Add a new column based on conditions\nTo add new columns based on conditions, the when-then-otherwise expression must be used.\nHere’s an example with equivalent syntax to help you understand:\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$with_columns(\n  pl$when(pl$col(\"Petal.Length\") &lt;= 2)$then(\"&lt;=2\")$\n    when(pl$col(\"Petal.Length\") &lt;= 5)$then(\"&lt;=5\")$\n    otherwise(\"&gt;5\")$alias(\"mygroups\")\n# we only need to display 2 variables to check that it's OK\n)$select(\n  pl$col(c(\"Petal.Length\",\"mygroups\"))\n)[c(1,2,59,150)]\n\nshape: (4, 2)\n┌──────────────┬──────────┐\n│ Petal.Length ┆ mygroups │\n│ ---          ┆ ---      │\n│ f64          ┆ str      │\n╞══════════════╪══════════╡\n│ 1.4          ┆ &lt;=2      │\n│ 1.4          ┆ &lt;=2      │\n│ 4.6          ┆ &lt;=5      │\n│ 5.1          ┆ &gt;5       │\n└──────────────┴──────────┘\n\n\n\n\n\niris$mygroups &lt;- ifelse(iris$Petal.Length &lt;= 2, \"&lt;=2\",\n                        ifelse(iris$Petal.Length &lt;= 5, \"&lt;=5\", \"&gt;5\"))\n# we only need to display 2 variables to check that it's OK\niris[c(1,2,59,150), c(\"Petal.Length\", \"mygroups\")]\n\n    Petal.Length mygroups\n1            1.4      &lt;=2\n2            1.4      &lt;=2\n59           4.6      &lt;=5\n150          5.1       &gt;5\n\n\n\n\n\niris |&gt;\n  mutate(\n    mygroups = case_when(\n      Petal.Length &lt;=2 ~ \"&lt;=2\",\n      Petal.Length &lt;=5 ~ \"&lt;=5\",\n      .default = \"&gt;5\")\n  ) |&gt;\n  # we only need to display 2 variables  to check that it's OK\n  select(Petal.Length,mygroups) |&gt;\n  slice(1,2,59,150)\n\n  Petal.Length mygroups\n1          1.4      &lt;=2\n2          1.4      &lt;=2\n3          4.6      &lt;=5\n4          5.1       &gt;5\n\n\n\n\n\niris_dt[, mygroups := case_when(\n  Petal.Length &lt;= 2 ~ \"&lt;=2\",\n  Petal.Length &lt;= 5 ~ \"&lt;=5\",\n  TRUE ~ \"&gt;5\"\n)]\n# we only need to display 2 variables to check that it's OK\niris_dt[c(1,2,59,150), .(Petal.Length, mygroups)]\n\n   Petal.Length mygroups\n1:            1      &lt;=2\n2:            1      &lt;=2\n3:            5      &lt;=5\n4:            5      &lt;=5\n\n\n\n\n\n\n\n2.6.5 Add a new column by group\nTo add new columns by group, the over expression must be used.\nThis expression is similar to performing a groupby aggregation and joining the result back into the original dataframe.\nHere’s an example with equivalent syntax to help you understand:\n\ndf &lt;- data.frame(\n  name = c(\"X\",\"X\",\"Y\",\"Y\",\"Z\",\"Z\"),\n  adress = c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"),\n  col2 = c(2L,4L,1L,3L,4L,2L),\n  col3 = c(5L,19L,17L,12L,11L,15L)\n)\ndf\n\n  name adress col2 col3\n1    X      A    2    5\n2    X      B    4   19\n3    Y      C    1   17\n4    Y      D    3   12\n5    Z      E    4   11\n6    Z      F    2   15\n\n\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(df)$with_columns(\n  pl$col(\"col3\")$max()$over(\"name\")$suffix(\"_max\")\n)\n\nshape: (6, 5)\n┌──────┬────────┬──────┬──────┬──────────┐\n│ name ┆ adress ┆ col2 ┆ col3 ┆ col3_max │\n│ ---  ┆ ---    ┆ ---  ┆ ---  ┆ ---      │\n│ str  ┆ str    ┆ i32  ┆ i32  ┆ i32      │\n╞══════╪════════╪══════╪══════╪══════════╡\n│ X    ┆ A      ┆ 2    ┆ 5    ┆ 19       │\n│ X    ┆ B      ┆ 4    ┆ 19   ┆ 19       │\n│ Y    ┆ C      ┆ 1    ┆ 17   ┆ 17       │\n│ Y    ┆ D      ┆ 3    ┆ 12   ┆ 17       │\n│ Z    ┆ E      ┆ 4    ┆ 11   ┆ 15       │\n│ Z    ┆ F      ┆ 2    ┆ 15   ┆ 15       │\n└──────┴────────┴──────┴──────┴──────────┘\n\n\n\n\n\nresult &lt;- aggregate(col3 ~ name, data = df, FUN = max)\ncolnames(result) &lt;- c(\"name\", \"col3_max\")\nmerge(df, result, by = \"name\", all.x = TRUE)\n\n  name adress col2 col3 col3_max\n1    X      A    2    5       19\n2    X      B    4   19       19\n3    Y      C    1   17       17\n4    Y      D    3   12       17\n5    Z      E    4   11       15\n6    Z      F    2   15       15\n\n\n\n\n\ndf |&gt;\n  group_by(name) |&gt; \n  mutate(col3_max = max(col3))\n\n# A tibble: 6 × 5\n# Groups:   name [3]\n  name  adress  col2  col3 col3_max\n  &lt;chr&gt; &lt;chr&gt;  &lt;int&gt; &lt;int&gt;    &lt;int&gt;\n1 X     A          2     5       19\n2 X     B          4    19       19\n3 Y     C          1    17       17\n4 Y     D          3    12       17\n5 Z     E          4    11       15\n6 Z     F          2    15       15\n\n\n\n\n\ndt &lt;- as.data.table(df)\ndt[, col3_max := max(col3), by = name]\ndt\n\n   name adress col2 col3 col3_max\n1:    X      A    2    5       19\n2:    X      B    4   19       19\n3:    Y      C    1   17       17\n4:    Y      D    3   12       17\n5:    Z      E    4   11       15\n6:    Z      F    2   15       15\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you need to pass multiple column names in the over expression, you can either list them like this over(\"name\",\"adress\") or - more conveniently - use a character vector over(c(\"name\",\"adress\"))."
  },
  {
    "objectID": "data_manipulation.html#rename-columns-1",
    "href": "data_manipulation.html#rename-columns-1",
    "title": "2  Data manipulation",
    "section": "2.7 Rename columns",
    "text": "2.7 Rename columns\n\n2.7.1 Selecting by name\nSimilar to the dplyr package, the rename() method can also be used to rename existing column.\nThe renaming logic is identical to that of dplyr, and is performed as follows: new_name=\"old_name\".\n\n\n\n\n\n\nNote\n\n\n\nNote the double quotes \"\" surrounding the name of the old variable to be renamed which does not exist with dplyr (see examples below).\n\n\n\npolarsR basedplyrdata.table\n\n\n\ndata(iris)\npl$DataFrame(iris)$\n  rename(\n    sepal_length = \"Sepal.Length\", \n    sepal_width = \"Sepal.Width\",\n    `length of petal` = \"Petal.Length\",\n    `width of petal` = \"Petal.Width\",\n    species = \"Species\"\n  )$columns\n\n[1] \"sepal_length\"    \"sepal_width\"     \"length of petal\" \"width of petal\" \n[5] \"species\"        \n\n\n\n\n\ndata(iris)\nnames(iris) &lt;- c(\"sepal_length\",\"sepal_width\",\"length of petal\",\"width of petal\",\"species\")\nnames(iris)\n\n[1] \"sepal_length\"    \"sepal_width\"     \"length of petal\" \"width of petal\" \n[5] \"species\"        \n\n\n\n\n\ndata(iris)\niris |&gt;\n  rename(\n    sepal_length = Sepal.Length, \n    sepal_width = Sepal.Width,\n    `length of petal` = Petal.Length,\n    `width of petal` = Petal.Width,\n    species = Species\n  ) |&gt;\n  names()\n\n[1] \"sepal_length\"    \"sepal_width\"     \"length of petal\" \"width of petal\" \n[5] \"species\"        \n\n\n\n\n\nsetnames(iris_dt, \n         old = c(\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\", \"Species\"),\n         new = c(\"sepal_length\", \"sepal_width\", \"length_of_petal\", \"width_of_petal\", \"species\"))\nnames(iris_dt)\n\n[1] \"sepal_length\"    \"sepal_width\"     \"length_of_petal\" \"width_of_petal\" \n[5] \"species\"         \"mygroups\""
  },
  {
    "objectID": "data_manipulation.html#remove-columns",
    "href": "data_manipulation.html#remove-columns",
    "title": "2  Data manipulation",
    "section": "2.8 Remove columns",
    "text": "2.8 Remove columns\n\n2.8.1 Removing by name\nTo remove columns from a DataFrame, the drop method must be used.\nHere’s an example with equivalent syntax:\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$\n  drop(c(\"Petal.Width\",\"Sepal.Length\",\"Sepal.Width\"))$\n  head(3)\n\nshape: (3, 2)\n┌──────────────┬─────────┐\n│ Petal.Length ┆ Species │\n│ ---          ┆ ---     │\n│ f64          ┆ cat     │\n╞══════════════╪═════════╡\n│ 1.4          ┆ setosa  │\n│ 1.4          ┆ setosa  │\n│ 1.3          ┆ setosa  │\n└──────────────┴─────────┘\n\n\n\n\n\niris[1:3,!(names(iris) %in% c(\"Petal.Width\",\"Sepal.Length\",\"Sepal.Width\"))]\n\n  Petal.Length Species\n1          1.4  setosa\n2          1.4  setosa\n3          1.3  setosa\n\n\n\n\n\niris |&gt;\n  select(-c(Petal.Width,Sepal.Length,Sepal.Width)) |&gt;\n  head(3)\n\n  Petal.Length Species\n1          1.4  setosa\n2          1.4  setosa\n3          1.3  setosa\n\n\n\n\n\niris_dt[, c(\"Petal.Width\",\"Sepal.Length\",\"Sepal.Width\") := NULL][1:3,]\n\n   Petal.Length Species\n1:          1.4  setosa\n2:          1.4  setosa\n3:          1.3  setosa\n\n\n\n\n\n\n\n2.8.2 Removing by name pattern\nTo remove columns by name pattern from a DataFrame, the drop expression must be used.\nLet’s see an example where you want to drop columns whose names starts with “Petal” in iris.\n\npolarsR basedplyrdata.table\n\n\n\nnum_to_drop &lt;- !grepl(\"^Petal\",pl$DataFrame(iris)$columns)\ncol_to_drop &lt;- pl$DataFrame(iris)$columns[num_to_drop]\n\npl$DataFrame(iris)$\n  drop(col_to_drop)$\n  head(3)\n\nshape: (3, 2)\n┌──────────────┬─────────────┐\n│ Petal.Length ┆ Petal.Width │\n│ ---          ┆ ---         │\n│ f64          ┆ f64         │\n╞══════════════╪═════════════╡\n│ 1.4          ┆ 0.2         │\n│ 1.4          ┆ 0.2         │\n│ 1.3          ┆ 0.2         │\n└──────────────┴─────────────┘\n\n\n\n\n\niris[1:3,!grepl(\"^Petal\",names(iris))]\n\n  Sepal.Length Sepal.Width Species\n1          5.1         3.5  setosa\n2          4.9         3.0  setosa\n3          4.7         3.2  setosa\n\n\n\n\n\niris |&gt;\n  select(-starts_with(\"Petal\")) |&gt;\n  head(3)\n\n  Sepal.Length Sepal.Width Species\n1          5.1         3.5  setosa\n2          4.9         3.0  setosa\n3          4.7         3.2  setosa\n\n\n\n\n\niris_dt[, which(grepl(\"^Petal$\", names(iris_dt))):=NULL][1:3,]\n\n   Petal.Length Species\n1:          1.4  setosa\n2:          1.4  setosa\n3:          1.3  setosa"
  },
  {
    "objectID": "data_manipulation.html#aggregation-by-group",
    "href": "data_manipulation.html#aggregation-by-group",
    "title": "2  Data manipulation",
    "section": "2.9 Aggregation by group",
    "text": "2.9 Aggregation by group\nAnother frequently used data manipulation is the aggregation of data by group. To do this, we indicate in the group_by() method which column will be used to group the data.frame. And the agg() method which specifies the expression to aggregate.\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$\n  groupby(\"Species\")$\n  agg(pl$col(c(\"Petal.Length\",\"Petal.Width\"))$sum())\n\nshape: (3, 3)\n┌────────────┬──────────────┬─────────────┐\n│ Species    ┆ Petal.Length ┆ Petal.Width │\n│ ---        ┆ ---          ┆ ---         │\n│ cat        ┆ f64          ┆ f64         │\n╞════════════╪══════════════╪═════════════╡\n│ setosa     ┆ 73.1         ┆ 12.3        │\n│ versicolor ┆ 213.0        ┆ 66.3        │\n│ virginica  ┆ 277.6        ┆ 101.3       │\n└────────────┴──────────────┴─────────────┘\n\n\n\n\n\naggregate(cbind(Petal.Length, Petal.Width) ~ Species, data = iris, FUN = sum)\n\n     Species Petal.Length Petal.Width\n1     setosa         73.1        12.3\n2 versicolor        213.0        66.3\n3  virginica        277.6       101.3\n\n\n\n\n\ndata(iris)\niris |&gt;\n  group_by(Species) |&gt;\n  summarise(across(c(Petal.Length, Petal.Width), sum)) \n\n# A tibble: 3 × 3\n  Species    Petal.Length Petal.Width\n  &lt;fct&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 setosa             73.1        12.3\n2 versicolor        213          66.3\n3 virginica         278.        101. \n\n\n\n\n\niris_dt &lt;- as.data.table(iris)\niris_dt[, .(Petal.Length = sum(Petal.Length), Petal.Width = sum(Petal.Width)), by = Species]\n\n      Species Petal.Length Petal.Width\n1:     setosa         73.1        12.3\n2: versicolor        213.0        66.3\n3:  virginica        277.6       101.3"
  },
  {
    "objectID": "data_manipulation.html#sort-a-dataframe",
    "href": "data_manipulation.html#sort-a-dataframe",
    "title": "2  Data manipulation",
    "section": "2.10 Sort a DataFrame",
    "text": "2.10 Sort a DataFrame\n\n2.10.1 Simply sort a DataFrame\nThe sort() method can be used to sort a DataFrame.\n\npolarsR basedplyrdata.table\n\n\n\n# Sort by one column\npl$DataFrame(iris)$\n  sort(\"Species\")$\n  head(3)\n\nshape: (3, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa  │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa  │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa  │\n└──────────────┴─────────────┴──────────────┴─────────────┴─────────┘\n\n# Sort by two columns\npl$DataFrame(iris)$\n  sort(c(\"Species\",\"Petal.Length\"))$\n  head(3)\n\nshape: (3, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╡\n│ 4.6          ┆ 3.6         ┆ 1.0          ┆ 0.2         ┆ setosa  │\n│ 4.3          ┆ 3.0         ┆ 1.1          ┆ 0.1         ┆ setosa  │\n│ 5.8          ┆ 4.0         ┆ 1.2          ┆ 0.2         ┆ setosa  │\n└──────────────┴─────────────┴──────────────┴─────────────┴─────────┘\n\n# Sort by two columns one in a decreasing manner and the other in an increasing manner\npl$DataFrame(iris)$\n  sort(c(\"Species\",\"Petal.Length\"), descending = c(TRUE,FALSE))$\n  head(3)\n\nshape: (3, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬───────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species   │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---       │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat       │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═══════════╡\n│ 4.9          ┆ 2.5         ┆ 4.5          ┆ 1.7         ┆ virginica │\n│ 6.2          ┆ 2.8         ┆ 4.8          ┆ 1.8         ┆ virginica │\n│ 6.0          ┆ 3.0         ┆ 4.8          ┆ 1.8         ┆ virginica │\n└──────────────┴─────────────┴──────────────┴─────────────┴───────────┘\n\n\n\n\n\n# Sort by one column\niris[order(iris$Species),][1:3,]\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n\n# Sort by two columns\niris[order(iris$Species,iris$Petal.Length),][1:3,]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n23          4.6         3.6          1.0         0.2  setosa\n14          4.3         3.0          1.1         0.1  setosa\n15          5.8         4.0          1.2         0.2  setosa\n\n# Sort by two columns one in a decreasing manner and the other in an increasing manner\niris[order(rev(iris$Species),iris$Petal.Length),][1:3,]\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n107          4.9         2.5          4.5         1.7 virginica\n127          6.2         2.8          4.8         1.8 virginica\n139          6.0         3.0          4.8         1.8 virginica\n\n\n\n\n\n# Sort by one column\niris |&gt;\n  arrange(Species) |&gt;\n  head(3)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n\n# Sort by two columns\niris |&gt;\n  arrange(Species, Petal.Length) |&gt;\n  head(3)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          4.6         3.6          1.0         0.2  setosa\n2          4.3         3.0          1.1         0.1  setosa\n3          5.8         4.0          1.2         0.2  setosa\n\n# Sort by two columns one in a decreasing manner and the other in an increasing manner\niris |&gt;\n  arrange(desc(Species), Petal.Length) |&gt;\n  head(3)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1          4.9         2.5          4.5         1.7 virginica\n2          6.2         2.8          4.8         1.8 virginica\n3          6.0         3.0          4.8         1.8 virginica\n\n\n\n\n\n# Sort by one column\niris_dt[order(Species)][1:3,]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1:          5.1         3.5          1.4         0.2  setosa\n2:          4.9         3.0          1.4         0.2  setosa\n3:          4.7         3.2          1.3         0.2  setosa\n\n# Sort by two columns\niris_dt[order(Species,Petal.Length)][1:3,]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1:          4.6         3.6          1.0         0.2  setosa\n2:          4.3         3.0          1.1         0.1  setosa\n3:          5.8         4.0          1.2         0.2  setosa\n\n# Sort by two columns one in a decreasing manner and the other in an increasing manner\niris_dt[order(-Species,Petal.Length)][1:3,]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1:          4.9         2.5          4.5         1.7 virginica\n2:          6.2         2.8          4.8         1.8 virginica\n3:          6.0         3.0          4.8         1.8 virginica\n\n\n\n\n\n\n\n2.10.2 Keep unique rows\nIf you want to keep unique/distinct rows from a DataFrame, you can use the unique() method:\n\npolarsR basedplyrdata.table\n\n\n\n# With one column\npl$DataFrame(iris)$unique(\n  subset = \"Species\"\n)\n\nshape: (3, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬────────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species    │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---        │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat        │\n╞══════════════╪═════════════╪══════════════╪═════════════╪════════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa     │\n│ 7.0          ┆ 3.2         ┆ 4.7          ┆ 1.4         ┆ versicolor │\n│ 6.3          ┆ 3.3         ┆ 6.0          ┆ 2.5         ┆ virginica  │\n└──────────────┴─────────────┴──────────────┴─────────────┴────────────┘\n\n# With one column keeping last entry\npl$DataFrame(iris)$unique(\n  subset = \"Species\",\n  keep = \"last\"\n)\n\nshape: (3, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬────────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species    │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---        │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat        │\n╞══════════════╪═════════════╪══════════════╪═════════════╪════════════╡\n│ 5.0          ┆ 3.3         ┆ 1.4          ┆ 0.2         ┆ setosa     │\n│ 5.7          ┆ 2.8         ┆ 4.1          ┆ 1.3         ┆ versicolor │\n│ 5.9          ┆ 3.0         ┆ 5.1          ┆ 1.8         ┆ virginica  │\n└──────────────┴─────────────┴──────────────┴─────────────┴────────────┘\n\n# With two colums, keeping last entry and maintaining the same order\npl$DataFrame(\n  x = c(1L, 1:3, 3L),\n  y = c(1L, 1:3, 3L),\n  z = c(1L, 1:3, 4L)\n)$unique(\n  subset = c(\"x\",\"y\"),\n  keep = \"last\",\n  maintain_order = TRUE\n)\n\nshape: (3, 3)\n┌─────┬─────┬─────┐\n│ x   ┆ y   ┆ z   │\n│ --- ┆ --- ┆ --- │\n│ i32 ┆ i32 ┆ i32 │\n╞═════╪═════╪═════╡\n│ 1   ┆ 1   ┆ 1   │\n│ 2   ┆ 2   ┆ 2   │\n│ 3   ┆ 3   ┆ 4   │\n└─────┴─────┴─────┘\n\n\n\n\n\n# With one column\naggregate(. ~ Species, data = iris, FUN = head, N = 1)\n\n     Species Sepal.Length.1 Sepal.Length.2 Sepal.Length.3 Sepal.Length.4\n1     setosa            5.1            4.9            4.7            4.6\n2 versicolor            7.0            6.4            6.9            5.5\n3  virginica            6.3            5.8            7.1            6.3\n  Sepal.Length.5 Sepal.Length.6 Sepal.Width.1 Sepal.Width.2 Sepal.Width.3\n1            5.0            5.4           3.5           3.0           3.2\n2            6.5            5.7           3.2           3.2           3.1\n3            6.5            7.6           3.3           2.7           3.0\n  Sepal.Width.4 Sepal.Width.5 Sepal.Width.6 Petal.Length.1 Petal.Length.2\n1           3.1           3.6           3.9            1.4            1.4\n2           2.3           2.8           2.8            4.7            4.5\n3           2.9           3.0           3.0            6.0            5.1\n  Petal.Length.3 Petal.Length.4 Petal.Length.5 Petal.Length.6 Petal.Width.1\n1            1.3            1.5            1.4            1.7           0.2\n2            4.9            4.0            4.6            4.5           1.4\n3            5.9            5.6            5.8            6.6           2.5\n  Petal.Width.2 Petal.Width.3 Petal.Width.4 Petal.Width.5 Petal.Width.6\n1           0.2           0.2           0.2           0.2           0.4\n2           1.5           1.5           1.3           1.5           1.3\n3           1.9           2.1           1.8           2.2           2.1\n\n# With one column keeping last entry\naggregate(. ~ Species, data = iris, FUN = tail, n = 1)\n\n     Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n1     setosa          5.0         3.3          1.4         0.2\n2 versicolor          5.7         2.8          4.1         1.3\n3  virginica          5.9         3.0          5.1         1.8\n\n# With two colums, keeping last entry and maintaining the same order\nmytest &lt;- data.frame(\n  x = c(1L, 1:3, 3L),\n  y = c(1L, 1:3, 3L),\n  z = c(1L, 1:3, 4L)\n) \naggregate(. ~ x + y, data = mytest, FUN = tail, n = 1)\n\n  x y z\n1 1 1 1\n2 2 2 2\n3 3 3 4\n\n\n\n\n\n# With one column\niris |&gt;\n  distinct(Species, .keep_all = TRUE)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1          5.1         3.5          1.4         0.2     setosa\n2          7.0         3.2          4.7         1.4 versicolor\n3          6.3         3.3          6.0         2.5  virginica\n\n# With one column keeping last entry\niris |&gt;\n  group_by(Species) |&gt;\n  slice_tail() |&gt;\n  ungroup()\n\n# A tibble: 3 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;     \n1          5           3.3          1.4         0.2 setosa    \n2          5.7         2.8          4.1         1.3 versicolor\n3          5.9         3            5.1         1.8 virginica \n\n# With two colums, keeping last entry and maintaining the same order\ndata.frame(\n  x = c(1L, 1:3, 3L),\n  y = c(1L, 1:3, 3L),\n  z = c(1L, 1:3, 4L)\n) |&gt;\n  group_by(x,y) |&gt;\n  slice_tail() |&gt;\n  ungroup()\n\n# A tibble: 3 × 3\n      x     y     z\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     1     1\n2     2     2     2\n3     3     3     4\n\n\n\n\n\n# With one column\nunique(iris_dt, by = \"Species\")\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1:          5.1         3.5          1.4         0.2     setosa\n2:          7.0         3.2          4.7         1.4 versicolor\n3:          6.3         3.3          6.0         2.5  virginica\n\n# With one column keeping last entry\nunique(iris_dt, by = \"Species\", fromLast = TRUE)\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1:          5.0         3.3          1.4         0.2     setosa\n2:          5.7         2.8          4.1         1.3 versicolor\n3:          5.9         3.0          5.1         1.8  virginica\n\n# With two colums, keeping last entry and maintaining the same order\nmytest_dt &lt;- data.table(\n  x = c(1L, 1:3, 3L),\n  y = c(1L, 1:3, 3L),\n  z = c(1L, 1:3, 4L)\n) \nunique(mytest_dt, by = c(\"x\",\"y\"), fromLast = TRUE)\n\n   x y z\n1: 1 1 1\n2: 2 2 2\n3: 3 3 4\n\n\n\n\n\n\n\n2.10.3 Keep some columns from sorted DataFrame\nIf you want to keep only some columns from a sorted DataFrame, you can use the sort_by() method with the select() method.\nIn details, sort_by() can sort a column by the ordering of another column, or multiple other columns.\nIt’s the equivalent of order() method of R base.\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$\n  select(pl$col(\"Petal.Length\")$\n  sort_by(\"Petal.Width\"))\n\nshape: (150, 1)\n┌──────────────┐\n│ Petal.Length │\n│ ---          │\n│ f64          │\n╞══════════════╡\n│ 1.5          │\n│ 1.4          │\n│ 1.1          │\n│ 1.5          │\n│ …            │\n│ 5.6          │\n│ 6.0          │\n│ 6.1          │\n│ 5.7          │\n└──────────────┘\n\n\n\n\n\ndata(iris)\niris[order(iris$Petal.Width), \"Petal.Length\", drop = FALSE]\n\n    Petal.Length\n10           1.5\n13           1.4\n14           1.1\n33           1.5\n38           1.4\n1            1.4\n2            1.4\n3            1.3\n4            1.5\n5            1.4\n8            1.5\n9            1.4\n11           1.5\n12           1.6\n15           1.2\n21           1.7\n23           1.0\n25           1.9\n26           1.6\n28           1.5\n29           1.4\n30           1.6\n31           1.6\n34           1.4\n35           1.5\n36           1.2\n37           1.3\n39           1.3\n40           1.5\n43           1.3\n47           1.6\n48           1.4\n49           1.5\n50           1.4\n7            1.4\n18           1.4\n19           1.7\n20           1.5\n41           1.3\n42           1.3\n46           1.4\n6            1.7\n16           1.5\n17           1.3\n22           1.5\n27           1.6\n32           1.5\n45           1.9\n24           1.7\n44           1.6\n58           3.3\n61           3.5\n63           4.0\n68           4.1\n80           3.5\n82           3.7\n94           3.3\n70           3.9\n81           3.8\n99           3.0\n74           4.7\n83           3.9\n91           4.4\n93           4.0\n96           4.2\n54           4.0\n56           4.5\n59           4.6\n65           3.6\n72           4.0\n75           4.3\n88           4.4\n89           4.1\n90           4.0\n95           4.2\n97           4.2\n98           4.3\n100          4.1\n51           4.7\n60           3.9\n64           4.7\n66           4.4\n76           4.4\n77           4.8\n92           4.6\n135          5.6\n52           4.5\n53           4.9\n55           4.6\n62           4.2\n67           4.5\n69           4.5\n73           4.9\n79           4.5\n85           4.5\n87           4.7\n120          5.0\n134          5.1\n57           4.7\n84           5.1\n86           4.5\n130          5.8\n78           5.0\n107          4.5\n71           4.8\n104          5.6\n108          6.3\n109          5.8\n117          5.5\n124          4.9\n126          6.0\n127          4.8\n128          4.9\n138          5.5\n139          4.8\n150          5.1\n102          5.1\n112          5.3\n131          6.1\n143          5.1\n147          5.0\n111          5.1\n114          5.0\n122          4.9\n123          6.7\n132          6.4\n148          5.2\n103          5.9\n106          6.6\n113          5.5\n125          5.7\n129          5.6\n140          5.4\n105          5.8\n118          6.7\n133          5.6\n116          5.3\n119          6.9\n121          5.7\n136          6.1\n142          5.1\n144          5.9\n146          5.2\n149          5.4\n115          5.1\n137          5.6\n141          5.6\n101          6.0\n110          6.1\n145          5.7\n\n\n\n\n\ndata(iris)\niris |&gt;\n  arrange(Petal.Width) |&gt;\n  select(Petal.Length)\n\n    Petal.Length\n1            1.5\n2            1.4\n3            1.1\n4            1.5\n5            1.4\n6            1.4\n7            1.4\n8            1.3\n9            1.5\n10           1.4\n11           1.5\n12           1.4\n13           1.5\n14           1.6\n15           1.2\n16           1.7\n17           1.0\n18           1.9\n19           1.6\n20           1.5\n21           1.4\n22           1.6\n23           1.6\n24           1.4\n25           1.5\n26           1.2\n27           1.3\n28           1.3\n29           1.5\n30           1.3\n31           1.6\n32           1.4\n33           1.5\n34           1.4\n35           1.4\n36           1.4\n37           1.7\n38           1.5\n39           1.3\n40           1.3\n41           1.4\n42           1.7\n43           1.5\n44           1.3\n45           1.5\n46           1.6\n47           1.5\n48           1.9\n49           1.7\n50           1.6\n51           3.3\n52           3.5\n53           4.0\n54           4.1\n55           3.5\n56           3.7\n57           3.3\n58           3.9\n59           3.8\n60           3.0\n61           4.7\n62           3.9\n63           4.4\n64           4.0\n65           4.2\n66           4.0\n67           4.5\n68           4.6\n69           3.6\n70           4.0\n71           4.3\n72           4.4\n73           4.1\n74           4.0\n75           4.2\n76           4.2\n77           4.3\n78           4.1\n79           4.7\n80           3.9\n81           4.7\n82           4.4\n83           4.4\n84           4.8\n85           4.6\n86           5.6\n87           4.5\n88           4.9\n89           4.6\n90           4.2\n91           4.5\n92           4.5\n93           4.9\n94           4.5\n95           4.5\n96           4.7\n97           5.0\n98           5.1\n99           4.7\n100          5.1\n101          4.5\n102          5.8\n103          5.0\n104          4.5\n105          4.8\n106          5.6\n107          6.3\n108          5.8\n109          5.5\n110          4.9\n111          6.0\n112          4.8\n113          4.9\n114          5.5\n115          4.8\n116          5.1\n117          5.1\n118          5.3\n119          6.1\n120          5.1\n121          5.0\n122          5.1\n123          5.0\n124          4.9\n125          6.7\n126          6.4\n127          5.2\n128          5.9\n129          6.6\n130          5.5\n131          5.7\n132          5.6\n133          5.4\n134          5.8\n135          6.7\n136          5.6\n137          5.3\n138          6.9\n139          5.7\n140          6.1\n141          5.1\n142          5.9\n143          5.2\n144          5.4\n145          5.1\n146          5.6\n147          5.6\n148          6.0\n149          6.1\n150          5.7\n\n\n\n\n\ndata(iris)\niris_dt &lt;- as.data.table(iris)\niris_dt[order(Petal.Width)][,.(Petal.Length)]\n\n     Petal.Length\n  1:          1.5\n  2:          1.4\n  3:          1.1\n  4:          1.5\n  5:          1.4\n ---             \n146:          5.6\n147:          5.6\n148:          6.0\n149:          6.1\n150:          5.7\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to use multiple columns/expressions, you can pass it in a list like this for example sort_by(list(\"Petal.Width\",\"Sepal.Width\")) or sort_by(list(\"Petal.Width\", pl$col(\"Sepal.Width\")))"
  },
  {
    "objectID": "data_manipulation.html#join-dataframes",
    "href": "data_manipulation.html#join-dataframes",
    "title": "2  Data manipulation",
    "section": "2.11 Join DataFrames",
    "text": "2.11 Join DataFrames\nTo perform joins, the join() method must be used.\n\npolarsR basedplyrdata.table\n\n\n\n# First, creation of colors_species Polars DataFrame\ncolors &lt;- pl$DataFrame(\n  Surname = pl$Series(c(\"toto\",\"titi\",\"tata\")),\n  Color = pl$Series(c(\"blue\",\"red\",\"yellow\"))\n)\nvalues &lt;- pl$DataFrame(\n  Surname = pl$Series(c(\"toto\",\"titi\",\"tata\")),\n  value = pl$Series(c(10,20,30))\n)\n# Let's join !\ncolors$join(\n  other = values,\n  on = \"Surname\",\n  how = \"left\"\n)\n\nshape: (3, 3)\n┌─────────┬────────┬───────┐\n│ Surname ┆ Color  ┆ value │\n│ ---     ┆ ---    ┆ ---   │\n│ str     ┆ str    ┆ f64   │\n╞═════════╪════════╪═══════╡\n│ toto    ┆ blue   ┆ 10.0  │\n│ titi    ┆ red    ┆ 20.0  │\n│ tata    ┆ yellow ┆ 30.0  │\n└─────────┴────────┴───────┘\n\n\n\n\n\ncolors &lt;- data.frame(\n  Surname = c(\"toto\",\"titi\",\"tata\"),\n  Color = c(\"blue\",\"red\",\"yellow\")\n)\nvalues &lt;- data.frame(\n  Surname = c(\"toto\",\"titi\",\"tata\"),\n  value = c(10,20,30)\n)\nmerge(colors, values, by = \"Surname\", all.x = TRUE)\n\n  Surname  Color value\n1    tata yellow    30\n2    titi    red    20\n3    toto   blue    10\n\n\n\n\n\ncolors |&gt;\n  left_join(values,\n            by = \"Surname\") \n\n  Surname  Color value\n1    toto   blue    10\n2    titi    red    20\n3    tata yellow    30\n\n\n\n\n\nmerge(as.data.table(colors), \n      as.data.table(values), \n      by = \"Surname\", all.x = TRUE)\n\n   Surname  Color value\n1:    tata yellow    30\n2:    titi    red    20\n3:    toto   blue    10"
  },
  {
    "objectID": "data_manipulation.html#pivot-a-dataframe",
    "href": "data_manipulation.html#pivot-a-dataframe",
    "title": "2  Data manipulation",
    "section": "2.12 Pivot a DataFrame",
    "text": "2.12 Pivot a DataFrame\n\n2.12.1 From long to wide\nThe pivot() method can be used to pivot a DataFrame from long to wide.\nLet’s go for a first example :\n\ndf &lt;- data.frame(\n  country = c(rep(\"France\",3),rep(\"Italy\",\"3\")),\n  city = c(\"Paris\", \"Lille\", \"Nice\", \"Roma\", \"Milan\", \"Napoli\"),\n  location = c(\"North\",\"North\",\"South\",\"South\",\"North\",\"South\"),\n  population = c(2.1, 0.2, 0.4, 2.8, 1.4, 3.0)\n)\ndf\n\n  country   city location population\n1  France  Paris    North        2.1\n2  France  Lille    North        0.2\n3  France   Nice    South        0.4\n4   Italy   Roma    South        2.8\n5   Italy  Milan    North        1.4\n6   Italy Napoli    South        3.0\n\n\n\npolarsR basetidyrdata.table\n\n\n\npl$DataFrame(df)$pivot(\n  index = \"country\", \n  columns = \"city\",\n  values = \"population\", \n)\n\nshape: (2, 7)\n┌─────────┬───────┬───────┬──────┬──────┬───────┬────────┐\n│ country ┆ Paris ┆ Lille ┆ Nice ┆ Roma ┆ Milan ┆ Napoli │\n│ ---     ┆ ---   ┆ ---   ┆ ---  ┆ ---  ┆ ---   ┆ ---    │\n│ str     ┆ f64   ┆ f64   ┆ f64  ┆ f64  ┆ f64   ┆ f64    │\n╞═════════╪═══════╪═══════╪══════╪══════╪═══════╪════════╡\n│ France  ┆ 2.1   ┆ 0.2   ┆ 0.4  ┆ null ┆ null  ┆ null   │\n│ Italy   ┆ null  ┆ null  ┆ null ┆ 2.8  ┆ 1.4   ┆ 3.0    │\n└─────────┴───────┴───────┴──────┴──────┴───────┴────────┘\n\n\n\n\n\nreshape(df[,-which(names(df) %in% c(\"location\"))], \n        idvar = \"country\", \n        timevar = \"city\", \n        direction = \"wide\")\n\n  country population.Paris population.Lille population.Nice population.Roma\n1  France              2.1              0.2             0.4              NA\n4   Italy               NA               NA              NA             2.8\n  population.Milan population.Napoli\n1               NA                NA\n4              1.4                 3\n\n\n\n\n\ndf |&gt;\n  pivot_wider(\n    id_cols = country,\n    names_from = city,\n    values_from = population\n  )\n\n# A tibble: 2 × 7\n  country Paris Lille  Nice  Roma Milan Napoli\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 France    2.1   0.2   0.4  NA    NA       NA\n2 Italy    NA    NA    NA     2.8   1.4      3\n\n\n\n\n\ndf_dt &lt;- as.data.table(df)\ndcast(df_dt, country ~ city, value.var = \"population\")\n\n   country Lille Milan Napoli Nice Paris Roma\n1:  France   0.2    NA     NA  0.4   2.1   NA\n2:   Italy    NA   1.4      3   NA    NA  2.8\n\n\n\n\n\nYou can also aggregate the results using a function that you enter in the argument aggregate_function in pivot() method.\nIn this case, the aggregate_function argument of pivot() is the equivalent of values_fn of pivot_wider() from {tidyr} and fun.aggregate of dcast() from {data.table}.\n\npolarsR basetidyrdata.table\n\n\n\npl$DataFrame(df)$pivot(\n  index = \"country\", \n  columns = \"location\",\n  values = \"population\",\n  aggregate_function = \"mean\"\n)\n\nshape: (2, 3)\n┌─────────┬───────┬───────┐\n│ country ┆ North ┆ South │\n│ ---     ┆ ---   ┆ ---   │\n│ str     ┆ f64   ┆ f64   │\n╞═════════╪═══════╪═══════╡\n│ France  ┆ 1.15  ┆ 0.4   │\n│ Italy   ┆ 1.4   ┆ 2.9   │\n└─────────┴───────┴───────┘\n\n\n\n\n\ndf_summary &lt;- aggregate(population ~ country + location, data = df, FUN = mean)\ndf_final &lt;- reshape(df_summary, idvar = \"country\", timevar = \"location\", direction = \"wide\")\ncolnames(df_final) &lt;- c(\"country\", \"North\", \"South\")\ndf_final\n\n  country North South\n1  France  1.15   0.4\n2   Italy  1.40   2.9\n\n\n\n\n\ndf |&gt;\n  pivot_wider(id_cols = country,\n              names_from = location, \n              values_from = population, \n              values_fn = mean)\n\n# A tibble: 2 × 3\n  country North South\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 France   1.15   0.4\n2 Italy    1.4    2.9\n\n\n\n\n\ndf_dt &lt;- as.data.table(df)\ndcast(df_dt, country ~ location, value.var = \"population\", fun.aggregate = mean)\n\n   country North South\n1:  France  1.15   0.4\n2:   Italy  1.40   2.9\n\n\n\n\n\nHowever with {polars}, we can also run an expression as an aggregation function.\nWith {tidyr} and {data.table}, you need to calculate this in advance.\nFor example:\n\npolarsR basetidyrdata.table\n\n\n\npl$DataFrame(df)$pivot(\n  index = \"country\", \n  columns = \"location\",\n  values = \"population\",\n  aggregate_function = pl$element()$sum()$sqrt()\n)\n\nshape: (2, 3)\n┌─────────┬──────────┬──────────┐\n│ country ┆ North    ┆ South    │\n│ ---     ┆ ---      ┆ ---      │\n│ str     ┆ f64      ┆ f64      │\n╞═════════╪══════════╪══════════╡\n│ France  ┆ 1.516575 ┆ 0.632456 │\n│ Italy   ┆ 1.183216 ┆ 2.408319 │\n└─────────┴──────────┴──────────┘\n\n\n\n\n\ndf_summarized &lt;- aggregate(population ~ country + location, df, FUN = function(x) sqrt(sum(x)))\ndf_final &lt;- reshape(df_summarized, idvar = \"country\", timevar = \"location\", direction = \"wide\")\ncolnames(df_final) &lt;- c(\"country\", \"North\", \"South\")\ndf_final\n\n  country    North     South\n1  France 1.516575 0.6324555\n2   Italy 1.183216 2.4083189\n\n\n\n\n\ndf |&gt;\n  group_by(country, location) |&gt;\n  summarise(population_sum = sqrt(sum(population))) |&gt;\n  pivot_wider(names_from = location, values_from = population_sum)\n\n# A tibble: 2 × 3\n# Groups:   country [2]\n  country North South\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 France   1.52 0.632\n2 Italy    1.18 2.41 \n\n\n\n\n\ndt_final &lt;- df_dt[, .(population_sum = sqrt(sum(population))), by = .(country, location)]\ndcast(dt_final, country ~ location, value.var = \"population_sum\")\n\n   country    North     South\n1:  France 1.516575 0.6324555\n2:   Italy 1.183216 2.4083189\n\n\n\n\n\n\n\n2.12.2 From wide to long\nThe melt() method can be used to pivot a DataFrame from wide to long.\nLet’s see with an example :\n\ndf &lt;- data.frame(\n  country = c(\"France\",\"Italy\"),\n  North = c(1.1,1.4),\n  South = c(0.4,2.9)\n)\n\n\npolarsR basetidyrdata.table\n\n\n\npl$DataFrame(df)$melt(\n  id_vars = \"country\",\n  value_vars = c(\"North\",\"South\")\n)\n\nshape: (4, 3)\n┌─────────┬──────────┬───────┐\n│ country ┆ variable ┆ value │\n│ ---     ┆ ---      ┆ ---   │\n│ str     ┆ str      ┆ f64   │\n╞═════════╪══════════╪═══════╡\n│ France  ┆ North    ┆ 1.1   │\n│ Italy   ┆ North    ┆ 1.4   │\n│ France  ┆ South    ┆ 0.4   │\n│ Italy   ┆ South    ┆ 2.9   │\n└─────────┴──────────┴───────┘\n\n\n\n\n\nmelted_df  &lt;- reshape(df, \n        varying = c(\"North\", \"South\"), \n        v.names = \"value\", \n        idvar = \"country\", \n        times = c(\"North\", \"South\"), \n        timevar = \"variable\", \n        direction = \"long\")\nrownames(melted_df) &lt;- NULL\nmelted_df\n\n  country variable value\n1  France    North   1.1\n2   Italy    North   1.4\n3  France    South   0.4\n4   Italy    South   2.9\n\n\n\n\n\ndf |&gt;\n  pivot_longer(\n    !country,\n    names_to = \"variable\",\n    values_to = \"value\"\n  )\n\n# A tibble: 4 × 3\n  country variable value\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n1 France  North      1.1\n2 France  South      0.4\n3 Italy   North      1.4\n4 Italy   South      2.9\n\n\n\n\n\ndf_dt &lt;- as.data.table(df)\nmelt(df_dt, id.vars = \"country\", variable.name = \"variable\", value.name = \"value\")\n\n   country variable value\n1:  France    North   1.1\n2:   Italy    North   1.4\n3:  France    South   0.4\n4:   Italy    South   2.9"
  },
  {
    "objectID": "data_manipulation.html#others-useful-methods",
    "href": "data_manipulation.html#others-useful-methods",
    "title": "2  Data manipulation",
    "section": "2.13 Others useful methods",
    "text": "2.13 Others useful methods\n\n2.13.1 On Series\n\n2.13.1.1 Change name of Series\nThe alias() method is very useful especially in method chaining operation.\nWith R base, the syntax is longer.\n\npolarsR base\n\n\n\npl$Series(1:3, name = \"toto\")$alias(\"titi\")\n\npolars Series: shape: (3,)\nSeries: 'titi' [i32]\n[\n    1\n    2\n    3\n]\n\n\n\n\n\ntoto &lt;- 1:3\ntiti &lt;- toto\nrm(toto)\n\n\n\n\n\n\n2.13.1.2 Reduce Boolean Series\nThe all() and any() methods can be used to check if all or any values in a vector evaluate to TRUE for some expression.\n\npolarsR base\n\n\n\n# all(pl$Series(c(TRUE,TRUE))) doesn't work\npl$Series(c(TRUE, TRUE, NA))$all()\n\n[1] FALSE\n\npl$Series(c(TRUE, TRUE, FALSE))$all()\n\n[1] FALSE\n\npl$Series(c(TRUE, TRUE, TRUE))$all()\n\n[1] TRUE\n\n\n\n\n\nall(c(TRUE,TRUE,NA))\n\n[1] NA\n\nall(c(TRUE,TRUE,FALSE))\n\n[1] FALSE\n\nall(c(TRUE,TRUE,TRUE))\n\n[1] TRUE\n\n\n\n\n\n\n\n2.13.1.3 Get data type of Series\nThe dtype() method can be used to get data type of Series.\n\npolarsR base\n\n\n\npl$Series(letters)$dtype\n\nDataType: Utf8\n\npl$Series(c(1, 2))$dtype\n\nDataType: Float64\n\npl$DataFrame(iris)$select(\"Species\")$to_series()$dtype\n\nDataType: Categorical(\n    Some(\n        local,\n    ),\n)\n\n\n\n\n\ninfer_type(letters)\n\nUtf8\nstring\n\ninfer_type(c(1, 2))\n\nFloat64\ndouble\n\ninfer_type(iris$Species)\n\nDictionaryType\ndictionary&lt;values=string, indices=int8&gt;\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nPolars is strongly typed. print(ls(pl$dtypes)) returns the full list of valid Polars types. Caution, some type names differ from what they are called in R base. See below!\n\n\n\npolarsR base\n\n\n\npl$Series(c(\"x\",\"y\",\"z\"))$dtype\n\nDataType: Utf8\n\npl$Series(c(1, 2, 3))$dtype\n\nDataType: Float64\n\npl$Series(c(1:3))$dtype\n\nDataType: Int32\n\npl$Series(c(TRUE,FALSE))$dtype\n\nDataType: Boolean\n\npl$DataFrame(iris)$select(\"Species\")$to_series()$dtype\n\nDataType: Categorical(\n    Some(\n        local,\n    ),\n)\n\npl$Series(Sys.Date())$dtype\n\nDataType: Date\n\npl$Series(c(0,1))$dtype\n\nDataType: Float64\n\n\n\n\n\ntypeof(c(\"x\",\"y\",\"z\"))\n\n[1] \"character\"\n\ntypeof(c(1, 2, 3))\n\n[1] \"double\"\n\ntypeof(c(1:3))\n\n[1] \"integer\"\n\ntypeof(c(TRUE,FALSE))\n\n[1] \"logical\"\n\ntypeof(iris$Species)\n\n[1] \"integer\"\n\ntypeof(Sys.Date())\n\n[1] \"double\"\n\n\n\n\n\nTo summarise the main types between Polars and R:\n\n\n\nPolars\nR Base\n\n\n\n\nUtf8\ncharacter\n\n\nFloat64\ndouble\n\n\nInt32\ninteger\n\n\nBoolean\nlogical\n\n\nCategorical\nFactor\n\n\nDate\nDate\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can deduce from this cross-reference table that if we want to create a categorical column in a DataFrame, we can proceed for example as follows: ::: {.cell}\npl$DataFrame(pl$Series(factor(c(\"a\",\"b\",\"c\"))))\n\nshape: (3, 1)\n┌─────┐\n│     │\n│ --- │\n│ cat │\n╞═════╡\n│ a   │\n│ b   │\n│ c   │\n└─────┘\n\n\n\n:::\nTo learn more about Data types in Polars, see here.\n\n\n2.13.1.4 Cast\nThe cast() method can be used to convert the data types of a column to a new one.\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$with_columns(\n  pl$col(\"Petal.Length\")$cast(pl$Int8), # The \"Petal.Length\" column is converted into integers\n  pl$col(\"Species\")$cast(pl$Utf8) # The \"Species\" column is converted into strings\n  )$schema\n\n$Sepal.Length\nDataType: Float64\n\n$Sepal.Width\nDataType: Float64\n\n$Petal.Length\nDataType: Int8\n\n$Petal.Width\nDataType: Float64\n\n$Species\nDataType: Utf8\n\n\n\n\n\ndata(iris)\niris$Petal.Length &lt;- as.integer(iris$Petal.Length)\niris$Species &lt;- as.integer(iris$Species)\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: int  1 1 1 1 1 1 1 1 1 1 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : int  1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\ndata(iris)\niris |&gt;\n  mutate(\n    Petal.Length = as.integer(Petal.Length),\n    Species = as.character(Species)) |&gt;\n  str()\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: int  1 1 1 1 1 1 1 1 1 1 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\n\n\n\n\niris_dt[, `:=`(Petal.Length = as.integer(Petal.Length),\n               Species = as.character(Species))]\nstr(iris_dt)\n\nClasses 'data.table' and 'data.frame':  150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: int  1 1 1 1 1 1 1 1 1 1 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt; \n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen working with very large tables we can Reduce the memory footprint by modifying the number of bits allocated to an element. ⚠️\n\n\nFor example, the example below illustrates how converting Float64 to Float8 reduces memory usage:\n\npl$DataFrame(iris)$estimated_size()\n\n[1] 5457\n\n#| label: reduce-footprint-polars\npl$DataFrame(iris)$with_columns(\n  pl$col(\"Petal.Length\")$cast(pl$Float32), \n  pl$col(\"Petal.Width\")$cast(pl$Float32), \n  pl$col(\"Sepal.Length\")$cast(pl$Float32), \n  pl$col(\"Sepal.Width\")$cast(pl$Float32)\n  )$estimated_size()\n\n[1] 3057\n\n\nWhen performing downcasting, it is crucial to ensure that the chosen number of bits is sufficient to accommodate the largest and smallest numbers in the column.\nA quick reminder:\n\n\n\nType\nRange\nAccuracy\n\n\n\n\nInt8\n-128 to +127\n\n\n\nInt16\n-32768 to +32767\n\n\n\nInt32\n-2147483648 to +2147483647\n\n\n\nInt64\n–2E63 to –2E63-1\n\n\n\nFloat32\n-3.4E+38 to +3.4E+38\nabout 7 decimal digits\n\n\nFloat64\n-1.7E+308 to +1.7E+308\nabout 16 decimal digits\n\n\n\n\n\n2.13.1.5 Check if Series is numeric\nThe is_numeric() method can be used to check if Series is numeric.\nNote that unlike R base, there is no method to check if a Series is character (in this case, its type is anyway Utf8).\n\npolarsR base\n\n\n\npl$Series(1:4)$is_numeric()\n\n[1] TRUE\n\npl$Series(c(\"a\", \"b\", \"c\"))$is_numeric()\n\n[1] FALSE\n\n\n\n\n\nis.numeric(1:4)\n\n[1] TRUE\n\nis.numeric(c(\"a\",\"b\",\"c\"))\n\n[1] FALSE\n\n\n\n\n\n\n\n2.13.1.6 Check if Series is sorted\nThe is_sorted() method can be used to check if Series is sorted.\nNote that R base provides is.unsorted() which returns the opposite boolean to is_sorted() of Polars.\n\npolarsR base\n\n\n\npl$Series(1:4)$is_sorted()\n\n[1] TRUE\n\npl$Series(c(1,3,2))$is_sorted()\n\n[1] FALSE\n\n\n\n\n\nis.unsorted(1:4)\n\n[1] FALSE\n\nis.unsorted(c(1,3,2))\n\n[1] TRUE\n\n\n\n\n\n\n\n2.13.1.7 Get length of a Series\nThe len() method can be used to get the length of a Series.\n\npolarsR base\n\n\n\npl$Series(1:4)$len()\n\n[1] 4\n\n\n\n\n\nlength(1:4)\n\n[1] 4\n\n\n\n\n\n\n\n2.13.1.8 Check if Series are equal\nThe series_equal() method can be used to check if a Series is equal with another Series.\n\n\n\n\n\n\nTip\n\n\n\nCaution, if two series are identical but one is named and the other is not then series_equal() returns FALSE.\n\n\n\npolarsR base\n\n\n\npl$Series(1:4)$series_equal(pl$Series(1:4))\n\n[1] TRUE\n\npl$Series(1:4,name = \"toto\")$series_equal(pl$Series(1:4))\n\n[1] FALSE\n\n\n\n\n\nidentical(1:4,1:4)\n\n[1] TRUE\n\n\n\n\n\n\n\n2.13.1.9 Convert Series to Polars DataFrame\nThe to_frame() method can be used to convert a Series to a DataFrame.\nIn this case, a DataFrame with only one column will be created. If the Series is initially named then the column of the DataFrame will be named as such.\n\npl$Series(1:3, \"toto\")$to_frame()\n\nshape: (3, 1)\n┌──────┐\n│ toto │\n│ ---  │\n│ i32  │\n╞══════╡\n│ 1    │\n│ 2    │\n│ 3    │\n└──────┘\n\n\n\n\n2.13.1.10 Get value Counts of a Series\nThe value_counts() method can be used to get a value counts of a Series.\n\npolarsR basedplyrdata.table\n\n\n\npl$Series(iris$Species)$value_counts()\n\nshape: (3, 2)\n┌────────────┬────────┐\n│            ┆ counts │\n│ ---        ┆ ---    │\n│ cat        ┆ u32    │\n╞════════════╪════════╡\n│ setosa     ┆ 50     │\n│ versicolor ┆ 50     │\n│ virginica  ┆ 50     │\n└────────────┴────────┘\n\n\n\n\n\ntable(iris$Species)\n\n\n    setosa versicolor  virginica \n        50         50         50 \n\n\n\n\n\niris |&gt;\n  count(Species)\n\n     Species  n\n1     setosa 50\n2 versicolor 50\n3  virginica 50\n\n\n\n\n\niris_dt[, .N, by = Species]\n\n      Species  N\n1:     setosa 50\n2: versicolor 50\n3:  virginica 50\n\n\n\n\n\n\n\n2.13.1.11 Sum across Series\nThe sum() method can be used to get a sum of a Series.\n\nFrom a single Series:\n\n\npolarsR base\n\n\n\npl$Series(1:3)$sum()\n\n[1] 6\n\n\n\n\n\nsum(c(1:3))\n\n[1] 6\n\n\n\n\n\n\nFrom a DataFrame and a column as a string:\n\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$select(pl$sum(\"Petal.Length\"))\n\nshape: (1, 1)\n┌──────────────┐\n│ Petal.Length │\n│ ---          │\n│ f64          │\n╞══════════════╡\n│ 563.7        │\n└──────────────┘\n\n\n\n\n\nsum(iris$Petal.Length)\n\n[1] 563.7\n\n\n\n\n\niris |&gt; summarise(sum(Petal.Length))\n\n  sum(Petal.Length)\n1             563.7\n\n\n\n\n\nsum(iris_dt[, Petal.Length])\n\n[1] 496\n\n\n\n\n\n\nFrom a DataFrame and a column as an expression:\n\n\npl$DataFrame(iris)$select(pl$sum(pl$col(\"Petal.Width\")))\n\nshape: (1, 1)\n┌─────────────┐\n│ Petal.Width │\n│ ---         │\n│ f64         │\n╞═════════════╡\n│ 179.9       │\n└─────────────┘\n\n\n\nFrom a DataFrame and a column as a list and sum horizontally:\n\nIn this case, use with_column() method.\n\npolarsR basedplyrdata.table\n\n\n\ndf_pl &lt;- pl$DataFrame(col1 = c(10L,20L), col2= c(30L,40L), col3 = c(40L,50L))\ndf_pl$with_column(pl$sum(list(\"col1\", \"col3\")))\n\nshape: (2, 4)\n┌──────┬──────┬──────┬─────┐\n│ col1 ┆ col2 ┆ col3 ┆ sum │\n│ ---  ┆ ---  ┆ ---  ┆ --- │\n│ i32  ┆ i32  ┆ i32  ┆ i32 │\n╞══════╪══════╪══════╪═════╡\n│ 10   ┆ 30   ┆ 40   ┆ 50  │\n│ 20   ┆ 40   ┆ 50   ┆ 70  │\n└──────┴──────┴──────┴─────┘\n\n\n\n\n\ndf &lt;- data.frame(col1 = c(10L,20L), col2= c(30L,40L), col3 = c(40L,50L))\nmysum &lt;- rowSums(df[, c(\"col1\", \"col3\")])\ncbind(df,mysum)\n\n  col1 col2 col3 mysum\n1   10   30   40    50\n2   20   40   50    70\n\n\n\n\n\ndf |&gt;\n  rowwise() |&gt; \n  mutate(mysum = sum(col1,col3))\n\n# A tibble: 2 × 4\n# Rowwise: \n   col1  col2  col3 mysum\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    10    30    40    50\n2    20    40    50    70\n\n\n\n\n\ndf_dt &lt;- as.data.table(df)\ndf_dt[, somme := rowSums(.SD), .SDcols = c(\"col1\", \"col3\")]\nprint(df_dt)\n\n   col1 col2 col3 somme\n1:   10   30   40    50\n2:   20   40   50    70\n\n\n\n\n\n\nFrom a DataFrame and sum horizontally all columns:\n\nIn this case, use list(*).\n\ndf_pl$with_column(pl$sum(list(\"*\")))\n\nshape: (2, 4)\n┌──────┬──────┬──────┬─────┐\n│ col1 ┆ col2 ┆ col3 ┆ sum │\n│ ---  ┆ ---  ┆ ---  ┆ --- │\n│ i32  ┆ i32  ┆ i32  ┆ i32 │\n╞══════╪══════╪══════╪═════╡\n│ 10   ┆ 30   ┆ 40   ┆ 80  │\n│ 20   ┆ 40   ┆ 50   ┆ 110 │\n└──────┴──────┴──────┴─────┘\n\n\nWith iris Dataframe, you must first select numerical variables:\n\npl$DataFrame(iris)$\n  select(\n  pl$col(c(\"Petal.Length\",\"Petal.Width\")))$\n  with_column(pl$sum(list(\"*\")))\n\nshape: (150, 3)\n┌──────────────┬─────────────┬─────┐\n│ Petal.Length ┆ Petal.Width ┆ sum │\n│ ---          ┆ ---         ┆ --- │\n│ f64          ┆ f64         ┆ f64 │\n╞══════════════╪═════════════╪═════╡\n│ 1.4          ┆ 0.2         ┆ 1.6 │\n│ 1.4          ┆ 0.2         ┆ 1.6 │\n│ 1.3          ┆ 0.2         ┆ 1.5 │\n│ 1.5          ┆ 0.2         ┆ 1.7 │\n│ …            ┆ …           ┆ …   │\n│ 5.0          ┆ 1.9         ┆ 6.9 │\n│ 5.2          ┆ 2.0         ┆ 7.2 │\n│ 5.4          ┆ 2.3         ┆ 7.7 │\n│ 5.1          ┆ 1.8         ┆ 6.9 │\n└──────────────┴─────────────┴─────┘\n\n\n\n\n\n2.13.2 On DataFrames\n\n2.13.2.1 Get Series from DataFrame\nThe to_series() method can be used to get one column from DataFrame as Series.\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$select(pl$col(\"Petal.Length\"))$to_series()\n\npolars Series: shape: (150,)\nSeries: 'Petal.Length' [f64]\n[\n    1.4\n    1.4\n    1.3\n    1.5\n    1.4\n    1.7\n    1.4\n    1.5\n    1.4\n    1.5\n    1.5\n    1.6\n    …\n    5.5\n    4.8\n    5.4\n    5.6\n    5.1\n    5.1\n    5.9\n    5.7\n    5.2\n    5.0\n    5.2\n    5.4\n    5.1\n]\n\n\n\n\n\niris$Petal.Length\n\n  [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n [19] 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n [37] 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0\n [55] 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0\n [73] 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0\n [91] 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3\n[109] 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0\n[127] 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n[145] 5.7 5.2 5.0 5.2 5.4 5.1\n\n\n\n\n\niris |&gt;\n  pull(Petal.Length)\n\n  [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n [19] 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n [37] 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0\n [55] 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0\n [73] 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0\n [91] 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3\n[109] 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0\n[127] 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n[145] 5.7 5.2 5.0 5.2 5.4 5.1\n\n\n\n\n\niris_dt[, c(Petal.Length)]\n\n  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 3 4 3 3 4 4 4 3 4 4 4 4 3 4 4 4 4\n [75] 4 4 4 5 4 3 3 3 3 5 4 4 4 4 4 4 4 4 4 3 4 4 4 4 3 4 6 5 5 5 5 6 4 6 5 6 5\n[112] 5 5 5 5 5 5 6 6 5 5 4 6 4 5 6 4 4 5 5 6 6 5 5 5 6 5 5 4 5 5 5 5 5 5 5 5 5\n[149] 5 5\n\n\n\n\n\n\n\n2.13.2.2 Get a R List from DataFrame\nThe to_list() method can be used to get a R List from DataFrame.\n\npolarsR base\n\n\n\nmylist &lt;- pl$DataFrame(iris)$to_list()\nnames(mylist)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\n\n\n\nmylist &lt;- as.list(iris)\nnames(mylist)\n\n[1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"     \n\n\n\n\n\n\n\n2.13.2.3 Get a slice of a DataFrame\nThe to_series() method can be used to get a slice of a DataFrame.\n\n\n\n\n\n\nImportant\n\n\n\nWith Polars, numeric default is 0! Thus the equivalent to slice(1,3) with Polars will be 1:4 in R Base and data.table and slice(1,4) with dplyr.\n\n\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(iris)$slice(1,3)\n\nshape: (3, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬─────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---     │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat     │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═════════╡\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa  │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa  │\n│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ setosa  │\n└──────────────┴─────────────┴──────────────┴─────────────┴─────────┘\n\n\n\n\n\niris[2:4,]\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n\n\n\n\n\niris |&gt;\n  slice(2:4)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          4.9         3.0          1.4         0.2  setosa\n2          4.7         3.2          1.3         0.2  setosa\n3          4.6         3.1          1.5         0.2  setosa\n\n\n\n\n\niris_dt[2:4,]\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1:          4.9         3.0            1         0.2  setosa\n2:          4.7         3.2            1         0.2  setosa\n3:          4.6         3.1            1         0.2  setosa\n\n\n\n\n\n\n\n2.13.2.4 Get a structure from a DataFrame\nThe to_struct() method can be used to get a structure from a DataFrame.\n\nmystruc &lt;- pl$DataFrame(iris)$to_struct()\nmystruc\n\npolars Series: shape: (150,)\nSeries: '' [struct[5]]\n[\n    {5.1,3.5,1.4,0.2,\"setosa\"}\n    {4.9,3.0,1.4,0.2,\"setosa\"}\n    {4.7,3.2,1.3,0.2,\"setosa\"}\n    {4.6,3.1,1.5,0.2,\"setosa\"}\n    {5.0,3.6,1.4,0.2,\"setosa\"}\n    {5.4,3.9,1.7,0.4,\"setosa\"}\n    {4.6,3.4,1.4,0.3,\"setosa\"}\n    {5.0,3.4,1.5,0.2,\"setosa\"}\n    {4.4,2.9,1.4,0.2,\"setosa\"}\n    {4.9,3.1,1.5,0.1,\"setosa\"}\n    {5.4,3.7,1.5,0.2,\"setosa\"}\n    {4.8,3.4,1.6,0.2,\"setosa\"}\n    …\n    {6.4,3.1,5.5,1.8,\"virginica\"}\n    {6.0,3.0,4.8,1.8,\"virginica\"}\n    {6.9,3.1,5.4,2.1,\"virginica\"}\n    {6.7,3.1,5.6,2.4,\"virginica\"}\n    {6.9,3.1,5.1,2.3,\"virginica\"}\n    {5.8,2.7,5.1,1.9,\"virginica\"}\n    {6.8,3.2,5.9,2.3,\"virginica\"}\n    {6.7,3.3,5.7,2.5,\"virginica\"}\n    {6.7,3.0,5.2,2.3,\"virginica\"}\n    {6.3,2.5,5.0,1.9,\"virginica\"}\n    {6.5,3.0,5.2,2.0,\"virginica\"}\n    {6.2,3.4,5.4,2.3,\"virginica\"}\n    {5.9,3.0,5.1,1.8,\"virginica\"}\n]\n\n\nto_struct() returns a Series which can be converted to a R list with to_r method.\n\nmylist &lt;- mystruc$to_r()\nstr(mylist)\n\nList of 5\n $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"is_struct\")= logi TRUE\n\n\nmylist is now a list where each element is a column of the initial DataFrame.\nWith to_frame() and unnest() methods, we can reconstruct the original DataFrame:\n\nback_df &lt;- mystruc$to_frame()$unnest()\nback_df\n\nshape: (150, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬───────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species   │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---       │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat       │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═══════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa    │\n│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ setosa    │\n│ …            ┆ …           ┆ …            ┆ …           ┆ …         │\n│ 6.3          ┆ 2.5         ┆ 5.0          ┆ 1.9         ┆ virginica │\n│ 6.5          ┆ 3.0         ┆ 5.2          ┆ 2.0         ┆ virginica │\n│ 6.2          ┆ 3.4         ┆ 5.4          ┆ 2.3         ┆ virginica │\n│ 5.9          ┆ 3.0         ┆ 5.1          ┆ 1.8         ┆ virginica │\n└──────────────┴─────────────┴──────────────┴─────────────┴───────────┘\n\n\n\n\n2.13.2.5 Drop all rows that contain null values\nThe drop_nulls() method can be used to drop all rows that contain null values in a DataFrame.\nBy default, drop_nulls() use all columns to drop rows:\n\npolarsR basedplyrdata.table\n\n\n\ndata_pl &lt;- pl$DataFrame(\n  col1 = pl$Series(c(NA,\"b\",\"c\")),\n  col2 = pl$Series(c(1,2,NA))\n)\ndata_pl$drop_nulls()\n\nshape: (1, 2)\n┌──────┬──────┐\n│ col1 ┆ col2 │\n│ ---  ┆ ---  │\n│ str  ┆ f64  │\n╞══════╪══════╡\n│ b    ┆ 2.0  │\n└──────┴──────┘\n\n\n\n\n\ndata_df &lt;- data.frame(\n  col1 = c(NA, \"b\", \"c\"),\n  col2 = c(1, 2, NA)\n)\ndata_df[complete.cases(data_df), ]\n\n  col1 col2\n2    b    2\n\n\n\n\n\ndata_df &lt;- data.frame(\n  col1 = c(NA, \"b\", \"c\"),\n  col2 = c(1, 2, NA)\n)\ndata_df %&gt;%\n  filter(complete.cases(.))\n\n  col1 col2\n1    b    2\n\n\n\n\n\ndata_dt &lt;- data.table(\n  col1 = c(NA, \"b\", \"c\"),\n  col2 = c(1, 2, NA)\n)\nna.omit(data_dt)\n\n   col1 col2\n1:    b    2\n\n\n\n\n\nIf you want, you can specify a column (or multiple columns):\n\npolarsR basedplyrdata.table\n\n\n\ndata_pl$drop_nulls(\"col1\")\n\nshape: (2, 2)\n┌──────┬──────┐\n│ col1 ┆ col2 │\n│ ---  ┆ ---  │\n│ str  ┆ f64  │\n╞══════╪══════╡\n│ b    ┆ 2.0  │\n│ c    ┆ null │\n└──────┴──────┘\n\n\n\n\n\ndata_df[!is.na(data_df$col1), ]\n\n  col1 col2\n2    b    2\n3    c   NA\n\n\n\n\n\ndata_df |&gt;\n  filter(!is.na(col1))\n\n  col1 col2\n1    b    2\n2    c   NA\n\n\n\n\n\ndata_dt[complete.cases(data_dt[, .SD, .SDcols = \"col1\"]), ]\n\n   col1 col2\n1:    b    2\n2:    c   NA"
  },
  {
    "objectID": "data_manipulation.html#strings-methods",
    "href": "data_manipulation.html#strings-methods",
    "title": "2  Data manipulation",
    "section": "2.14 Strings methods",
    "text": "2.14 Strings methods\nIn polars, a lot of strings methods are useful. Here is the list.\nTo use them, simply prefix them with str.\n\n2.14.1 Get substrings\nThe str$slice() method can be used to create substrings of the string values of a Utf8 Series.\nstr$slice() does not work like R base’s substr() function for finding the substring of interest: - substr() takes two arguments: the first and last elements; - str$slice() takes two arguments: the first element and the extraction length.\n\n\n\n\n\n\nImportant\n\n\n\nWith Polars, numeric default is 0! Thus the equivalent to str$slice(0,3) with Polars will be substr(1,3).\n\n\nTwo further comments:\n\nIf the second argument length is not specified, the sub-character string of interest will default to the end of the character string. For example in a DataFrame if mycol is a string column of length 4, pl.col(\"mycol\").str.slice(1) is equivalent to substr(mycol,2,4) in dplyr.\nThe first argument accepts negative values, which means that sub-strings can be considered starting from the end. For example in a DataFrame if mycol is a string column of length 4, pl.col(\"mycol\").str.slice(-2) is equivalent to substr(mycol,3,4) in dplyr.\n\nLet’s see an example:\n\nmydf &lt;- data.frame(\n  col1 = 1:4,\n  col2 = c(\"One_X\",\"One_Y\",\"Two_X\",\"Two_Y\")\n)\n\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(mydf)$with_columns(\n  pl$col(\"col2\")$str$slice(0,length=3)$alias(\"level\"),\n  pl$col(\"col2\")$str$slice(-1)$alias(\"x_y\")\n)\n\nshape: (4, 4)\n┌──────┬───────┬───────┬─────┐\n│ col1 ┆ col2  ┆ level ┆ x_y │\n│ ---  ┆ ---   ┆ ---   ┆ --- │\n│ i32  ┆ str   ┆ str   ┆ str │\n╞══════╪═══════╪═══════╪═════╡\n│ 1    ┆ One_X ┆ One   ┆ X   │\n│ 2    ┆ One_Y ┆ One   ┆ Y   │\n│ 3    ┆ Two_X ┆ Two   ┆ X   │\n│ 4    ┆ Two_Y ┆ Two   ┆ Y   │\n└──────┴───────┴───────┴─────┘\n\n\n\n\n\nmydf$level &lt;- substr(mydf$col2, 1, 3)\nmydf$x_y &lt;- substr(mydf$col2, nchar(mydf$col2), nchar(mydf$col2))\nmydf\n\n  col1  col2 level x_y\n1    1 One_X   One   X\n2    2 One_Y   One   Y\n3    3 Two_X   Two   X\n4    4 Two_Y   Two   Y\n\n\n\n\n\nmydf |&gt;\n  mutate(level = substr(col2, 1, 3),\n         x_y = substr(col2, nchar(col2), nchar(col2)))\n\n  col1  col2 level x_y\n1    1 One_X   One   X\n2    2 One_Y   One   Y\n3    3 Two_X   Two   X\n4    4 Two_Y   Two   Y\n\n\n\n\n\nmydt &lt;- as.data.table(mydf) \nmydt[, c(\"level\", \"x_y\") := .(substr(col2, 1, 3), substr(col2, nchar(col2), nchar(col2)))]\nmydt\n\n   col1  col2 level x_y\n1:    1 One_X   One   X\n2:    2 One_Y   One   Y\n3:    3 Two_X   Two   X\n4:    4 Two_Y   Two   Y\n\n\n\n\n\n\n\n2.14.2 Check if string values start with a substring\nThe str$starts_with() method can be used to check if string values start with a substring. It returns a Boolean.\nLet’s see an example where we create new Boolean columns based on the start of a character string:\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(mydf)$with_columns(\n  pl$col(\"col2\")$str$starts_with(\"One\")$alias(\"is_one\"),\n  pl$col(\"col2\")$str$starts_with(\"Two\")$alias(\"is_two\")\n)\n\nshape: (4, 6)\n┌──────┬───────┬───────┬─────┬────────┬────────┐\n│ col1 ┆ col2  ┆ level ┆ x_y ┆ is_one ┆ is_two │\n│ ---  ┆ ---   ┆ ---   ┆ --- ┆ ---    ┆ ---    │\n│ i32  ┆ str   ┆ str   ┆ str ┆ bool   ┆ bool   │\n╞══════╪═══════╪═══════╪═════╪════════╪════════╡\n│ 1    ┆ One_X ┆ One   ┆ X   ┆ true   ┆ false  │\n│ 2    ┆ One_Y ┆ One   ┆ Y   ┆ true   ┆ false  │\n│ 3    ┆ Two_X ┆ Two   ┆ X   ┆ false  ┆ true   │\n│ 4    ┆ Two_Y ┆ Two   ┆ Y   ┆ false  ┆ true   │\n└──────┴───────┴───────┴─────┴────────┴────────┘\n\n\n\n\n\nmydf$is_one &lt;- grepl(\"^One\", mydf$col2)\nmydf$is_two &lt;- grepl(\"^Two\", mydf$col2)\nmydf\n\n  col1  col2 level x_y is_one is_two\n1    1 One_X   One   X   TRUE  FALSE\n2    2 One_Y   One   Y   TRUE  FALSE\n3    3 Two_X   Two   X  FALSE   TRUE\n4    4 Two_Y   Two   Y  FALSE   TRUE\n\n\n\n\n\nmydf |&gt;\n  mutate(level = substr(col2, 1, 3),\n         x_y = substr(col2, nchar(col2), nchar(col2)))\n\n  col1  col2 level x_y is_one is_two\n1    1 One_X   One   X   TRUE  FALSE\n2    2 One_Y   One   Y   TRUE  FALSE\n3    3 Two_X   Two   X  FALSE   TRUE\n4    4 Two_Y   Two   Y  FALSE   TRUE\n\n\n\n\n\nmydt &lt;- as.data.table(mydf) \nmydt[, c(\"is_one\", \"is_two\") := .(grepl(\"^One\", col2), grepl(\"^Two\", col2))]\nmydt\n\n   col1  col2 level x_y is_one is_two\n1:    1 One_X   One   X   TRUE  FALSE\n2:    2 One_Y   One   Y   TRUE  FALSE\n3:    3 Two_X   Two   X  FALSE   TRUE\n4:    4 Two_Y   Two   Y  FALSE   TRUE\n\n\n\n\n\n\n\n2.14.3 Check if string values end with a substring\nThe str$ends_with() method can be used to check if string values start with a substring. It returns a Boolean.\nLet’s see an example where we filter the lines of a DataFrame based on the start of a character string:\n\npolarsR basedplyrdata.table\n\n\n\npl$DataFrame(mydf)$filter(\n  pl$col(\"col2\")$str$ends_with(\"X\")\n)\n\nshape: (2, 6)\n┌──────┬───────┬───────┬─────┬────────┬────────┐\n│ col1 ┆ col2  ┆ level ┆ x_y ┆ is_one ┆ is_two │\n│ ---  ┆ ---   ┆ ---   ┆ --- ┆ ---    ┆ ---    │\n│ i32  ┆ str   ┆ str   ┆ str ┆ bool   ┆ bool   │\n╞══════╪═══════╪═══════╪═════╪════════╪════════╡\n│ 1    ┆ One_X ┆ One   ┆ X   ┆ true   ┆ false  │\n│ 3    ┆ Two_X ┆ Two   ┆ X   ┆ false  ┆ true   │\n└──────┴───────┴───────┴─────┴────────┴────────┘\n\n\n\n\n\nmydf[substr(mydf$col2, nchar(mydf$col2), nchar(mydf$col2)) == \"X\", ]\n\n  col1  col2 level x_y is_one is_two\n1    1 One_X   One   X   TRUE  FALSE\n3    3 Two_X   Two   X  FALSE   TRUE\n\n\n\n\n\nmydf |&gt;\n  filter(endsWith(col2, \"X\"))\n\n  col1  col2 level x_y is_one is_two\n1    1 One_X   One   X   TRUE  FALSE\n2    3 Two_X   Two   X  FALSE   TRUE\n\n\n\n\n\nmydt &lt;- as.data.table(mydf) \nmydt[substr(col2, nchar(col2), nchar(col2)) == \"X\"]\n\n   col1  col2 level x_y is_one is_two\n1:    1 One_X   One   X   TRUE  FALSE\n2:    3 Two_X   Two   X  FALSE   TRUE"
  },
  {
    "objectID": "data_manipulation.html#list-of-methods-to-apply-to-series",
    "href": "data_manipulation.html#list-of-methods-to-apply-to-series",
    "title": "2  Data manipulation",
    "section": "2.15 List of methods to apply to Series",
    "text": "2.15 List of methods to apply to Series\nTo learn more about the methods to be applied to the Series, see this page.\n\n# See all exported methods for Series\nls(polars:::Series)\n\n [1] \"abs\"           \"add\"           \"alias\"         \"all\"          \n [5] \"any\"           \"append\"        \"apply\"         \"arg_max\"      \n [9] \"arg_min\"       \"arr\"           \"ceil\"          \"chunk_lengths\"\n[13] \"clone\"         \"compare\"       \"cumsum\"        \"div\"          \n[17] \"dtype\"         \"expr\"          \"flags\"         \"floor\"        \n[21] \"is_numeric\"    \"is_sorted\"     \"len\"           \"max\"          \n[25] \"mean\"          \"median\"        \"min\"           \"mul\"          \n[29] \"n_unique\"      \"name\"          \"print\"         \"rem\"          \n[33] \"rename\"        \"rep\"           \"series_equal\"  \"set_sorted\"   \n[37] \"shape\"         \"sort\"          \"std\"           \"sub\"          \n[41] \"sum\"           \"to_frame\"      \"to_lit\"        \"to_r\"         \n[45] \"to_r_list\"     \"to_r_vector\"   \"to_vector\"     \"value_counts\" \n[49] \"var\"          \n\n# See all private methods for Series (not intended for regular use)\nls(polars:::.pr$Series)\n\n [1] \"abs\"                    \"add\"                    \"alias\"                 \n [4] \"all\"                    \"any\"                    \"append_mut\"            \n [7] \"apply\"                  \"arg_max\"                \"arg_min\"               \n[10] \"ceil\"                   \"chunk_lengths\"          \"clone\"                 \n[13] \"compare\"                \"cumsum\"                 \"div\"                   \n[16] \"dtype\"                  \"floor\"                  \"from_arrow\"            \n[19] \"get_fmt\"                \"is_sorted\"              \"is_sorted_flag\"        \n[22] \"is_sorted_reverse_flag\" \"len\"                    \"max\"                   \n[25] \"mean\"                   \"median\"                 \"min\"                   \n[28] \"mul\"                    \"n_unique\"               \"name\"                  \n[31] \"new\"                    \"panic\"                  \"print\"                 \n[34] \"rem\"                    \"rename_mut\"             \"rep\"                   \n[37] \"series_equal\"           \"set_sorted_mut\"         \"shape\"                 \n[40] \"sleep\"                  \"sort_mut\"               \"std\"                   \n[43] \"sub\"                    \"sum\"                    \"to_fmt_char\"           \n[46] \"to_frame\"               \"to_r\"                   \"value_counts\"          \n[49] \"var\""
  },
  {
    "objectID": "data_manipulation.html#list-of-methods-to-apply-to-dataframe",
    "href": "data_manipulation.html#list-of-methods-to-apply-to-dataframe",
    "title": "2  Data manipulation",
    "section": "2.16 List of methods to apply to DataFrame",
    "text": "2.16 List of methods to apply to DataFrame\n👉 To learn more about the methods to be applied to the DataFrames, see this page.\n\n# See all exported methods for DataFrame\nls(polars:::DataFrame)\n\n [1] \"as_data_frame\"  \"clone\"          \"columns\"        \"describe\"      \n [5] \"drop\"           \"drop_in_place\"  \"drop_nulls\"     \"dtype_strings\" \n [9] \"dtypes\"         \"estimated_size\" \"explode\"        \"fill_nan\"      \n[13] \"fill_null\"      \"filter\"         \"first\"          \"frame_equal\"   \n[17] \"get_column\"     \"get_columns\"    \"glimpse\"        \"groupby\"       \n[21] \"head\"           \"height\"         \"join\"           \"join_asof\"     \n[25] \"last\"           \"lazy\"           \"limit\"          \"max\"           \n[29] \"mean\"           \"median\"         \"melt\"           \"min\"           \n[33] \"null_count\"     \"pivot\"          \"print\"          \"quantile\"      \n[37] \"rename\"         \"reverse\"        \"schema\"         \"select\"        \n[41] \"shape\"          \"shift\"          \"shift_and_fill\" \"slice\"         \n[45] \"sort\"           \"std\"            \"sum\"            \"tail\"          \n[49] \"to_data_frame\"  \"to_list\"        \"to_series\"      \"to_struct\"     \n[53] \"unique\"         \"unnest\"         \"var\"            \"width\"         \n[57] \"with_column\"    \"with_columns\"   \"with_row_count\"\n\n# See all private methods for DataFrame (not intended for regular use)\nls(polars:::.pr$DataFrame)\n\n [1] \"by_agg\"                    \"clone_see_me_macro\"       \n [3] \"columns\"                   \"default\"                  \n [5] \"drop_in_place\"             \"dtype_strings\"            \n [7] \"dtypes\"                    \"estimated_size\"           \n [9] \"export_stream\"             \"frame_equal\"              \n[11] \"from_arrow_record_batches\" \"get_column\"               \n[13] \"get_columns\"               \"lazy\"                     \n[15] \"melt\"                      \"new_par_from_list\"        \n[17] \"new_with_capacity\"         \"null_count\"               \n[19] \"pivot_expr\"                \"print\"                    \n[21] \"schema\"                    \"select\"                   \n[23] \"select_at_idx\"             \"set_column_from_robj\"     \n[25] \"set_column_from_series\"    \"set_column_names_mut\"     \n[27] \"shape\"                     \"to_list\"                  \n[29] \"to_list_tag_structs\"       \"to_list_unwind\"           \n[31] \"to_struct\"                 \"unnest\"                   \n[33] \"with_row_count\""
  },
  {
    "objectID": "import_export.html#import-data",
    "href": "import_export.html#import-data",
    "title": "3  Import/Export",
    "section": "3.1 Import data",
    "text": "3.1 Import data\n\n3.1.1 Read a csv file or URL\nThe read_csv() method can be used to import a csv file from a file or an URL. read_csv() returns a DataFrame.\n\n3.1.1.1 From a file\n\npolarsR base\n\n\n\npl$read_csv(\"examples/iris.csv\")\n\nshape: (150, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬───────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species   │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---       │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ str       │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═══════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa    │\n│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ setosa    │\n│ …            ┆ …           ┆ …            ┆ …           ┆ …         │\n│ 6.3          ┆ 2.5         ┆ 5.0          ┆ 1.9         ┆ virginica │\n│ 6.5          ┆ 3.0         ┆ 5.2          ┆ 2.0         ┆ virginica │\n│ 6.2          ┆ 3.4         ┆ 5.4          ┆ 2.3         ┆ virginica │\n│ 5.9          ┆ 3.0         ┆ 5.1          ┆ 1.8         ┆ virginica │\n└──────────────┴─────────────┴──────────────┴─────────────┴───────────┘\n\n\n\n\n\nread.csv(\"examples/iris.csv\")\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\n\n\n\n\n3.1.1.2 From multiple files\nFirst, let’s create a dozen csv files\n\ndir.create(\"Datasets\")\nmydf &lt;- data.frame(\n  col1 = 1:3,\n  col2 = c(\"a\", \"b\", \"c\")\n)\nfor (i in 1:10) {\n  write.csv(mydf, file = paste0(\"Datasets/example_data_\",i,\".csv\"))\n}\n\n\n\n\n\n\n\nImportant\n\n\n\nJune 2023: Reading those multiple files into a single DataFrame is not yet implemented in R. See here for an example in Python.\n\n\n\n\n3.1.1.3 From an URL\nThe read_csv() method also works with an URL:\n\npl$read_csv(\"https://j.mp/iriscsv\")\n\ntmp file placed in \n /tmp/RtmplcMLLF/https...j.mp.iriscsv\n\n\nshape: (150, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬───────────┐\n│ sepal_length ┆ sepal_width ┆ petal_length ┆ petal_width ┆ species   │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---       │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ str       │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═══════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa    │\n│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ setosa    │\n│ …            ┆ …           ┆ …            ┆ …           ┆ …         │\n│ 6.3          ┆ 2.5         ┆ 5.0          ┆ 1.9         ┆ virginica │\n│ 6.5          ┆ 3.0         ┆ 5.2          ┆ 2.0         ┆ virginica │\n│ 6.2          ┆ 3.4         ┆ 5.4          ┆ 2.3         ┆ virginica │\n│ 5.9          ┆ 3.0         ┆ 5.1          ┆ 1.8         ┆ virginica │\n└──────────────┴─────────────┴──────────────┴─────────────┴───────────┘\n\n\n👉 For a complete list of arguments to use with the read_csv() method, see this page.\n\n\n\n3.1.2 Scan a csv file\nThe pl$scan_csv() method can be used to lazily read a csv file from a file.\npl$scan_csv() returns a LazyFrame.\n\nThis allows the query optimizer to push down predicates and projections to the scan level, thereby potentially reducing memory overhead.\n\n\npl$scan_csv(\n  \"examples/iris.csv\")$select( # lazy, don't do a thing\n    pl$col(c(\"Petal.Length\",\"Petal.Width\")) # select only 2 columns\n  )$\n  filter(\n    pl$col(\"Petal.Length\") &gt; 4 # the filter is pushed down the scan, so less data is read into memory\n  )$collect() # &lt;- don't forget collect() here!\n\nshape: (84, 2)\n┌──────────────┬─────────────┐\n│ Petal.Length ┆ Petal.Width │\n│ ---          ┆ ---         │\n│ f64          ┆ f64         │\n╞══════════════╪═════════════╡\n│ 4.7          ┆ 1.4         │\n│ 4.5          ┆ 1.5         │\n│ 4.9          ┆ 1.5         │\n│ 4.6          ┆ 1.5         │\n│ …            ┆ …           │\n│ 5.0          ┆ 1.9         │\n│ 5.2          ┆ 2.0         │\n│ 5.4          ┆ 2.3         │\n│ 5.1          ┆ 1.8         │\n└──────────────┴─────────────┘\n\n\n👉 For a complete list of arguments to use with the lazy_csv_reader() method, see this page.\n\n\n\n\n\n\nImportant\n\n\n\nJune 2023: arguments available in Python eol_char and with_column_names not yet supporting in R\n\n\n\n\n3.1.3 Scan a parquet file\n\n3.1.3.1 From a single file\nThe pl$scan_parquet() method can be used to lazily read a parquet file from a file.\nScanning delays the actual parsing of the file and pl$scan_parquet() returns a LazyFrame.\n\npl$scan_parquet(\"examples/iris.parquet\")\n\n[1] \"polars LazyFrame naive plan: (run ldf$describe_optimized_plan() to see the optimized plan)\"\n\n  PARQUET SCAN examples/iris.parquet\n  PROJECT */5 COLUMNS\n\n\n👉 For a complete list of arguments to use with the scan_parquet() method, see this page.\nAt the end of the query, don’t forget to use the collect() method to inform Polars that you want to execute it.\n\npl$scan_parquet(\"examples/iris.parquet\")$\n  collect()\n\nshape: (150, 5)\n┌──────────────┬─────────────┬──────────────┬─────────────┬───────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width ┆ Species   │\n│ ---          ┆ ---         ┆ ---          ┆ ---         ┆ ---       │\n│ f64          ┆ f64         ┆ f64          ┆ f64         ┆ cat       │\n╞══════════════╪═════════════╪══════════════╪═════════════╪═══════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         ┆ setosa    │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         ┆ setosa    │\n│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         ┆ setosa    │\n│ …            ┆ …           ┆ …            ┆ …           ┆ …         │\n│ 6.3          ┆ 2.5         ┆ 5.0          ┆ 1.9         ┆ virginica │\n│ 6.5          ┆ 3.0         ┆ 5.2          ┆ 2.0         ┆ virginica │\n│ 6.2          ┆ 3.4         ┆ 5.4          ┆ 2.3         ┆ virginica │\n│ 5.9          ┆ 3.0         ┆ 5.1          ┆ 1.8         ┆ virginica │\n└──────────────┴─────────────┴──────────────┴─────────────┴───────────┘\n\n\n\n\n\n\n\n\nCaution\n\n\n\nJune 2023 : Export methods have not yet been implemented in R. This methods start with write_ (write_parquet(), write_parquet(), write_json(), write_ndjson()…)\n\n\n\n\n3.1.3.2 From multiple files\nThe pl$scan_parquet() method can also be used to lazily read multiple parquet files in the same folder.\nThis is particularly useful for partitioned files! For example:\n\n# Write multiple parquet files in examples folder\narrow::write_dataset(dataset = iris,\n                     path = \"examples\",\n                     partitioning = \"Species\")\n# Reading all parquet files in the example folder and its subfolders\npl$scan_parquet(\"examples/*/*.parquet\")$\n  collect()\n\nshape: (150, 4)\n┌──────────────┬─────────────┬──────────────┬─────────────┐\n│ Sepal.Length ┆ Sepal.Width ┆ Petal.Length ┆ Petal.Width │\n│ ---          ┆ ---         ┆ ---          ┆ ---         │\n│ f64          ┆ f64         ┆ f64          ┆ f64         │\n╞══════════════╪═════════════╪══════════════╪═════════════╡\n│ 5.1          ┆ 3.5         ┆ 1.4          ┆ 0.2         │\n│ 4.9          ┆ 3.0         ┆ 1.4          ┆ 0.2         │\n│ 4.7          ┆ 3.2         ┆ 1.3          ┆ 0.2         │\n│ 4.6          ┆ 3.1         ┆ 1.5          ┆ 0.2         │\n│ …            ┆ …           ┆ …            ┆ …           │\n│ 6.3          ┆ 2.5         ┆ 5.0          ┆ 1.9         │\n│ 6.5          ┆ 3.0         ┆ 5.2          ┆ 2.0         │\n│ 6.2          ┆ 3.4         ┆ 5.4          ┆ 2.3         │\n│ 5.9          ┆ 3.0         ┆ 5.1          ┆ 1.8         │\n└──────────────┴─────────────┴──────────────┴─────────────┘\n\n\nIn the code above:\n\n/* refers to all subfolders in the example folder\n\n/*.parquet refers to all files with a .parquet extension\n\n\n\n\n\n\n\nImportant\n\n\n\nIn this case, note that the Species column which been used for partitioning is missing\n\n\nOf course, the advantage of using pl$scan_parquet() is that you can query several partitioned files and retrieve the result of the query in R. See an example here."
  },
  {
    "objectID": "import_export.html#export-data-to-excel",
    "href": "import_export.html#export-data-to-excel",
    "title": "3  Import/Export",
    "section": "3.2 Export data to Excel",
    "text": "3.2 Export data to Excel\nAs with Python, there are no native method in Rust for exporting to Excel format.\nThe best current solution is to use the data.frame conversion method and then use the {openxlsx} package or one of its {tablexlsx} wrapper to export these DataFrames in xlsx format. The more recent{openxlxs2} package is also a great tool for exporting to xlsx files.\nLet’s look at the syntax of a simple export with theses 3 packages:\n\nopenxlsxtablexlsxopenxlsx2\n\n\n\n# install.packages(\"openxlsx\")\nlibrary(openxlsx)\n\nopenxlsx::write.xlsx(\n    iris,\n    file = tempdir()\n)\n\n\n\n\n# install.packages(\"tablexlsx\")\nlibrary(tablexlsx)\n\niris |&gt; toxlsx(path = tempdir())\n\n\n\n\n# install.packages(\"openxlsx2\")\nlibrary(openxlsx2)\n\nopenxlsx2::write_xlsx(\n    iris,\n    file = tempdir()\n)"
  },
  {
    "objectID": "lazy_execution.html#introduction-to-lazy-mode",
    "href": "lazy_execution.html#introduction-to-lazy-mode",
    "title": "4  Lazy execution",
    "section": "4.1 Introduction to lazy mode",
    "text": "4.1 Introduction to lazy mode\nPolars supports two modes of operation: lazy and eager.\nLet’s start this chapter by citing the official documentation:\n\nIn the eager API the query is executed immediately while in the lazy API the query is only evaluated once it is ‘needed’. Deferring the execution to the last minute can have significant performance advantages that is why the Lazy API is preferred in most cases. Delaying execution until the last possible moment allows Polars to apply automatic optimization to every query.\n\nAs you can see, with lazy mode, you give the engine the chance to analyse what you want to do in order to propose optimal execution (for both reading and transforming datasets). Lazy evaluation is a fairly common method of improving processing speed and is used by Spark, among others.\nSo far in this book, we have only used the eager mode but fortunately all the syntax we’ve seen applies to lazy mode too. Whatever mode is used, queries will be executed transparently for users.\n\n4.1.1 Creation of a LazyFrame with lazy()\nTo convert a DataFrame to a LazyFrame we can use the lazy() contructor.\n\npl$DataFrame(iris)$lazy()\n\n[1] \"polars LazyFrame naive plan: (run ldf$describe_optimized_plan() to see the optimized plan)\"\nDF [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]; PROJECT */5 COLUMNS; SELECTION: \"None\"\n\n\nWe are no longer working on a DataFrame but on a LazyFrame.\n\n\n4.1.2 First query passed on LazyFrame\nLet’s look at what happens when we request this LazyFrame:\n\nmyquery &lt;- pl$DataFrame(iris)$lazy()$filter(\n  pl$col(\"Species\") == \"setosa\"\n)$select(\n  pl$col(c(\"Species\", \"Petal.Length\"))\n)\nmyquery\n\n[1] \"polars LazyFrame naive plan: (run ldf$describe_optimized_plan() to see the optimized plan)\"\n SELECT [col(\"Species\"), col(\"Petal.Length\")] FROM\n  FILTER [(col(\"Species\")) == (Utf8(setosa))] FROM\n  DF [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]; PROJECT */5 COLUMNS; SELECTION: \"None\"\n\n\nThis way, we can display the naive plan (which means it is an non-optimized plan). Let’s see what it contains for our example:\n\nFILTER [(col(\"Species\")) == (Utf8(setosa))] FROM DF [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"] means that once the entire datasets has been read into memory, this DataFrame will be filtered for rows with Species equals to “setosa”;\n\nPROJECT */5 COLUMNS selects all 5 of the columns (* is the wildcard meaning all);\n\nSELECTION: \"None\" means no rows will be filtered out.\n\nAs indicated in the console, we can use the describe_optimized_plan() method to see the optimized plan.\n\nmyquery$describe_optimized_plan()\n\nFAST_PROJECT: [Species, Petal.Length]\n  DF [\"Sepal.Length\", \"Sepal.Width\", \"Petal.Length\", \"Petal.Width\"]; PROJECT 2/5 COLUMNS; SELECTION: \"[(col(\\\"Species\\\")) == (Utf8(setosa))]\"\n\n\nThis example shows a simple but surprisingly effective element of query optimisation: projection.\nLet’s see what changed in this optimized plan:\n\nPROJECT 2/5 COLUMNS selects only 2 columns;\n\nSELECTION: \"[(col(\\\"Species\\\")) == (Utf8(setosa))] means that Polars will apply the filter conditions on the Species column as the datasets is being read.\n\nWe can see that Polars has identified that only 2 columns are needed to execute our query which is memory efficient! And Polars did this without me having to select these variables myself (for example with a select method).\nThe added value of Polars is that it applies some optimizations that I/you might not even have known about. 💪\n\n\n4.1.3 Execute the plan\nTo actually execute the plan, we just need to invoke the collect() method.\n\nmyquery$collect()\n\nshape: (50, 2)\n┌─────────┬──────────────┐\n│ Species ┆ Petal.Length │\n│ ---     ┆ ---          │\n│ cat     ┆ f64          │\n╞═════════╪══════════════╡\n│ setosa  ┆ 1.4          │\n│ setosa  ┆ 1.4          │\n│ setosa  ┆ 1.3          │\n│ setosa  ┆ 1.5          │\n│ …       ┆ …            │\n│ setosa  ┆ 1.6          │\n│ setosa  ┆ 1.4          │\n│ setosa  ┆ 1.5          │\n│ setosa  ┆ 1.4          │\n└─────────┴──────────────┘"
  },
  {
    "objectID": "lazy_execution.html#lazy-vs-eager-mode-comparison",
    "href": "lazy_execution.html#lazy-vs-eager-mode-comparison",
    "title": "4  Lazy execution",
    "section": "4.2 Lazy vs eager mode comparison",
    "text": "4.2 Lazy vs eager mode comparison\n\n4.2.1 General principles\nIn this first example we use the eager API:\n\ndf &lt;- pl$read_csv(\"examples/iris.csv\")\ndf_small = df$filter(pl$col(\"Petal.Length\") &gt; 5)\ndf_agg = df_small$groupby(\"Species\")$agg(pl$col(\"Petal.Width\")$median())\ndf_agg\n\nshape: (2, 2)\n┌────────────┬─────────────┐\n│ Species    ┆ Petal.Width │\n│ ---        ┆ ---         │\n│ str        ┆ f64         │\n╞════════════╪═════════════╡\n│ versicolor ┆ 1.6         │\n│ virginica  ┆ 2.1         │\n└────────────┴─────────────┘\n\n\nThis example:\n\nRead the iris dataset.\nFilter the dataset based on Petal.Length\nCalculate the median of the Petal.Width per Species\n\nEvery step is executed immediately returning the intermediate results. This can be very wastefull as we might do work or load extra data that is not being used.\nIf we instead used the lazy API and waited on execution untill all the steps are defined then the query planner could perform various optimizations. In this case:\n\nPredicate pushdown: Apply filters as early as possible while reading the dataset, thus only reading rows with sepal length greater than 5.\nProjection pushdown: Select only the columns that are needed while reading the dataset, thus removing the need to load additional columns\n\n\n\n\n\n\n\nTip\n\n\n\nTo consult the list of optimisations made by Polars on queries in lazy mode, see this page..\n\n\nHere is the equivalent code using the lazy API. At the end of the query, don’t forget to use the collect() method to inform Polars that you want to execute it.\n\npl$scan_csv(\"examples/iris.csv\")$\n  filter(\n    pl$col(\"Petal.Length\") &gt; 5)$\n  groupby(\"Species\")$\n  agg(pl$col(\"Petal.Width\")$median())$\n  collect() # &lt;- don't forget collect() here!\n\nshape: (2, 2)\n┌────────────┬─────────────┐\n│ Species    ┆ Petal.Width │\n│ ---        ┆ ---         │\n│ str        ┆ f64         │\n╞════════════╪═════════════╡\n│ virginica  ┆ 2.1         │\n│ versicolor ┆ 1.6         │\n└────────────┴─────────────┘\n\n\n\n\n\n\n\n\nImportant\n\n\n\nUse lazy execution will signficantly lower the load on memory & CPU thus allowing you to fit bigger datasets in memory and process faster.\n\n\nThe next section will demonstrate this time saving. 👇\n\n\n4.2.2 Limits of lazy mode\nThere are some operations that cannot be performed in lazy mode (whether in polars or other lazy frameworks such as SQL database). One limitation is that Polars needs to know the column names and dtypes at each step of the query plan.\nFor example, we can’t pivot() (see here) in lazy mode as the column names are data-dependant following a pivot. Indeed, when you have to pivot() a DataFrame your future columns names cannot be predicted because it depends on what it is actually in your datasets!\nWhen you have to do operations that can be done in lazy mode, the recommandation is: - Running your query in lazy mode as far as possible;\n- Evaluating this lazy query with collect() when you need a non-lazy method;\n- Running the non-lazy methods;\n- Calling lazy() on the output to continue in lazy mode.\nHere’s an example:\n\npl$scan_parquet(\"Datasets/fakir_file.parquet\")$\n  # Call collect() because I need to pivot()\n  collect()$\n  pivot(\n    index = \"region\",\n    columns = \"priority\",\n    values = \"age\", \n    aggregate_function = \"mean\"\n  )$\n  # Continue in lazy mode\n  lazy()$\n  select(\n    pl$col(c(\"region\",\"Gold\",\"Platinium\"))\n  )$\n  collect()\n\nshape: (21, 3)\n┌────────────────────┬───────────┬───────────┐\n│ region             ┆ Gold      ┆ Platinium │\n│ ---                ┆ ---       ┆ ---       │\n│ str                ┆ f64       ┆ f64       │\n╞════════════════════╪═══════════╪═══════════╡\n│ Bretagne           ┆ 54.0      ┆ null      │\n│ Nord-Pas-de-Calais ┆ null      ┆ 81.0      │\n│ Île-de-France      ┆ 67.410169 ┆ null      │\n│ Basse-Normandie    ┆ 68.683417 ┆ null      │\n│ …                  ┆ …         ┆ …         │\n│ Champagne-Ardenne  ┆ null      ┆ null      │\n│ Pays de la Loire   ┆ null      ┆ null      │\n│ Limousin           ┆ null      ┆ null      │\n│ Haute-Normandie    ┆ 60.0      ┆ null      │\n└────────────────────┴───────────┴───────────┘"
  },
  {
    "objectID": "lazy_execution.html#lazy-vs-eager-mode-fight",
    "href": "lazy_execution.html#lazy-vs-eager-mode-fight",
    "title": "4  Lazy execution",
    "section": "4.3 Lazy vs eager mode : fight! ⚔️",
    "text": "4.3 Lazy vs eager mode : fight! ⚔️\nFor this fight, we’re going to use a fake dataset with 1 000 000 rows and 25 columns created with the {fakir} package. The code for creating this dataset is available at the beginning of this document.\nThis fight will take place over 3 rounds :\n\nWith an eager query versus a lazy query from a DataFrame\nWith an eager query versus a lazy query from a csv file\nWith an eager query versus a lazy query from a parquet file\n\n\n4.3.1 From a DataFrame\nFor this first round and as seen above, let’s start with a simple query from a DataFrame:\n\ntic()\n#| label: fight-eager_dataframe\npl$DataFrame(fake_data)$select(\n    pl$col(c(\"region\",\"departement\",\"priority\")) \n  )$\n  filter(\n    pl$col(\"region\") == \"Aquitaine\")\n\nshape: (6_517, 3)\n┌───────────┬────────────────┬──────────┐\n│ region    ┆ departement    ┆ priority │\n│ ---       ┆ ---            ┆ ---      │\n│ str       ┆ str            ┆ cat      │\n╞═══════════╪════════════════╪══════════╡\n│ Aquitaine ┆ Dordogne       ┆ Bronze   │\n│ Aquitaine ┆ Dordogne       ┆ Bronze   │\n│ Aquitaine ┆ Dordogne       ┆ Bronze   │\n│ Aquitaine ┆ Dordogne       ┆ Bronze   │\n│ …         ┆ …              ┆ …        │\n│ Aquitaine ┆ null           ┆ Bronze   │\n│ Aquitaine ┆ null           ┆ Gold     │\n│ Aquitaine ┆ Lot-et-Garonne ┆ Bronze   │\n│ Aquitaine ┆ null           ┆ Bronze   │\n└───────────┴────────────────┴──────────┘\n\ntoc()\n\n0.086 sec elapsed\n\n\nAs seen above, we’re going to use the lazy() method to convert a DataFrame to a LazyFrame:\n\ntic()\n#| label: fight-lazy_lazyframe\npl$DataFrame(fake_data)$lazy()$\n  select(\n    pl$col(c(\"region\",\"departement\",\"priority\")) \n  )$\n  filter(\n    pl$col(\"region\") == \"Aquitaine\")$\n  collect() # don't forget collect() here!\n\nshape: (6_517, 3)\n┌───────────┬────────────────┬──────────┐\n│ region    ┆ departement    ┆ priority │\n│ ---       ┆ ---            ┆ ---      │\n│ str       ┆ str            ┆ cat      │\n╞═══════════╪════════════════╪══════════╡\n│ Aquitaine ┆ Dordogne       ┆ Bronze   │\n│ Aquitaine ┆ Dordogne       ┆ Bronze   │\n│ Aquitaine ┆ Dordogne       ┆ Bronze   │\n│ Aquitaine ┆ Dordogne       ┆ Bronze   │\n│ …         ┆ …              ┆ …        │\n│ Aquitaine ┆ null           ┆ Bronze   │\n│ Aquitaine ┆ null           ┆ Gold     │\n│ Aquitaine ┆ Lot-et-Garonne ┆ Bronze   │\n│ Aquitaine ┆ null           ┆ Bronze   │\n└───────────┴────────────────┴──────────┘\n\ntoc()\n\n0.082 sec elapsed\n\n\n\n\n4.3.2 From a csv file\nNow, the eager mode is represented here by the read_csv() method…\n\ntic()\n#| label: fight-eager_read_csv\npl$read_csv(\"Datasets/fakir_file.csv\", infer_schema_length=0)$ \n  select(\n    pl$col(c(\"region\",\"departement\",\"priority\",\"age\")))$\n  with_columns(\n    pl$col(\"age\")$cast(pl$Int32,strict = FALSE))$\n  filter(\n    pl$col(\"region\") == \"Bretagne\")$\n  groupby(\"departement\",\"priority\")$\n  agg(pl$col(\"age\")$mean())\n\nshape: (9, 3)\n┌─────────────────┬──────────┬───────────┐\n│ departement     ┆ priority ┆ age       │\n│ ---             ┆ ---      ┆ ---       │\n│ str             ┆ str      ┆ f64       │\n╞═════════════════╪══════════╪═══════════╡\n│ Finistère       ┆ Bronze   ┆ 25.0      │\n│ Ille-et-Vilaine ┆ Silver   ┆ 53.0      │\n│ NA              ┆ Bronze   ┆ 25.0      │\n│ Côtes-d'Armor   ┆ Bronze   ┆ 19.0      │\n│ Morbihan        ┆ Gold     ┆ 54.0      │\n│ Ille-et-Vilaine ┆ Bronze   ┆ 30.936524 │\n│ NA              ┆ Silver   ┆ 18.0      │\n│ Côtes-d'Armor   ┆ Silver   ┆ 53.0      │\n│ Finistère       ┆ Silver   ┆ 27.0      │\n└─────────────────┴──────────┴───────────┘\n\ntoc()\n\n0.106 sec elapsed\n\n\n… while the lazy method is represented by the pl$scan_csv():\n\ntic()\npl$scan_csv(\"Datasets/fakir_file.csv\", infer_schema_length=0)$\n  select(\n    pl$col(c(\"region\",\"departement\",\"priority\",\"age\")))$\n  with_columns(\n    pl$col(\"age\")$cast(pl$Int32,strict = FALSE))$\n  filter(\n    pl$col(\"region\") == \"Bretagne\")$\n  groupby(\"departement\",\"priority\")$\n  agg(pl$col(\"age\")$mean())$\n  collect()\n\nshape: (9, 3)\n┌─────────────────┬──────────┬───────────┐\n│ departement     ┆ priority ┆ age       │\n│ ---             ┆ ---      ┆ ---       │\n│ str             ┆ str      ┆ f64       │\n╞═════════════════╪══════════╪═══════════╡\n│ Finistère       ┆ Silver   ┆ 27.0      │\n│ Ille-et-Vilaine ┆ Bronze   ┆ 30.936524 │\n│ NA              ┆ Bronze   ┆ 25.0      │\n│ Côtes-d'Armor   ┆ Bronze   ┆ 19.0      │\n│ NA              ┆ Silver   ┆ 18.0      │\n│ Côtes-d'Armor   ┆ Silver   ┆ 53.0      │\n│ Ille-et-Vilaine ┆ Silver   ┆ 53.0      │\n│ Morbihan        ┆ Gold     ┆ 54.0      │\n│ Finistère       ┆ Bronze   ┆ 25.0      │\n└─────────────────┴──────────┴───────────┘\n\ntoc()\n\n0.04 sec elapsed\n\n\nWe can clearly see that we save a lot of time when executing the lazy version of the code!\n\n\n4.3.3 From a parquet file\nThe read_parquet() method has not been implemented in the R Polars package, but for this fight we will use arrow::read_parquet() and {dplyr} syntax, which will compete with pl$scan_parquet().\n\ntic()\narrow::read_parquet(\"Datasets/fakir_file.parquet\", as_data_frame = FALSE) |&gt;\n  filter(region == \"Bretagne\") |&gt; \n  group_by(departement,priority) |&gt; \n  summarise(mymean=mean(age, na.rm = TRUE)) |&gt; \n  arrange(departement) |&gt;\n  collect()\n\n# A tibble: 9 × 3\n# Groups:   departement [5]\n  departement     priority mymean\n  &lt;chr&gt;           &lt;fct&gt;     &lt;dbl&gt;\n1 Côtes-d'Armor   Bronze     19  \n2 Côtes-d'Armor   Silver     53  \n3 Finistère       Bronze     25  \n4 Finistère       Silver     27  \n5 Ille-et-Vilaine Silver     53  \n6 Ille-et-Vilaine Bronze     30.9\n7 Morbihan        Gold       54  \n8 &lt;NA&gt;            Bronze     25  \n9 &lt;NA&gt;            Silver     18  \n\ntoc()\n\n0.252 sec elapsed\n\n\n\ntic()\npl$scan_parquet(\"Datasets/fakir_file.parquet\")$\n  filter( \n    pl$col(\"region\") == \"Bretagne\")$\n  groupby(c(\"departement\",\"priority\"))$\n  agg(\n    pl$col(c(\"age\"))$mean()\n)$sort(\"departement\")$\n  collect()\n\nshape: (9, 3)\n┌─────────────────┬──────────┬───────────┐\n│ departement     ┆ priority ┆ age       │\n│ ---             ┆ ---      ┆ ---       │\n│ str             ┆ cat      ┆ f64       │\n╞═════════════════╪══════════╪═══════════╡\n│ null            ┆ Bronze   ┆ 25.0      │\n│ null            ┆ Silver   ┆ 18.0      │\n│ Côtes-d'Armor   ┆ Bronze   ┆ 19.0      │\n│ Côtes-d'Armor   ┆ Silver   ┆ 53.0      │\n│ Finistère       ┆ Silver   ┆ 27.0      │\n│ Finistère       ┆ Bronze   ┆ 25.0      │\n│ Ille-et-Vilaine ┆ Bronze   ┆ 30.936524 │\n│ Ille-et-Vilaine ┆ Silver   ┆ 53.0      │\n│ Morbihan        ┆ Gold     ┆ 54.0      │\n└─────────────────┴──────────┴───────────┘\n\ntoc()\n\n0.013 sec elapsed\n\n\nAnd it’s another victory for the lazy execution!\n\n\n\n\n\n\nImportant\n\n\n\nNote that the {arrow} package also have ability to scan parquet files in a lazy way with the arrow::open_dataset function.\n\ntic()\narrow::open_dataset(\"Datasets/fakir_file.parquet\") |&gt; \n  filter(region == \"Bretagne\") |&gt;\n  group_by(departement,priority) |&gt; \n  summarise(mymean=mean(age, na.rm = TRUE)) |&gt;\n  arrange(departement) |&gt;\n  collect()\n\n# A tibble: 9 × 3\n# Groups:   departement [5]\n  departement     priority mymean\n  &lt;chr&gt;           &lt;fct&gt;     &lt;dbl&gt;\n1 Côtes-d'Armor   Bronze     19  \n2 Côtes-d'Armor   Silver     53  \n3 Finistère       Bronze     25  \n4 Finistère       Silver     27  \n5 Ille-et-Vilaine Silver     53  \n6 Ille-et-Vilaine Bronze     30.9\n7 Morbihan        Gold       54  \n8 &lt;NA&gt;            Bronze     25  \n9 &lt;NA&gt;            Silver     18  \n\ntoc()\n\n0.105 sec elapsed"
  },
  {
    "objectID": "benchmarking.html#from-an-r-object",
    "href": "benchmarking.html#from-an-r-object",
    "title": "5  Benchmarking",
    "section": "5.1 From an R object",
    "text": "5.1 From an R object\nThis section analyses the different methods for making a query from an R object already loaded in memory.\nLet’s start by comparing polars with R base, dplyr and data.table.\n\npolarsR basedplyrdata.table\n\n\n\nrobject_polars &lt;- function() {\n  \n  DataMultiTypes_pl$\n    # Filter rows\n    filter(\n      pl$col(\"colInt\")&gt;2000 & pl$col(\"colInt\")&lt;8000\n    )$\n    # Grouping and aggregation\n    groupby(\n      \"colString\")$\n    agg(\n      pl$col(\"colInt\")$min()$alias(\"min_colInt\"),\n      pl$col(\"colInt\")$mean()$alias(\"mean_colInt\"),\n      pl$col(\"colInt\")$max()$alias(\"max_colInt\"),\n      pl$col(\"colNum\")$min()$alias(\"min_colNum\"),\n      pl$col(\"colNum\")$mean()$alias(\"mean_colNum\"),\n      pl$col(\"colNum\")$max()$alias(\"max_colNum\")\n    )\n}\n\n\n\n\nrobject_rbase &lt;- function() {\n  \n  # Grouping and aggregation from data filtered\n  aggregate(cbind(colInt, colNum) ~ colString, \n            data = DataMultiTypes[DataMultiTypes$colInt&gt;2000 & DataMultiTypes$colInt&lt;8000,], \n            FUN = function(x) c(mean = mean(x), \n                                min = min(x), \n                                max = max(x)))\n  \n}\n\n\n\n\nrobject_dplyr &lt;- function() {\n  \n  DataMultiTypes |&gt;\n    \n   # Filter rows\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n      ) |&gt;\n    \n    # Grouping and aggregation\n    group_by(colString) |&gt; \n    \n    summarise(\n      min_colInt = min(colInt),\n      mean_colInt = mean(colInt),\n      mas_colInt = max(colInt),\n      min_colNum = min(colNum),\n      mean_colNum = mean(colNum),\n      max_colNum = max(colNum)\n  )\n\n}\n\n\n\n\nrobject_dt &lt;- function() {\n  \n  as.data.table(DataMultiTypes)[\n    \n    colInt &gt; 2000 & colInt &lt; 8000\n    \n  ][, .(min_colInt = min(colInt),\n        mean_colInt = mean(colInt),\n        mas_colInt = max(colInt),\n        min_colNum = min(colNum),\n        mean_colNum = mean(colNum),\n        max_colNum = max(colNum)),\n    \n    by = colString\n  ]\n}\n\n\n\n\nNow let’s look at how to use the DuckDb engine on R objects.\nThere are 3 main possibilities:\n\nTo use the DuckDB engine to query a R object with dplyr, you can use the duckdb::duckdb_register() method and then the dplyr::tbl() method to pass your dplyr instructions (dplyr/DuckDB).\nTo use the DuckDB engine to query a R object with the standard DBI methods, you can use the duckdb::duckdb_register() method and then the DBI::dbGetQuery() method to pass your SQL query (SQL/DuckDB).\nTo use the DuckDB engine to query a R object in combination with {arrow} package, you can use the arrow::to_duckdb() and then pass your dplyr instructions (dplyr/arrow/DuckDB).\n\n\ndplyr/DuckDBSQL/DuckDBdplyr/arrow/DuckDB\n\n\n\nrobject_duckdb_dplyr &lt;- function(variables) {\n  \n  con &lt;- DBI::dbConnect(duckdb::duckdb())\n\n  duckdb::duckdb_register(con, \"DataMultiTypes\", DataMultiTypes)\n\n  tbl(con, \"DataMultiTypes\") |&gt;\n    \n    # Filter rows\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n    ) |&gt;\n    # Grouping and aggregation\n    group_by(colString) |&gt; \n    summarise(\n      min_colInt = min(colInt, na.rm = TRUE),\n      mean_colInt = mean(colInt, na.rm = TRUE),\n      mas_colInt = max(colInt, na.rm = TRUE),\n      min_colNum = min(colNum, na.rm = TRUE),\n      mean_colNum = mean(colNum, na.rm = TRUE),\n      max_colNum = max(colNum, na.rm = TRUE)\n    ) |&gt;\n    collect()\n  \n  DBI::dbDisconnect(con, shutdown=TRUE)\n  \n}\n\n\n\n\nrobject_duckdb_sql &lt;- function(variables) {\n  \n  con &lt;- DBI::dbConnect(duckdb::duckdb())\n\n  duckdb::duckdb_register(con, \"DataMultiTypes\", DataMultiTypes)\n\n  DBI::dbGetQuery(\n    con, \n    \"SELECT colString,\n           MIN(colInt) AS min_colInt,\n           AVG(colInt) AS mean_colInt,\n           MAX(colInt) AS max_colInt,\n           MIN(colNum) AS min_colNum,\n           AVG(colNum) AS mean_colNum,\n           MAX(colNum) AS max_colNum\n    FROM (\n        SELECT colString,\n               colInt,\n               colNum\n        FROM DataMultiTypes\n        WHERE colInt &gt; 2000 AND colInt &lt; 8000\n) AS filtered_data\nGROUP BY colString;\")\n  \n  DBI::dbDisconnect(con, shutdown=TRUE)\n  \n}\n\n\n\n\nrobject_duckdb_arrow_dplyr &lt;- function(variables) {\n          \n  DataMultiTypes |&gt;\n    \n    to_duckdb() |&gt;\n    \n    # Filter rows\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n    ) |&gt;\n    # Grouping and aggregation\n    group_by(colString) |&gt; \n    \n    summarise(\n      min_colInt = min(colInt, na.rm = TRUE),\n      mean_colInt = mean(colInt, na.rm = TRUE),\n      mas_colInt = max(colInt, na.rm = TRUE),\n      min_colNum = min(colNum, na.rm = TRUE),\n      mean_colNum = mean(colNum, na.rm = TRUE),\n      max_colNum = max(colNum, na.rm = TRUE)\n    ) \n  \n}\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nOne of the advantages of using the DuckDB engine and dplyr may be to use a feature implemented by DuckDB but not yet by Arrow. We can do the opposite, and return to the Arrow engine with arrow::to_arrow().\nHowever, the benchmark results are clear: SQL queries are by far the fastest! 🏆\n\n\n\n5.1.1 Results with a R object\n\nmicrobenchmark(\n  robject_polars(),\n  robject_rbase(),\n  robject_dplyr(),\n  robject_dt(),\n  robject_duckdb_dplyr(),\n  robject_duckdb_sql(),\n  robject_duckdb_arrow_dplyr(),\n  times = 5\n ) \n\nUnit: milliseconds\n                         expr      min       lq      mean   median       uq\n             robject_polars()  18.6219  20.7776  24.95742  21.3858  31.2507\n              robject_rbase() 195.2656 214.2676 216.81914 216.9113 224.5080\n              robject_dplyr()  28.8766  29.5144  39.04676  39.7682  48.3565\n                 robject_dt()  39.5213  40.3337  50.92768  47.3632  58.8975\n       robject_duckdb_dplyr() 289.8819 291.5973 300.83822 300.9643 307.8014\n         robject_duckdb_sql()  68.4872  69.1932  74.20600  72.9217  79.5441\n robject_duckdb_arrow_dplyr() 218.3563 224.5558 243.24250 230.6395 237.6823\n      max neval\n  32.7511     5\n 233.1432     5\n  48.7181     5\n  68.5227     5\n 313.9462     5\n  80.8838     5\n 304.9786     5\n\n\n👉 Conclusion of this little benchmark using R objects already loaded in memory: the fastest to run are polars and dplyr followed closely by data.table. 🏆🏆🏆\nThe worst performer is surprisingly duckdb with the dplyr syntax, while duckdb with the SQL language does very well and comes 4th in this ranking."
  },
  {
    "objectID": "benchmarking.html#from-a-csv-file",
    "href": "benchmarking.html#from-a-csv-file",
    "title": "5  Benchmarking",
    "section": "5.2 From a csv file",
    "text": "5.2 From a csv file\nFor this comparison, we will use :\n\nFor polars (eager), the pl$read_csv() method\nFor polars (lazy), the pl$scan_csv() method\nFor R base, the read.csv() method\nFor dplyr, the readr::read_csv() method\nFor data.table, the data.table::fread() method\n\n\npolars (eager)polars (lazy)R basedplyrdplyr (Acero)data.table\n\n\n\ncsv_eager_polars &lt;- function() {\n# Reading the csv file (eager mode)\nresult_agg &lt;- pl$read_csv(path = \"Datasets/DataMultiTypes.csv\")$\n  # Conversion of 2 columns to Date format\n  with_columns(\n    pl$col(\"colDate1\")$str$strptime(pl$Date, \"%F %T\", strict = FALSE),\n    pl$col(\"colDate2\")$str$strptime(pl$Date, \"%F %T\", strict = FALSE)\n  )$\n  # Creation of a diff column between 2 dates (in days)\n  with_columns(\n    (pl$col(\"colDate2\") - pl$col(\"colDate1\"))$dt$days()$alias(\"diff\")\n  )$\n  # Filter rows\n  filter(\n    pl$col(\"colInt\")&gt;2000 & pl$col(\"colInt\")&lt;8000\n  )$\n  # Grouping and aggregation\n  groupby(\n    \"colString\")$\n  agg(\n    pl$col(\"colInt\")$min()$alias(\"min_colInt\"),\n    pl$col(\"colInt\")$mean()$alias(\"mean_colInt\"),\n    pl$col(\"colInt\")$max()$alias(\"max_colInt\"),\n    pl$col(\"colNum\")$min()$alias(\"min_colNum\"),\n    pl$col(\"colNum\")$mean()$alias(\"mean_colNum\"),\n    pl$col(\"colNum\")$max()$alias(\"max_colNum\")\n  )\n  \n  return(result_agg)\n}\ntic()\ncsv_eager_polars()\n\nshape: (3, 7)\n┌───────────┬────────────┬─────────────┬────────────┬────────────┬─────────────┬────────────┐\n│ colString ┆ min_colInt ┆ mean_colInt ┆ max_colInt ┆ min_colNum ┆ mean_colNum ┆ max_colNum │\n│ ---       ┆ ---        ┆ ---         ┆ ---        ┆ ---        ┆ ---         ┆ ---        │\n│ str       ┆ i64        ┆ f64         ┆ i64        ┆ f64        ┆ f64         ┆ f64        │\n╞═══════════╪════════════╪═════════════╪════════════╪════════════╪═════════════╪════════════╡\n│ C         ┆ 2001       ┆ 5001.243285 ┆ 7999       ┆ 0.00003    ┆ 0.501472    ┆ 0.999992   │\n│ B         ┆ 2001       ┆ 5004.31148  ┆ 7999       ┆ 0.000034   ┆ 0.500546    ┆ 0.999986   │\n│ A         ┆ 2001       ┆ 4998.624945 ┆ 7999       ┆ 0.000038   ┆ 0.498445    ┆ 0.999988   │\n└───────────┴────────────┴─────────────┴────────────┴────────────┴─────────────┴────────────┘\n\ntoc()\n\n0.249 sec elapsed\n\n\n\n\n\ncsv_lazy_polars &lt;- function() {\n# Reading the csv file (eager mode)\nresult_agg &lt;- pl$scan_csv(path = \"Datasets/DataMultiTypes.csv\")$\n  # Conversion of 2 columns to Date format\n  with_columns(\n    pl$col(\"colDate1\")$str$strptime(pl$Date, \"%F %T\", strict = FALSE),\n    pl$col(\"colDate2\")$str$strptime(pl$Date, \"%F %T\", strict = FALSE)\n  )$\n  # Creation of a diff column between 2 dates (in days)\n  with_columns(\n    (pl$col(\"colDate2\") - pl$col(\"colDate1\"))$dt$days()$alias(\"diff\")\n  )$\n  # Filter rows\n  filter(\n    pl$col(\"colInt\")&gt;2000 & pl$col(\"colInt\")&lt;8000\n  )$\n  # Grouping and aggregation\n  groupby(\n    \"colString\")$\n  agg(\n    pl$col(\"colInt\")$min()$alias(\"min_colInt\"),\n    pl$col(\"colInt\")$mean()$alias(\"mean_colInt\"),\n    pl$col(\"colInt\")$max()$alias(\"max_colInt\"),\n    pl$col(\"colNum\")$min()$alias(\"min_colNum\"),\n    pl$col(\"colNum\")$mean()$alias(\"mean_colNum\"),\n    pl$col(\"colNum\")$max()$alias(\"max_colNum\")\n  )\n  \n  return(result_agg)\n}\ntic()\ncsv_lazy_polars()$collect()\n\nshape: (3, 7)\n┌───────────┬────────────┬─────────────┬────────────┬────────────┬─────────────┬────────────┐\n│ colString ┆ min_colInt ┆ mean_colInt ┆ max_colInt ┆ min_colNum ┆ mean_colNum ┆ max_colNum │\n│ ---       ┆ ---        ┆ ---         ┆ ---        ┆ ---        ┆ ---         ┆ ---        │\n│ str       ┆ i64        ┆ f64         ┆ i64        ┆ f64        ┆ f64         ┆ f64        │\n╞═══════════╪════════════╪═════════════╪════════════╪════════════╪═════════════╪════════════╡\n│ C         ┆ 2001       ┆ 5001.243285 ┆ 7999       ┆ 0.00003    ┆ 0.501472    ┆ 0.999992   │\n│ A         ┆ 2001       ┆ 4998.624945 ┆ 7999       ┆ 0.000038   ┆ 0.498445    ┆ 0.999988   │\n│ B         ┆ 2001       ┆ 5004.31148  ┆ 7999       ┆ 0.000034   ┆ 0.500546    ┆ 0.999986   │\n└───────────┴────────────┴─────────────┴────────────┴────────────┴─────────────┴────────────┘\n\ntoc()\n\n0.075 sec elapsed\n\n\n\n\n\ncsv_rbase &lt;- function() {\n  \n  # Reading the csv file\n  result &lt;- read.csv(\"Datasets/DataMultiTypes.csv\")\n  \n  # Conversion of 2 columns to Date format\n  result$colDate1 &lt;- as.Date(result$colDate1)\n  result$colDate2 &lt;- as.Date(result$colDate2)\n  \n  # Creation of a diff column between 2 dates (in days)\n  result$diff &lt;- round(\n    as.integer(\n      difftime(\n        result$colDate2,\n        result$colDate1,\n        units = \"days\")\n      ),\n    0)\n  \n  # Filter rows\n  result &lt;- result[result$colInt&gt;2000 & result$colInt&lt;8000,]\n  \n  # Grouping and aggregation\n  result_agg &lt;- aggregate(cbind(colInt, colNum) ~ colString, \n                          data = result, \n                          FUN = function(x) c(mean = mean(x), \n                                              min = min(x), \n                                              max = max(x)))\n  \n  return(result_agg)\n}\n\ntic()\nres_rbase &lt;- csv_rbase()\ntoc()\n\n8.512 sec elapsed\n\nprint(res_rbase)\n\n  colString colInt.mean colInt.min colInt.max  colNum.mean   colNum.min\n1         A    4998.625   2001.000   7999.000 4.984446e-01 3.794138e-05\n2         B    5004.311   2001.000   7999.000 5.005457e-01 3.385660e-05\n3         C    5001.243   2001.000   7999.000 5.014723e-01 3.045052e-05\n    colNum.max\n1 9.999879e-01\n2 9.999863e-01\n3 9.999921e-01\n\n\n\n\n\ncsv_dplyr &lt;- function() {\n  \n  # Reading the csv file\n  result &lt;- readr::read_csv(\"Datasets/DataMultiTypes.csv\", show_col_types = FALSE)\n  \n  # Conversion of 2 columns to Date format\n  result &lt;- result |&gt;\n    mutate(\n      colDate1 = as.Date(colDate1),\n      colDate2 = as.Date(colDate2)\n    )\n  \n  # Creation of a diff column between 2 dates (in days)\n  result &lt;- result |&gt; \n    mutate(diff = round(as.integer(difftime(colDate2, colDate1, units = \"days\")),0))\n  \n  # Filter rows\n  result &lt;- result |&gt;\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n      )\n  \n  # Grouping and aggregation\n  result_agg &lt;- result |&gt;\n    group_by(colString) |&gt; \n    summarise(\n      min_colInt = min(colInt),\n      mean_colInt = mean(colInt),\n      mas_colInt = max(colInt),\n      min_colNum = min(colNum),\n      mean_colNum = mean(colNum),\n      max_colNum = max(colNum)\n  )\n  \n  return(result_agg)\n}\n\ntic()\nres_dplyr &lt;- csv_dplyr()\ntoc()\n\n0.643 sec elapsed\n\nprint(res_dplyr)\n\n# A tibble: 3 × 7\n  colString min_colInt mean_colInt mas_colInt min_colNum mean_colNum max_colNum\n  &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 A               2001       4999.       7999  0.0000379       0.498       1.00\n2 B               2001       5004.       7999  0.0000339       0.501       1.00\n3 C               2001       5001.       7999  0.0000305       0.501       1.00\n\n\n\n\n\ncsv_arrow &lt;- function() {\n  \n  # Reading the csv file\n  result &lt;- arrow::read_csv_arrow(\"Datasets/DataMultiTypes.csv\", as_data_frame = FALSE)\n  \n  # Conversion of 2 columns to Date format\n  result &lt;- result |&gt;\n    mutate(\n      colDate1 = as.Date(colDate1),\n      colDate2 = as.Date(colDate2)\n    )\n  \n  # Creation of a diff column between 2 dates (in days)\n  result &lt;- result |&gt;\n    # difftime(unit = \"days\") is not supported in arrow yet\n    mutate(diff = round(as.integer64(difftime(colDate2, colDate1)) %/% (60 * 60 * 24), 0))\n  \n  # Filter rows\n  result &lt;- result |&gt;\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n      )\n  \n  # Grouping and aggregation\n  result_agg &lt;- result |&gt;\n    group_by(colString) |&gt; \n    summarise(\n      min_colInt = min(colInt),\n      mean_colInt = mean(colInt),\n      mas_colInt = max(colInt),\n      min_colNum = min(colNum),\n      mean_colNum = mean(colNum),\n      max_colNum = max(colNum)\n  ) |&gt;\n    collect()\n\n  return(result_agg)\n}\n\ntic()\nres_arrow &lt;- csv_arrow()\ntoc()\n\n0.316 sec elapsed\n\nprint(res_arrow)\n\n# A tibble: 3 × 7\n  colString min_colInt mean_colInt mas_colInt min_colNum mean_colNum max_colNum\n  &lt;chr&gt;          &lt;int&gt;       &lt;dbl&gt;      &lt;int&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 A               2001       4999.       7999  0.0000379       0.498       1.00\n2 C               2001       5001.       7999  0.0000305       0.501       1.00\n3 B               2001       5004.       7999  0.0000339       0.501       1.00\n\n\n\n\n\ncsv_dt &lt;- function() {\n  \n  result_agg &lt;- as.data.table(data.table::fread(\"Datasets/DataMultiTypes.csv\"))[, `:=`(\n    \n  colDate1 = as.Date(colDate1),\n  colDate2 = as.Date(colDate2),\n  diff = as.integer(difftime(colDate2, colDate1, units = \"days\"))\n  \n)][colInt &gt; 2000 & colInt &lt; 8000, .(\n  \n  min_colInt = min(colInt),\n  mean_colInt = mean(colInt),\n  max_colInt = max(colInt),\n  min_colNum = min(colNum),\n  mean_colNum = mean(colNum),\n  max_colNum = max(colNum)\n  \n), by = colString]\n  \n  return(result_agg)\n}\ntic()\ncsv_dt()\n\n   colString min_colInt mean_colInt max_colInt   min_colNum mean_colNum\n1:         B       2001    5004.311       7999 3.385660e-05   0.5005457\n2:         C       2001    5001.243       7999 3.045052e-05   0.5014723\n3:         A       2001    4998.625       7999 3.794138e-05   0.4984446\n   max_colNum\n1:  0.9999863\n2:  0.9999921\n3:  0.9999879\n\ntoc()\n\n0.305 sec elapsed\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe data processing performed is not entirely equivalent, since it includes in addition:\n- for polars (lazy mode), conversion to data.frame R at the end of processing\n- for data.table, conversion to dt format at the start, then conversion to data.frame R at the end of processing\n\n\n\n5.2.1 Results eager vs lazy mode\n\ncsv_bmk &lt;- microbenchmark(\n  \"polars (eager) from csv file\" = csv_eager_polars(),\n  \"polars (lazy) from csv file\" = csv_lazy_polars()$collect(),\n  \"R base - from csv file\" = csv_rbase(),\n  \"dplyr - from csv file\" = csv_dplyr(),\n  \"dplyr (Acero) - from csv file\" = csv_arrow(),\n  \"data.table - from csv file\" = csv_dt(),\n  times = 5\n )\ncsv_bmk\n\nUnit: milliseconds\n                          expr       min        lq       mean    median\n  polars (eager) from csv file  238.6106  239.9899  243.86062  241.5123\n   polars (lazy) from csv file   69.9565   70.1934   73.60146   70.4803\n        R base - from csv file 7160.1802 7376.7072 7495.97596 7390.0756\n         dplyr - from csv file  480.7333  507.3747  534.68212  517.9662\n dplyr (Acero) - from csv file  185.9720  186.2465  193.43840  196.5292\n    data.table - from csv file  223.2953  228.7601  312.96244  281.3352\n        uq       max neval\n  248.8952  250.2951     5\n   71.0704   86.3067     5\n 7561.6750 7991.2418     5\n  580.0369  587.2995     5\n  198.7684  199.6759     5\n  355.8614  475.5602     5\n\n\n👉 Conclusion of this little benchmark based on csv files: the big winners are polars (eager mode) and dplyr with {arrow}. The results will undoubtedly be even better with polars (lazy mode)… 🏆🏆🏆\nTO DO !!!"
  },
  {
    "objectID": "benchmarking.html#from-an-unique-parquet-file",
    "href": "benchmarking.html#from-an-unique-parquet-file",
    "title": "5  Benchmarking",
    "section": "5.3 From an unique parquet file",
    "text": "5.3 From an unique parquet file\nFor this comparison on unique parquet file, we will use :\n\nFor polars (lazy), the pl$scan_parquet() method\nFor arrow (eager), the arrow::read_parquet() method\nFor arrow (lazy), the arrow::open_dataset() method\nFor Duckdb and SQL, the arrow::read_parquet() and DBI::dbGetQuery() methods\n\n\n\n\n\n\n\nNote\n\n\n\nWith arrow, you can use the following verbs from the tidyverse to do transformations on your tables.\n\n\n\npolars (lazy)arrow (eager)arrow (lazy)Duckdb and SQL\n\n\n\nparquet_polars_lazy &lt;- function(variables) {\n  \n  result &lt;- pl$scan_parquet(file = \"Datasets/DataMultiTypes.parquet\")$\n    # Conversion of 2 columns to Date format\n    with_columns(\n      pl$col(\"colDate1\")$str$strptime(pl$Date, \"%F %T\", strict = FALSE),\n      pl$col(\"colDate2\")$str$strptime(pl$Date, \"%F %T\", strict = FALSE)\n    )$\n    # Filter rows\n    filter(\n      pl$col(\"colInt\")&gt;2000 & pl$col(\"colInt\")&lt;8000\n    )$\n    # Grouping and aggregation\n    groupby(\n      \"colString\")$\n    agg(\n      pl$col(\"colInt\")$min()$alias(\"min_colInt\"),\n      pl$col(\"colInt\")$mean()$alias(\"mean_colInt\"),\n      pl$col(\"colInt\")$max()$alias(\"max_colInt\"),\n      pl$col(\"colNum\")$min()$alias(\"min_colNum\"),\n      pl$col(\"colNum\")$mean()$alias(\"mean_colNum\"),\n      pl$col(\"colNum\")$max()$alias(\"max_colNum\")\n    )\n  \n  return(result)\n}\ntic()\nparquet_polars_lazy()$collect()$to_data_frame()\n\n  colString min_colInt mean_colInt max_colInt   min_colNum mean_colNum\n1         A       2001    4998.625       7999 3.794138e-05   0.4984446\n2         B       2001    5004.311       7999 3.385660e-05   0.5005457\n3         C       2001    5001.243       7999 3.045052e-05   0.5014723\n  max_colNum\n1  0.9999879\n2  0.9999863\n3  0.9999921\n\ntoc()\n\n0.046 sec elapsed\n\n\n\n\n\narrow_eager &lt;- function(variables) {\n  \n  result &lt;- arrow::read_parquet(\"Datasets/DataMultiTypes.parquet\") |&gt;\n    \n    mutate(\n      # Conversion of 2 columns to Date format\n      colDate1 = as.Date(colDate1),\n      colDate2 = as.Date(colDate2)\n    ) |&gt;\n    # Filter rows\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n    ) |&gt;\n    # Grouping and aggregation\n    group_by(colString) |&gt; \n    summarise(\n      min_colInt = min(colInt),\n      mean_colInt = mean(colInt),\n      mas_colInt = max(colInt),\n      min_colNum = min(colNum),\n      mean_colNum = mean(colNum),\n      max_colNum = max(colNum)\n  )\n  \n  return(result)\n  \n}\ntic()\narrow_eager()\n\n# A tibble: 3 × 7\n  colString min_colInt mean_colInt mas_colInt min_colNum mean_colNum max_colNum\n  &lt;chr&gt;          &lt;int&gt;       &lt;dbl&gt;      &lt;int&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 A               2001       4999.       7999  0.0000379       0.498       1.00\n2 B               2001       5004.       7999  0.0000339       0.501       1.00\n3 C               2001       5001.       7999  0.0000305       0.501       1.00\n\ntoc()\n\n0.118 sec elapsed\n\n\n\n\n\narrow_lazy &lt;- function(variables) {\n  \n  result &lt;- arrow::open_dataset(\"Datasets/DataMultiTypes.parquet\") |&gt;\n    \n    mutate(\n      # Conversion of 2 columns to Date format\n      colDate1 = as.Date(colDate1),\n      colDate2 = as.Date(colDate2)\n    ) |&gt;\n    # Filter rows\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n    ) |&gt;\n    # Grouping and aggregation\n    group_by(colString) |&gt; \n    summarise(\n      min_colInt = min(colInt),\n      mean_colInt = mean(colInt),\n      mas_colInt = max(colInt),\n      min_colNum = min(colNum),\n      mean_colNum = mean(colNum),\n      max_colNum = max(colNum)\n  )\n  \n  return(result)\n  \n}\ntic()\narrow_lazy() |&gt; collect()\n\n# A tibble: 3 × 7\n  colString min_colInt mean_colInt mas_colInt min_colNum mean_colNum max_colNum\n  &lt;chr&gt;          &lt;int&gt;       &lt;dbl&gt;      &lt;int&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 B               2001       5004.       7999  0.0000339       0.501       1.00\n2 C               2001       5001.       7999  0.0000305       0.501       1.00\n3 A               2001       4999.       7999  0.0000379       0.498       1.00\n\ntoc()\n\n0.143 sec elapsed\n\n\n\n\n\nparquet_duckdb_sql &lt;- function(variables) {\n  \n  con &lt;- dbConnect(duckdb::duckdb())\n  \n  result &lt;- dbGetQuery(\n    con, \n    \"SELECT colString,\n           MIN(colInt) AS min_colInt,\n           AVG(colInt) AS mean_colInt,\n           MAX(colInt) AS max_colInt,\n           MIN(colNum) AS min_colNum,\n           AVG(colNum) AS mean_colNum,\n           MAX(colNum) AS max_colNum\n    FROM (\n        SELECT colString,\n               colInt,\n               colNum\n        FROM read_parquet('Datasets/DataMultiTypes.parquet')\n        WHERE colInt &gt; 2000 AND colInt &lt; 8000\n) AS filtered_data\nGROUP BY colString;\")\n  \n  dbDisconnect(con, shutdown=TRUE)\n  \n  return(result)\n}\ntic()\nparquet_duckdb_sql()\n\n  colString min_colInt mean_colInt max_colInt   min_colNum mean_colNum\n1         B       2001    5004.311       7999 3.385660e-05   0.5005457\n2         C       2001    5001.243       7999 3.045052e-05   0.5014723\n3         A       2001    4998.625       7999 3.794138e-05   0.4984446\n  max_colNum\n1  0.9999863\n2  0.9999921\n3  0.9999879\n\ntoc()\n\n0.08 sec elapsed\n\n\n\n\n\n\n5.3.1 Results for unique parquet file\n\nunique_parquet_bmk &lt;- microbenchmark(\n  \"polars (lazy) - from unique parquet file\" = parquet_polars_lazy()$collect()$to_data_frame(),\n  \"arrow (eager) - from unique parquet file\" = arrow_eager(),\n  \"arrow (lazy) - from unique parquet file\" = arrow_lazy() |&gt; collect(),\n  \"Duckdb and SQL - from unique parquet file\" = parquet_duckdb_sql(),\n  times = 5\n )\nprint(unique_parquet_bmk)\n\nUnit: milliseconds\n                                      expr      min       lq      mean   median\n  polars (lazy) - from unique parquet file  33.0525  33.6470  36.55972  33.9424\n  arrow (eager) - from unique parquet file  82.8215  85.7903  91.34888  87.7755\n   arrow (lazy) - from unique parquet file 102.4740 102.7013 107.52028 103.7083\n Duckdb and SQL - from unique parquet file  76.9753  77.2823  79.36308  77.4298\n       uq      max neval\n  34.0775  48.0792     5\n  95.1018 105.2553     5\n 110.9548 117.7630     5\n  77.6968  87.4312     5\n\n\n👉 Conclusion of this little benchmark based on unique parquet files: the big winner is polars (lazy mode) ! 🏆🏆🏆"
  },
  {
    "objectID": "benchmarking.html#from-a-partitioned-parquet-file",
    "href": "benchmarking.html#from-a-partitioned-parquet-file",
    "title": "5  Benchmarking",
    "section": "5.4 From a partitioned parquet file",
    "text": "5.4 From a partitioned parquet file\nLet’s now look at how to perform queries on partitioned files.\nThe structure of partitioned files on the disk is as follows:\n\nfs::dir_tree(path = \"Datasets/DataMultiTypes/\")\n\nDatasets/DataMultiTypes/\n├── colFactor=High\n│   └── part-0.parquet\n├── colFactor=Low\n│   └── part-0.parquet\n└── colFactor=Medium\n    └── part-0.parquet\n\n\nFor this comparison, we will use :\n\nFor arrow (lazy), the arrow::open_dataset() method\nFor dplyr (duckdb), the DBI::dbConnect, dplyr::tbl() and arrow::read_parquet() methods\nFor polars (lazy), the pl$scan_parquet() method\n\n\narrow (lazy)dplyr (duckdb)polars (lazy)\n\n\n\npartitioned_parquet_arrow_lazy &lt;- function(variables) {\n  \n  result &lt;- arrow::open_dataset(\n    \"Datasets/DataMultiTypes/\",\n    partitioning = arrow::schema(colFactor = arrow::utf8())) |&gt;\n    \n    mutate(\n      # Conversion of 2 columns to Date format\n      colDate1 = as.Date(colDate1),\n      colDate2 = as.Date(colDate2)\n    ) |&gt;\n    # Filter rows\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n    ) |&gt;\n    # Grouping and aggregation\n    group_by(colString) |&gt; \n    summarise(\n      min_colInt = min(colInt),\n      mean_colInt = mean(colInt),\n      mas_colInt = max(colInt),\n      min_colNum = min(colNum),\n      mean_colNum = mean(colNum),\n      max_colNum = max(colNum)\n    ) |&gt; \n    collect()\n  \n  return(result)\n  \n}\ntic()\npartitioned_parquet_arrow_lazy() \n\n# A tibble: 3 × 7\n  colString min_colInt mean_colInt mas_colInt min_colNum mean_colNum max_colNum\n  &lt;chr&gt;          &lt;int&gt;       &lt;dbl&gt;      &lt;int&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 B               2001       5004.       7999  0.0000339       0.501       1.00\n2 C               2001       5001.       7999  0.0000305       0.501       1.00\n3 A               2001       4999.       7999  0.0000379       0.498       1.00\n\ntoc()\n\n0.142 sec elapsed\n\n\n\n\n\n# library(dbplyr)\n\npartitioned_parquet_dplyr_duckdb &lt;- function(variables) {\n  \n  con &lt;- DBI::dbConnect(duckdb::duckdb())\n  \n  result &lt;- tbl(con, \"read_parquet('Datasets/DataMultiTypes/*/*.parquet', hive_partitioning=1)\") |&gt;\n    \n    mutate(\n      # Conversion of 2 columns to Date format\n      colDate1 = as.Date(colDate1),\n      colDate2 = as.Date(colDate2)\n    ) |&gt;\n    # Filter rows\n    filter(\n      colInt&gt;2000 & colInt&lt;8000\n    ) |&gt;\n    # Grouping and aggregation\n    group_by(colString) |&gt; \n    summarise(\n      min_colInt = min(colInt, na.rm = TRUE),\n      mean_colInt = mean(colInt, na.rm = TRUE),\n      mas_colInt = max(colInt, na.rm = TRUE),\n      min_colNum = min(colNum, na.rm = TRUE),\n      mean_colNum = mean(colNum, na.rm = TRUE),\n      max_colNum = max(colNum, na.rm = TRUE)\n    ) |&gt; \n    collect()\n  \n  DBI::dbDisconnect(con)\n  return(result)\n}\ntic()\npartitioned_parquet_dplyr_duckdb() \n\n# A tibble: 3 × 7\n  colString min_colInt mean_colInt mas_colInt min_colNum mean_colNum max_colNum\n  &lt;chr&gt;          &lt;int&gt;       &lt;dbl&gt;      &lt;int&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 A               2001       4999.       7999  0.0000379       0.498       1.00\n2 B               2001       5004.       7999  0.0000339       0.501       1.00\n3 C               2001       5001.       7999  0.0000305       0.501       1.00\n\ntoc()\n\n0.372 sec elapsed\n\n\n\n\n\npartitioned_parquet_polars_lazy &lt;- function(variables) {\n  \n  result &lt;- pl$scan_parquet(file = \"Datasets/DataMultiTypes.parquet\")$\n    # Conversion of 2 columns to Date format\n    with_columns(\n      pl$col(\"colDate1\")$str$strptime(pl$Date, \"%F %T\", strict = FALSE),\n      pl$col(\"colDate2\")$str$strptime(pl$Date, \"%F %T\", strict = FALSE)\n    )$\n    # Filter rows\n    filter(\n      pl$col(\"colInt\")&gt;2000 & pl$col(\"colInt\")&lt;8000\n    )$\n    # Grouping and aggregation\n    groupby(\n      \"colString\")$\n    agg(\n      pl$col(\"colInt\")$min()$alias(\"min_colInt\"),\n      pl$col(\"colInt\")$mean()$alias(\"mean_colInt\"),\n      pl$col(\"colInt\")$max()$alias(\"max_colInt\"),\n      pl$col(\"colNum\")$min()$alias(\"min_colNum\"),\n      pl$col(\"colNum\")$mean()$alias(\"mean_colNum\"),\n      pl$col(\"colNum\")$max()$alias(\"max_colNum\")\n    )$collect()\n  \n  return(result)\n}\ntic()\npartitioned_parquet_polars_lazy()\n\nshape: (3, 7)\n┌───────────┬────────────┬─────────────┬────────────┬────────────┬─────────────┬────────────┐\n│ colString ┆ min_colInt ┆ mean_colInt ┆ max_colInt ┆ min_colNum ┆ mean_colNum ┆ max_colNum │\n│ ---       ┆ ---        ┆ ---         ┆ ---        ┆ ---        ┆ ---         ┆ ---        │\n│ str       ┆ i32        ┆ f64         ┆ i32        ┆ f64        ┆ f64         ┆ f64        │\n╞═══════════╪════════════╪═════════════╪════════════╪════════════╪═════════════╪════════════╡\n│ A         ┆ 2001       ┆ 4998.624945 ┆ 7999       ┆ 0.000038   ┆ 0.498445    ┆ 0.999988   │\n│ B         ┆ 2001       ┆ 5004.31148  ┆ 7999       ┆ 0.000034   ┆ 0.500546    ┆ 0.999986   │\n│ C         ┆ 2001       ┆ 5001.243285 ┆ 7999       ┆ 0.00003    ┆ 0.501472    ┆ 0.999992   │\n└───────────┴────────────┴─────────────┴────────────┴────────────┴─────────────┴────────────┘\n\ntoc()\n\n0.035 sec elapsed\n\n\n\n\n\n\n5.4.1 Results for partitioned parquet files\n\npartitioned_parquet_bmk &lt;- microbenchmark(\n  \"arrow (lazy) - from partitioned parquet file\" = partitioned_parquet_arrow_lazy(),\n  \"dplyr (duckdb) - from partitioned parquet file\" = partitioned_parquet_dplyr_duckdb(),\n  \"polars (lazy) - from partitioned parquet file\" = partitioned_parquet_polars_lazy()$to_data_frame(),\n  times = 5\n )\nprint(partitioned_parquet_bmk)\n\nUnit: milliseconds\n                                           expr      min       lq      mean\n   arrow (lazy) - from partitioned parquet file 113.6898 113.7473 121.36800\n dplyr (duckdb) - from partitioned parquet file 322.5423 328.5422 334.01282\n  polars (lazy) - from partitioned parquet file  33.2203  33.5641  36.57194\n   median       uq      max neval\n 121.3518 128.0819 129.9692     5\n 332.5040 336.4439 350.0317     5\n  33.8401  33.9387  48.2965     5\n\n\n👉 Conclusion of this little benchmark based on partitioned parquet files: as for unique parquet files, the big winner is polars (lazy mode) ! 🏆🏆🏆"
  },
  {
    "objectID": "benchmarking.html#from-a-duckdb-file",
    "href": "benchmarking.html#from-a-duckdb-file",
    "title": "5  Benchmarking",
    "section": "5.5 From a DuckDb file",
    "text": "5.5 From a DuckDb file\nLet’s look at how to perform queries on duckdb files.\nFor this comparison, we will use :\n\nFor SQL, the DBI::dbGetQuery() method. In this way, we use the standard DBI methods to work from a DuckDb file.\n\n\nSQL\n\n\n\nduckdb_dbfile_sql &lt;- function(variables) {\n  \n  con &lt;- dbConnect(duckdb::duckdb(),\n                 \"Datasets/DataMultiTypes.duckdb\")\n  \n  result &lt;- dbGetQuery(\n    con, \n    \"SELECT colString,\n           MIN(colInt) AS min_colInt,\n           AVG(colInt) AS mean_colInt,\n           MAX(colInt) AS max_colInt,\n           MIN(colNum) AS min_colNum,\n           AVG(colNum) AS mean_colNum,\n           MAX(colNum) AS max_colNum\n    FROM (\n        SELECT colString,\n               colInt,\n               colNum\n        FROM DataMultiTypes\n        WHERE colInt &gt; 2000 AND colInt &lt; 8000\n) AS filtered_data\nGROUP BY colString;\")\n  \n  dbDisconnect(con, shutdown=TRUE)\n  \n  return(result)\n  \n}\ntic()\nduckdb_dbfile_sql()\n\n  colString min_colInt mean_colInt max_colInt   min_colNum mean_colNum\n1         B       2001    5004.311       7999 3.385660e-05   0.5005457\n2         A       2001    4998.625       7999 3.794138e-05   0.4984446\n3         C       2001    5001.243       7999 3.045052e-05   0.5014723\n  max_colNum\n1  0.9999863\n2  0.9999879\n3  0.9999921\n\ntoc()\n\n0.074 sec elapsed\n\n\n\n\n\n\n5.5.1 Results for DuckDB file\n\nduckdb_bmk &lt;- microbenchmark(\n  \"SQL from duckdb file\" = duckdb_dbfile_sql(),\n  times = 5\n )\nduckdb_bmk\n\nUnit: milliseconds\n                 expr     min      lq     mean  median      uq     max neval\n SQL from duckdb file 67.7209 68.6537 70.08498 69.1979 71.5329 73.3195     5\n\n\nNote that the query with the standard DBI methods is faster than those with dplyr verbs 🏆"
  },
  {
    "objectID": "benchmarking.html#final-results",
    "href": "benchmarking.html#final-results",
    "title": "5  Benchmarking",
    "section": "5.6 Final results",
    "text": "5.6 Final results\n\n5.6.1 Performance\nSo what can we conclude?\nWith which file format and which method is it fastest to execute the same request?\nLet’s have a look! First, let’s aggregate all the benchmark results:\n\n# Aggregation\nbmk_results &lt;- rbind(\n  csv_bmk,\n  unique_parquet_bmk,\n  partitioned_parquet_bmk,\n  duckdb_bmk\n)\n\nLet’s do a quick sort on the expr column before plotting the results :\n\n\nCode\n# Sort the results\nbmk_results$expr &lt;- reorder(bmk_results$expr, bmk_results$time, decreasing = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinal conclusions\n\n\n\n👉 A few conclusions can be drawn from this section on benchmarking:\n\nIt is more efficient to work from a parquet or duckdb file except for polars with lazy evaluation which is very fast;\n\nIn terms of execution speed, there is no great difference between a single parquet file and several partitioned parquet files (although the gap will undoubtedly widen in favour of partitioned files if the size of the initial work file is increased);\n\nLazy evaluation of polars performs best whatever the format of the file you are working on. 🏆🏆\nIt’s followed by SQL queries executed directly on a duckdb file. 🏆\n\n\n\n\n\n5.6.2 Memory usage\nWe’ve just analysed the performance of the various alternatives to Polars, but what about R’s memory usage?\nTo do this, we’re going to use mem_change() from {pryr} package. This method tells you how memory changes during code execution. Positive numbers represent an increase in the memory used by R, and negative numbers represent a decrease.\n\n\n\n\n\n\n\n\n\n\n\nMemory usage conclusions\n\n\n\n👉 A few conclusions can be drawn from this section on benchmarking about memory usage:\n\nFirstly, the method with data.table from a csv file surprisingly consumes a lot of RAM. Maybe it’s related to the as.data.table() conversion? If a reader has an explanation, I’m interested and feel free to open an issue;\n\nRegarding csv files, syntaxes with R base and dplyr are the least consuming RAM (but at the expense of speed);\n\nRegarding parquet files, syntaxes with arrow (eager) and Duckdb with SQL are the least consuming RAM;\n\nThe SQL language used on a Duckdb file also consumes very little RAM\n\n🏆🏆🏆"
  }
]